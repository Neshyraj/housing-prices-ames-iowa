{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import initial packages and data.\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set_context('notebook')\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import warnings as wrns\n",
    "wrns.filterwarnings('ignore')\n",
    "data = pd.read_csv('train.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Data Handling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Seperate data by variable types.\n",
    "\n",
    "Continuous = ['LotFrontage','LotArea','MasVnrArea','BsmtFinSF1','BsmtFinSF2','BsmtUnfSF','TotalBsmtSF',\n",
    "              '1stFlrSF','2ndFlrSF','LowQualFinSF','GrLivArea','GarageArea','WoodDeckSF','OpenPorchSF',\n",
    "              'EnclosedPorch','3SsnPorch','ScreenPorch','PoolArea','MiscVal','SalePrice']\n",
    "\n",
    "Discrete = ['GarageYrBlt', 'YearRemod/Add', 'YearBuilt', 'BsmtFullBath','FullBath','HalfBath','BedroomAbvGr',\n",
    "            'KitchenAbvGr','TotRmsAbvGrd','Fireplaces','GarageCars','MoSold','YrSold']\n",
    "\n",
    "Ordinal=['Utilities','LotShape','LandSlope','OverallQual','OverallCond','ExterQual','ExterCond','BsmtQual',\n",
    "         'BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2','HeatingQC','Electrical','KitchenQual',\n",
    "         'Functional','FireplaceQu','GarageFinish','GarageQual','GarageCond','PavedDrive','PoolQC','Fence']\n",
    "\n",
    "Nominal = ['MSSubClass','MSZoning','Street','Alley','LandContour','LotConfig','Neighborhood','Condition1',\n",
    "           'Condition2','BldgType','HouseStyle','RoofStyle','RoofMatl','Exterior1st','Exterior2nd',\n",
    "           'MasVnrType','Foundation','Heating','CentralAir','GarageType','MiscFeature','SaleType']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Define function to find missing values.\n",
    "\n",
    "def num_missing(x):\n",
    "  return sum(x.isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find number of missing values for continuous variables.\n",
    "\n",
    "print ('Missing values for continuous variables:')\n",
    "missing_con = pd.DataFrame(data[Continuous].apply(num_missing, axis=0)[data[Continuous].apply(num_missing, axis=0)>0])\n",
    "missing_con"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Find number of missing values for discrete variables.\n",
    "\n",
    "print ('Missing values for discrete variables:')\n",
    "missing_dis = pd.DataFrame(data[Discrete].apply(num_missing, axis=0)[data[Discrete].apply(num_missing, axis=0)>0])\n",
    "missing_dis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find number of missing values for ordinal variables.\n",
    "\n",
    "print ('Missing values for ordinal variables:')\n",
    "missing_ord = pd.DataFrame(data[Ordinal].apply(num_missing, axis=0)[data[Ordinal].apply(num_missing, axis=0)>0])\n",
    "missing_ord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find number of missing values for nominal variables.\n",
    "\n",
    "print ('Missing values for nominal variables:')\n",
    "missing_nom = pd.DataFrame(data[Nominal].apply(num_missing, axis=0)[data[Nominal].apply(num_missing, axis=0)>0])\n",
    "missing_nom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Filter out rows where MasVnrArea data is missing arbitrarily. This calls into question the entire row.\n",
    "\n",
    "data = data[data['MasVnrArea'] >= 0]\n",
    "\n",
    "#Fill object type blanks with NA or 0 as appropriate. Doing one by one instead of loop to easily see all altered variables.\n",
    "#GarageYrBlt left as is and will be dealt with at later stage.\n",
    "\n",
    "data['LotFrontage'] = data['LotFrontage'].fillna(0)\n",
    "data['Alley'] = data['Alley'].fillna('NA')\n",
    "data['BsmtQual'] = data['BsmtQual'].fillna('NA')\n",
    "data['BsmtCond'] = data['BsmtCond'].fillna('NA')\n",
    "data['BsmtExposure'] = data['BsmtExposure'].fillna('NA')\n",
    "data['BsmtFinType1'] = data['BsmtFinType1'].fillna('NA')\n",
    "data['BsmtFinType2'] = data['BsmtFinType2'].fillna('NA')\n",
    "data['FireplaceQu'] = data['FireplaceQu'].fillna('NA')\n",
    "data['GarageType'] = data['GarageType'].fillna('NA')\n",
    "data['GarageFinish'] = data['GarageFinish'].fillna('NA')\n",
    "data['GarageQual'] = data['GarageQual'].fillna('NA')\n",
    "data['GarageCond'] = data['GarageCond'].fillna('NA')\n",
    "data['PoolQC'] = data['PoolQC'].fillna('NA')\n",
    "data['Fence'] = data['Fence'].fillna('NA')\n",
    "data['MiscFeature'] = data['MiscFeature'].fillna('NA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis and Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import statistical packages for later use.\n",
    "\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Convert MSSubClass to string since it is nominal but read in to python as numerical.\n",
    "\n",
    "data['MSSubClass'] = data['MSSubClass'].astype(str)\n",
    "\n",
    "#Create variables for age of house and age of garage to use instead of YearBlt, YearRemod/Add and GarageYrBlt.\n",
    "\n",
    "data['AgeHouse'] = (data['YrSold'] - data['YearRemod/Add']).astype(float)\n",
    "data['AgeGarage'] = (data['YrSold'] - data['GarageYrBlt']).astype(float)\n",
    "\n",
    "#Replace AgeGarage blanks with 0 and append variables to continuous list.\n",
    "\n",
    "data['AgeGarage'] = data['AgeGarage'].fillna(0)\n",
    "Continuous.append('AgeHouse')\n",
    "Continuous.append('AgeGarage')\n",
    "del Discrete[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Continuous variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Create table to describe continous variables.\n",
    "\n",
    "table = data[Continuous].describe()\n",
    "table.loc['skewness']= data.skew()\n",
    "table.loc['kurtosis']= data.kurt()\n",
    "table.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Create histograms and box plots for continuous variables and variables treated as continuous. Then save graphs as pictures.\n",
    "\n",
    "for i in Continuous:\n",
    "    fig,ax=plt.subplots(1,2,figsize=(12,5))\n",
    "    sns.distplot(data[i],ax=ax[0],hist_kws={'alpha':0.9},kde_kws={'color':'black','alpha':0.6})\n",
    "    ax[0].set(ylabel='Frequency', title='Histogram for {}'.format(i), xlabel=i)\n",
    "    sns.boxplot(data[i],orient='v',ax=ax[1])\n",
    "    ax[1].set(title='Box plot for {}'.format(i), ylabel=i)\n",
    "    #fig.savefig('{}.png'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create LogSalePrice transformations for suspected right skew in SalePrice.\n",
    "\n",
    "data['LogSalePrice'] = np.log(data['SalePrice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print skew values before and after log transformation.\n",
    "\n",
    "skew_std_err = 6/np.sqrt(len(data))\n",
    "print('standard error of skewness = {}'.format(skew_std_err))\n",
    "skew_before = data['SalePrice'].skew()\n",
    "skew_after = data['LogSalePrice'].skew()\n",
    "print('skew before log transformation = {}'.format(skew_before))\n",
    "print('skew after log transformation = {}'.format(skew_after))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Remove anything that is more than 3 standard deviations from the mean to correct for outliers.\n",
    "#Done on Sale Price rather than LogSalePrice.\n",
    "\n",
    "data_removed_outliers = data[data['SalePrice']<500000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print skew after outliers removed and LogSalePrice used. Skewness almost 0.\n",
    "\n",
    "skew_after = data_removed_outliers['LogSalePrice'].skew()\n",
    "print('skew after log transformation and removed outliers = {}'.format(skew_after))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Histograms of SalePrice before removing outliers (initial) and LogSalePrice after removing outliers (final).\n",
    "#Save results as picture.\n",
    "\n",
    "fig,ax=plt.subplots(1,2,figsize=(12,5))\n",
    "sns.distplot(data['SalePrice'],ax=ax[0],hist_kws={'alpha':0.9},kde_kws={'color':'black','alpha':0.6})\n",
    "ax[0].set(title='Histogram for SalePrice before removed outliers', xlabel='SalePrice', ylabel='Frequency')\n",
    "sns.distplot(data_removed_outliers['LogSalePrice'],ax=ax[1],hist_kws={'alpha':0.9},kde_kws={'color':'black','alpha':0.6})\n",
    "ax[1].set(title='Histogram for LogSalePrice after removed outliers',  xlabel='logSalePrice', ylabel='Frequency')\n",
    "#fig.savefig('histogram for saleprice before and after removed outliers.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Histogram of SalePrice and LogSalePrice before removed outliers.\n",
    "\n",
    "fig,ax=plt.subplots(1,2,figsize=(12,5))\n",
    "sns.distplot(data['SalePrice'],ax=ax[0],hist_kws={'alpha':0.9},kde_kws={'color':'black','alpha':0.6})\n",
    "ax[0].set(title='Histogram for SalePrice before removed outliers', xlabel=i)\n",
    "sns.distplot(data['LogSalePrice'],ax=ax[1],hist_kws={'alpha':0.9},kde_kws={'color':'black','alpha':0.6})\n",
    "ax[1].set(title='Histogram for LogSalePrice before removed outliers', ylabel=i)\n",
    "#fig.savefig('histogram for saleprice before and after removed outliers.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Histogram of SalePrice and LogSalePrice after removed outliers.\n",
    "\n",
    "fig,ax=plt.subplots(1,2,figsize=(12,5))\n",
    "sns.distplot(data['LogSalePrice'],ax=ax[0],hist_kws={'alpha':0.9},kde_kws={'color':'black','alpha':0.6})\n",
    "ax[0].set(title='Histogram for LogSalePrice before removing outliers', xlabel='LogSalePrice')\n",
    "sns.distplot(data_removed_outliers['LogSalePrice'],ax=ax[1],hist_kws={'alpha':0.9},kde_kws={'color':'black','alpha':0.6})\n",
    "ax[1].set(title='Histogram for LogSalePrice after removing outliers', xlabel='logSalePrice')\n",
    "# fig.savefig('Histogram for SalePrice and logSalePrice.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Set transformed data set, data_removed_outliers, as main data.\n",
    "\n",
    "data = data_removed_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Draw regression plots for all continuous variables and save the results as picture.\n",
    "#Some variables which have a linear relationship with SalePrice are MasVnrArea, TotalBsmtSF, 1stFlrSF, GrLivArea, GarageArea.\n",
    "#Some variables which have a non-linear relationship with SalePrice are BsmtFinSF1, OpenporchSF.\n",
    "#There could still be some outliers.\n",
    "\n",
    "for i in Continuous:\n",
    "    fig,ax=plt.subplots(1,1,figsize=(12,5))\n",
    "    sns.regplot(data[i], data['LogSalePrice'], scatter_kws = {'s': 25}, lowess=True, color=sns.color_palette('Blues')[-1])\n",
    "    sns.despine()\n",
    "    ax.set(ylabel='LogSalePrice', title='Scatter plot for {}'.format(i))\n",
    "    plt.show()\n",
    "    #fig.savefig('{}.png'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Print number of non-zero values for continuous variables.\n",
    "#LowQualFinSF, 3SsnPorch, PoolArea, MiscVal have only a little non-zero values so the sample size is insufficient.\n",
    "\n",
    "print('the number of non-zero value for each continuous varible')\n",
    "for i in Continuous:\n",
    "    count = 0\n",
    "    for m in data[i]:\n",
    "        if m != 0:\n",
    "            count += 1\n",
    "    print('{}:{}'.format(i,count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discrete variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Plot histograms and box plots for discrete variables and save output as picture.\n",
    "\n",
    "for i in Discrete:\n",
    "    fig,ax=plt.subplots(1,2,figsize=(12,5))\n",
    "    ax[0].set(title='Histogram for {}'.format(i), xlabel=i)\n",
    "    sns.distplot(data[i],ax=ax[0],hist_kws={'alpha':0.9},kde_kws={'color':'black','alpha':0.6})\n",
    "    ax[1].set(title='Boxplot for {}'.format(i), xlabel=i)\n",
    "    sns.boxplot(data[i],orient='v',ax=ax[1])\n",
    "    #fig.savefig('{}.png'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create table to describe data for discrete variables.\n",
    "\n",
    "table = data[Discrete].describe()\n",
    "table.loc['skewness']= data.skew()\n",
    "table.loc['kurtosis']= data.kurt()\n",
    "table.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Create regression plots of discrete variables and save output.\n",
    "#There is an approximately linear trend for almost all discrete variables, except for YrSold, MoSold (as expected) and KitchenAbvGr.\n",
    "#FullBath, GarageCars, TotRmsAbrGrd, BedroomAbvGr have non-linear trends in the box plots. \n",
    "#However, the sample size for some classes is insufficient. \n",
    "#Those variables are likely to have linear relationship with saleprice, if sample size is large enough.\n",
    "\n",
    "for i in Discrete:\n",
    "    fig,ax=plt.subplots(1,1,figsize=(12,5))\n",
    "    sns.regplot(data[i], data['LogSalePrice'], scatter_kws = {'s': 25}, lowess=True, color=sns.color_palette('Blues')[-1])\n",
    "    sns.despine()\n",
    "    ax.set(ylabel='LogSalePrice', title = 'Scatter plot for {}'.format(i))\n",
    "    plt.show()\n",
    "    #fig.savefig('{}.png'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Category count for those discrete variables that don't seem to have linear trends.\n",
    "\n",
    "def count(cata_var):\n",
    "    count = {}\n",
    "    for i in cata_var.unique():\n",
    "        count[i] = 0 \n",
    "        for j in cata_var:\n",
    "            if j == i:\n",
    "                count[i] += 1\n",
    "    return count\n",
    "\n",
    "non_linear_discrete = ['FullBath', 'GarageCars', 'TotRmsAbvGrd', 'BedroomAbvGr']\n",
    "for i in non_linear_discrete:\n",
    "    print('{}:{}'.format(i,count(data[i])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ordinal Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Draw box plots for ordinal variables and save output as picture.\n",
    "#There is linear trend for Quality variables (OverallQual, KitchenQual, FireplaceQC, etc.)\n",
    "#Treat them as numerical rather than nominal or ordinal.\n",
    "\n",
    "for i in Ordinal:\n",
    "    fig, ax= plt.subplots()\n",
    "    sns.boxplot(data[i], data['LogSalePrice'], ax=ax, palette='Blues')\n",
    "    ax.set(ylabel='LogSalePrice', title='Boxplot for {}'.format(i))\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    #fig.savefig('{}.png'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Box plots of all \"quality\" variables and graphed in ascending order and saved as pictures.\n",
    "\n",
    "Quality_terms = ['ExterQual', 'BsmtQual', 'BsmtExposure', 'KitchenQual', 'FireplaceQu', \n",
    "                 'GarageQual', 'HeatingQC', 'GarageCond', 'BsmtCond', 'ExterCond']\n",
    "Order1 = ['NA','Po','Fa','TA','Gd','Ex']\n",
    "Order2 = ['NA','No','Mn','Av','Gd']\n",
    "for i in Quality_terms:\n",
    "    if i != 'BsmtExposure':\n",
    "        fig, ax= plt.subplots()\n",
    "        sns.boxplot(data[i], data['LogSalePrice'], ax=ax, order = Order1, palette='Blues')\n",
    "        ax.set(ylabel='LogSalePrice', title='Boxplot for {}'.format(i))\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        #fig.savefig('{} in order.png'.format(i))\n",
    "    if i == 'BsmtExposure':\n",
    "        fig, ax= plt.subplots()\n",
    "        sns.boxplot(data[i], data['LogSalePrice'], ax=ax, order = Order2, palette='Blues')\n",
    "        ax.set(ylabel='LogSalePrice', title='Boxplot for {}'.format(i))\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        #fig.savefig('{} in order.png'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Count data breakdown by catagory/class.\n",
    "#For some classes in a variable, the sample size is insufficient.\n",
    "\n",
    "for i in Ordinal:\n",
    "    print('{}:{}'.format(i,count(data[i])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nominal Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Box plots of remaining nominal variables.\n",
    "\n",
    "for i in Nominal:\n",
    "    fig, ax= plt.subplots()\n",
    "    sns.boxplot(data[i], data['LogSalePrice'], data=data, ax=ax, palette='Blues')\n",
    "    ax.set(ylabel='LogSalePrice', title='Boxplot for {}'.format(i))\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    #fig.savefig('boxplots for nominal {}.png'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Count data breakdown by category.\n",
    "\n",
    "for i in Nominal:\n",
    "    print('{}:{}'.format(i,count(data[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Convert month to string because it is stored as numerical, but not treated as numerical.\n",
    "\n",
    "data['MoSold'] = data['MoSold'].astype(str) \n",
    "\n",
    "#Delete year built, remodeled, and garage year built.\n",
    "\n",
    "del data['YearBuilt']\n",
    "del data['YearRemod/Add']\n",
    "del data['GarageYrBlt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Duplicate data to keep record of previous version in case need to use it.\n",
    "\n",
    "data_num = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Sort neighborhoods by mean.\n",
    "\n",
    "neighbor_mean = data_num.groupby('Neighborhood')[['SalePrice']].apply(np.mean)\n",
    "neighbor_mean.sort_values('SalePrice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Import scip to compare Neighborhood Categories with Welch's t-tests assuming unequal variance.\n",
    "#Group categories accordingly to decrease number of neighborhood categories.\n",
    "#Significance level 10%\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "#Leave MeadowV\n",
    "\n",
    "t, pvalue = stats.ttest_ind(data_num.loc[data_num['Neighborhood']=='MeadowV','SalePrice'],\n",
    "                            data_num.loc[data_num['Neighborhood']=='BrDale','SalePrice'],equal_var=False)\n",
    "print('MeadowV vs BrDale',pvalue)\n",
    "\n",
    "#Combine BrDale and IDOTRR\n",
    "\n",
    "t, pvalue = stats.ttest_ind(data_num.loc[data_num['Neighborhood']=='BrDale','SalePrice'],\n",
    "                            data_num.loc[data_num['Neighborhood']=='IDOTRR','SalePrice'],equal_var=False)\n",
    "print('BrDale vs IDOTRR',pvalue)\n",
    "\n",
    "#Combine OldTown Edwards SWISU BrkSide\n",
    "\n",
    "t, pvalue = stats.ttest_ind(data_num.loc[data_num['Neighborhood']=='OldTown','SalePrice'],\n",
    "                            data_num.loc[data_num['Neighborhood']=='Edwards','SalePrice'],equal_var=False)\n",
    "print('OldTown vs Edwards',pvalue) \n",
    "t, pvalue = stats.ttest_ind(data_num.loc[data_num['Neighborhood']=='OldTown','SalePrice'],\n",
    "                            data_num.loc[data_num['Neighborhood']=='SWISU','SalePrice'],equal_var=False)\n",
    "print('OldTown vs SWISU',pvalue)\n",
    "t, pvalue = stats.ttest_ind(data_num.loc[data_num['Neighborhood']=='OldTown','SalePrice'],\n",
    "                            data_num.loc[data_num['Neighborhood']=='BrkSide','SalePrice'],equal_var=False)\n",
    "print('OldTown vs BrkSide',pvalue)\n",
    "t, pvalue = stats.ttest_ind(data_num.loc[data_num['Neighborhood']=='Edwards','SalePrice'],\n",
    "                            data_num.loc[data_num['Neighborhood']=='SWISU','SalePrice'],equal_var=False)\n",
    "print('Edwards vs SWISU',pvalue)\n",
    "t, pvalue = stats.ttest_ind(data_num.loc[data_num['Neighborhood']=='Edwards','SalePrice'],\n",
    "                            data_num.loc[data_num['Neighborhood']=='BrkSide','SalePrice'],equal_var=False)\n",
    "print('Edwards vs BrkSide',pvalue)\n",
    "t, pvalue = stats.ttest_ind(data_num.loc[data_num['Neighborhood']=='SWISU','SalePrice'],\n",
    "                            data_num.loc[data_num['Neighborhood']=='BrkSide','SalePrice'],equal_var=False)\n",
    "print('SWISU vs BrkSide',pvalue)\n",
    "\n",
    "#Combine Sawyer NAmes Blueste NPkVill\n",
    "\n",
    "t, pvalue = stats.ttest_ind(data_num.loc[data_num['Neighborhood']=='Sawyer','SalePrice'],\n",
    "                            data_num.loc[data_num['Neighborhood']=='NAmes','SalePrice'],equal_var=False)\n",
    "print('Sawyer vs NAmes',pvalue)\n",
    "t, pvalue = stats.ttest_ind(data_num.loc[data_num['Neighborhood']=='Sawyer','SalePrice'],\n",
    "                            data_num.loc[data_num['Neighborhood']=='Blueste','SalePrice'],equal_var=False)\n",
    "print('Sawyer vs Blueste',pvalue)\n",
    "t, pvalue = stats.ttest_ind(data_num.loc[data_num['Neighborhood']=='Sawyer','SalePrice'],\n",
    "                            data_num.loc[data_num['Neighborhood']=='NPkVill','SalePrice'],equal_var=False)\n",
    "print('Sawyer vs NPkVill',pvalue)\n",
    "t, pvalue = stats.ttest_ind(data_num.loc[data_num['Neighborhood']=='NAmes','SalePrice'],\n",
    "                            data_num.loc[data_num['Neighborhood']=='Blueste','SalePrice'],equal_var=False)\n",
    "print('NAmes vs Blueste',pvalue)\n",
    "t, pvalue = stats.ttest_ind(data_num.loc[data_num['Neighborhood']=='NAmes','SalePrice'],\n",
    "                            data_num.loc[data_num['Neighborhood']=='NPkVill','SalePrice'],equal_var=False)\n",
    "print('NAmes vs NPkVill',pvalue)\n",
    "t, pvalue = stats.ttest_ind(data_num.loc[data_num['Neighborhood']=='Blueste','SalePrice'],\n",
    "                            data_num.loc[data_num['Neighborhood']=='NPkVill','SalePrice'],equal_var=False)\n",
    "print('Blueste vs NPkVill',pvalue)\n",
    "\n",
    "#Combine Mitchel SawyerW Blmngtn\n",
    "\n",
    "t, pvalue = stats.ttest_ind(data_num.loc[data_num['Neighborhood']=='Mitchel','SalePrice'],\n",
    "                            data_num.loc[data_num['Neighborhood']=='SawyerW','SalePrice'],equal_var=False)\n",
    "print('Mitchel vs SawyerW',pvalue)\n",
    "t, pvalue = stats.ttest_ind(data_num.loc[data_num['Neighborhood']=='Mitchel','SalePrice'],\n",
    "                            data_num.loc[data_num['Neighborhood']=='Blmngtn','SalePrice'],equal_var=False)\n",
    "print('Mitchel vs Blmngtn',pvalue)\n",
    "t, pvalue = stats.ttest_ind(data_num.loc[data_num['Neighborhood']=='SawyerW','SalePrice'],\n",
    "                            data_num.loc[data_num['Neighborhood']=='Blmngtn','SalePrice'],equal_var=False)\n",
    "print('SawyerW vs Blmgtn',pvalue)\n",
    "\n",
    "#Combine Gilbert NWAmes Crawfor CollgCr\n",
    "\n",
    "t, pvalue = stats.ttest_ind(data_num.loc[data_num['Neighborhood']=='Gilbert','SalePrice'],\n",
    "                            data_num.loc[data_num['Neighborhood']=='NWAmes','SalePrice'],equal_var=False)\n",
    "print('Gilbert vs NWAmes',pvalue)\n",
    "t, pvalue = stats.ttest_ind(data_num.loc[data_num['Neighborhood']=='Gilbert','SalePrice'],\n",
    "                            data_num.loc[data_num['Neighborhood']=='Crawfor','SalePrice'],equal_var=False)\n",
    "print('Gilbert vs Crawfor',pvalue)\n",
    "t, pvalue = stats.ttest_ind(data_num.loc[data_num['Neighborhood']=='Gilbert','SalePrice'],\n",
    "                            data_num.loc[data_num['Neighborhood']=='CollgCr','SalePrice'],equal_var=False)\n",
    "print('Gilbert vs CollgCr',pvalue)\n",
    "t, pvalue = stats.ttest_ind(data_num.loc[data_num['Neighborhood']=='NWAmes','SalePrice'],\n",
    "                            data_num.loc[data_num['Neighborhood']=='Crawfor','SalePrice'],equal_var=False)\n",
    "print('NWAmes vs Crawfor',pvalue)\n",
    "t, pvalue = stats.ttest_ind(data_num.loc[data_num['Neighborhood']=='NWAmes','SalePrice'],\n",
    "                            data_num.loc[data_num['Neighborhood']=='CollgCr','SalePrice'],equal_var=False)\n",
    "print('NWAmes vs CollgCr',pvalue)\n",
    "t, pvalue = stats.ttest_ind(data_num.loc[data_num['Neighborhood']=='Crawfor','SalePrice'],\n",
    "                            data_num.loc[data_num['Neighborhood']=='CollgCr','SalePrice'],equal_var=False)\n",
    "print('Crawfor vs CollgCr',pvalue)\n",
    "\n",
    "#Combine Greens ClearCr Somerst Timber\n",
    "\n",
    "t, pvalue = stats.ttest_ind(data_num.loc[data_num['Neighborhood']=='Greens','SalePrice'],\n",
    "                            data_num.loc[data_num['Neighborhood']=='ClearCr','SalePrice'],equal_var=False)\n",
    "print('Greens vs ClearCr',pvalue)\n",
    "t, pvalue = stats.ttest_ind(data_num.loc[data_num['Neighborhood']=='Greens','SalePrice'],\n",
    "                            data_num.loc[data_num['Neighborhood']=='Somerst','SalePrice'],equal_var=False)\n",
    "print('Greens vs Somerst',pvalue)\n",
    "t, pvalue = stats.ttest_ind(data_num.loc[data_num['Neighborhood']=='Greens','SalePrice'],\n",
    "                            data_num.loc[data_num['Neighborhood']=='Timber','SalePrice'],equal_var=False)\n",
    "print('Greens vs Timber',pvalue)\n",
    "t, pvalue = stats.ttest_ind(data_num.loc[data_num['Neighborhood']=='ClearCr','SalePrice'],\n",
    "                            data_num.loc[data_num['Neighborhood']=='Somerst','SalePrice'],equal_var=False)\n",
    "print('ClearCr vs Somerst',pvalue)\n",
    "t, pvalue = stats.ttest_ind(data_num.loc[data_num['Neighborhood']=='ClearCr','SalePrice'],\n",
    "                            data_num.loc[data_num['Neighborhood']=='Timber','SalePrice'],equal_var=False)\n",
    "print('ClearCr vs Timber',pvalue)\n",
    "t, pvalue = stats.ttest_ind(data_num.loc[data_num['Neighborhood']=='Somerst','SalePrice'],\n",
    "                            data_num.loc[data_num['Neighborhood']=='Timber','SalePrice'],equal_var=False)\n",
    "print('Somerst vs Timber',pvalue)\n",
    "\n",
    "#Leave Veenker\n",
    "\n",
    "t, pvalue = stats.ttest_ind(data_num.loc[data_num['Neighborhood']=='Veenker','SalePrice'],\n",
    "                            data_num.loc[data_num['Neighborhood']=='StoneBr','SalePrice'],equal_var=False)\n",
    "print('Veenker vs StoneBr',pvalue)\n",
    "\n",
    "#Combine StoneBr NoRidge NridgHt\n",
    "\n",
    "t, pvalue = stats.ttest_ind(data_num.loc[data_num['Neighborhood']=='StoneBr','SalePrice'],\n",
    "                            data_num.loc[data_num['Neighborhood']=='NoRidge','SalePrice'],equal_var=False)\n",
    "print('StoneBr vs NoRidge',pvalue)\n",
    "t, pvalue = stats.ttest_ind(data_num.loc[data_num['Neighborhood']=='StoneBr','SalePrice'],\n",
    "                            data_num.loc[data_num['Neighborhood']=='NridgHt','SalePrice'],equal_var=False)\n",
    "print('StoneBr vs NridgHt',pvalue)\n",
    "t, pvalue = stats.ttest_ind(data_num.loc[data_num['Neighborhood']=='NoRidge','SalePrice'],\n",
    "                            data_num.loc[data_num['Neighborhood']=='NridgHt','SalePrice'],equal_var=False)\n",
    "print('NoRidge vs NridgHt',pvalue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Show top 25 numerical variables by correlation to LogSalePrice.\n",
    "\n",
    "pd.set_option('display.max_rows',300)\n",
    "abs_correl = abs(data_num.corr().round(3)['LogSalePrice'])\n",
    "abs_correl_sort = abs_correl.sort_values(ascending=False)\n",
    "abs_correl_sort.head(27)\n",
    "pd.DataFrame(abs_correl_sort.head(27))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get list so easy to copy and paste into cell below. Use 27 to get top 25 for correlation heatmap.\n",
    "\n",
    "abs_correl_sort.head(27).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Put top 25 numerical variables in a list.\n",
    "\n",
    "top_variables_25 = ['LogSalePrice', 'OverallQual', 'GrLivArea', 'GarageCars',\n",
    "       'GarageArea', 'TotalBsmtSF', '1stFlrSF', 'AgeHouse', 'FullBath',\n",
    "       'Fireplaces', 'TotRmsAbvGrd', 'BsmtFinSF1', 'AgeGarage', 'MasVnrArea',\n",
    "       'WoodDeckSF', 'HalfBath', 'OpenPorchSF', '2ndFlrSF', 'LotArea',\n",
    "       'BsmtFullBath', 'BedroomAbvGr', 'BsmtUnfSF', 'EnclosedPorch',\n",
    "       'KitchenAbvGr', 'LotFrontage', 'ScreenPorch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Create heatmap of top 25 numerical variables. Note this is before dummy variable creation and simply to have an idea of\n",
    "#numerical relationships.\n",
    "\n",
    "data_num[top_variables_25].corr().round(4)\n",
    "fig, ax = plt.subplots(figsize = (11,10))\n",
    "cmap = sns.diverging_palette(220,10,as_cmap=True)\n",
    "sns.heatmap(data_num[top_variables_25].corr(), ax=ax, cmap=cmap)\n",
    "ax.set(title='Correlation heatmap for top 25 variables correlated with LogSalePrice')\n",
    "#fig.savefig('Correlation heatmap before feature engineering (top 25).png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Combine Neighborhood variables using results from Welch's t-tests in EDA.\n",
    "\n",
    "neighbor_combined = {'MeadowV':'MeadowV',\n",
    "                     'BrDale': 'BrD_IDO',\n",
    "                     'IDOTRR': 'BrD_IDO',\n",
    "                     'OldTown':'Old_Ed_SW_Brk',\n",
    "                     'Edwards':'Old_Ed_SW_Brk',\n",
    "                     'SWISU':'Old_Ed_SW_Brk',\n",
    "                     'BrkSide':'Old_Ed_SW_Brk',\n",
    "                     'Sawyer':'Sa_NA_Bl_NP',\n",
    "                     'NAmes':'Sa_NA_Bl_NP',\n",
    "                     'Blueste':'Sa_NA_Bl_NP',\n",
    "                     'NPkVill':'Sa_NA_Bl_NP',\n",
    "                     'Mitchel':'Mi_SaW,Bng',\n",
    "                     'SawyerW':'Mi_SaW,Bng',\n",
    "                     'Blmngtn':'Mi_SaW,Bng',\n",
    "                     'Gilbert':'Gi_NWA_Cr_Co',\n",
    "                     'NWAmes':'Gi_NWA_Cr_Co',\n",
    "                     'Crawfor':'Gi_NWA_Cr_Co',\n",
    "                     'CollgCr':'Gi_NWA_Cr_Co',\n",
    "                     'Greens':'Gr_CC_So_Ti',\n",
    "                     'ClearCr':'Gr_CC_So_Ti',\n",
    "                     'Somerst':'Gr_CC_So_Ti',\n",
    "                     'Timber':'Gr_CC_So_Ti',\n",
    "                     'Veenker':'Veenker',\n",
    "                     'StoneBr':'St_No_NHt',\n",
    "                     'NoRidge':'St_No_NHt',\n",
    "                     'NridgHt':'St_No_NHt'}\n",
    "data_num['Neighborhood'] = data_num['Neighborhood'].map(neighbor_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Box plots of neighborhood after combining neighborhoods.\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "sns.boxplot(x = 'Neighborhood' , y = 'LogSalePrice', ax = ax, data = data_num, palette = 'Greens')\n",
    "plt.xticks(rotation=20)\n",
    "ax.set(title='Boxplot for Neighborhood after clustering')\n",
    "#fig.savefig('Boxplot for Neighborhood after clustering.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Recode and convert quality type ordinals to numerical for more simplicity in analysis.\n",
    "\n",
    "exterqual_vals = {'Fa':1,'TA':2,'Gd':3,'Ex':4}\n",
    "data_num['ExterQual'] = data_num['ExterQual'].map(exterqual_vals).astype(int)\n",
    "\n",
    "bsmt_vals = {'NA':0,'Po':1,'Fa':2,'TA':3,'Gd':4,'Ex':5}\n",
    "data_num['BsmtQual'] = data_num['BsmtQual'].map(bsmt_vals).astype(int)\n",
    "\n",
    "bsmt_exp = {'NA':0,'No':1,'Mn':2,'Av':3,'Gd':4}\n",
    "data_num['BsmtExposure'] = data_num['BsmtExposure'].map(bsmt_exp).astype(int)\n",
    "\n",
    "kitchen_vals = {'Po':1,'Fa':2,'TA':3,'Gd':4,'Ex':5}\n",
    "data_num['KitchenQual'] = data_num['KitchenQual'].map(kitchen_vals).astype(int)\n",
    "\n",
    "fireplace_qual = {'NA':0,'Po':1,'Fa':2,'TA':3,'Gd':4,'Ex':5}\n",
    "data_num['FireplaceQu'] = data_num['FireplaceQu'].map(fireplace_qual).astype(int)\n",
    "\n",
    "garage_vals= {'NA':0,'Po':1,'Fa':2,'TA':3,'Gd':4}\n",
    "data_num['GarageQual'] = data_num['GarageQual'].map(garage_vals).astype(int)\n",
    "\n",
    "heating_vals = {'Fa':1,'TA':2,'Gd':3,'Ex':4}\n",
    "data_num['HeatingQC'] = data_num['HeatingQC'].map(kitchen_vals).astype(int)\n",
    "\n",
    "garage_cond = {'NA':0,'Po':1,'Fa':2,'TA':3,'Gd':4}\n",
    "data_num['GarageCond'] = data_num['GarageCond'].map(garage_cond).astype(int)\n",
    "\n",
    "bsmt_cond = {'NA':0,'Po':1,'Fa':2,'TA':3,'Gd':4,'Ex':5}\n",
    "data_num['BsmtCond'] = data_num['BsmtCond'].map(bsmt_cond).astype(int)\n",
    "\n",
    "exter_cond = {'Fa':1,'TA':2,'Gd':3,'Ex':4}\n",
    "data_num['ExterCond'] = data_num['ExterCond'].map(exter_cond).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create dummy variables for remaining categoricals.\n",
    "\n",
    "columns_cat_num = list(data_num.select_dtypes(['object']).columns)\n",
    "for column in columns_cat_num:\n",
    "    data_num = pd.get_dummies(data_num, columns = [column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create interactions. GrLiv_Rooms created but ultimately left out.\n",
    "\n",
    "data_num['BsmtSF_Qual'] = data_num['TotalBsmtSF']*data_num['BsmtQual']\n",
    "data_num['GarageArea_Qual'] = data_num['GarageArea']*data_num['GarageQual']\n",
    "#data_num['GrLiv_Rooms'] = data_num['GrLivArea']*data_num['TotRmsAbvGrd']\n",
    "data_num['GarageArea_Cars'] = data_num['GarageArea']*data_num['GarageCars']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further EDA - Correlation Matrix with Interaction Terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Show top 70 correlated with LogSalePrice\n",
    "\n",
    "pd.set_option('display.max_rows',300)\n",
    "abs_correl = abs(data_num.corr().round(3)['LogSalePrice'])\n",
    "abs_correl_sort = abs_correl.sort_values(ascending=False)\n",
    "abs_correl_sort.head(72)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Print list so easy to copy and paste in cell below.\n",
    "\n",
    "abs_correl_sort.head(72).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#List used for large 70 variable correlation heatmap.\n",
    "\n",
    "predictors_heat_large = ['LogSalePrice', 'OverallQual', 'BsmtSF_Qual', 'GrLivArea',\n",
    "       'GarageCars', 'GarageArea_Cars', 'GarageArea_Qual', 'GarageArea',\n",
    "       'ExterQual', 'BsmtQual', 'TotalBsmtSF', 'KitchenQual', '1stFlrSF',\n",
    "       'AgeHouse', 'FullBath', 'FireplaceQu', 'Foundation_PConc', 'Fireplaces',\n",
    "       'TotRmsAbvGrd', 'Neighborhood_St_No_NHt', 'HeatingQC',\n",
    "       'GarageType_Attchd', 'GarageFinish_Unf', 'BsmtFinType1_GLQ',\n",
    "       'GarageType_Detchd', 'BsmtFinSF1', 'AgeGarage',\n",
    "       'Neighborhood_Old_Ed_SW_Brk', 'MSSubClass_60', 'MasVnrArea',\n",
    "       'CentralAir_Y', 'CentralAir_N', 'PavedDrive_Y', 'Exterior1st_VinylSd',\n",
    "       'Exterior2nd_VinylSd', 'GarageQual', 'BsmtExposure', 'PavedDrive_N',\n",
    "       'MSZoning_RM', 'WoodDeckSF', 'GarageFinish_Fin', 'LotShape_Reg',\n",
    "       'GarageCond', 'MasVnrType_None', 'HalfBath', 'MSSubClass_30',\n",
    "       'OpenPorchSF', 'Electrical_SBrkr', 'LotShape_IR1', 'Foundation_CBlock',\n",
    "       '2ndFlrSF', 'GarageType_NA', 'GarageFinish_NA', 'BsmtCond',\n",
    "       'MSZoning_RL', 'GarageFinish_RFn', 'LotArea', 'MasVnrType_BrkFace',\n",
    "       'Foundation_BrkTil', 'HouseStyle_2Story', 'Neighborhood_Gr_CC_So_Ti',\n",
    "       'BsmtFullBath', 'Electrical_FuseA', 'Neighborhood_Sa_NA_Bl_NP',\n",
    "       'BsmtFinType1_NA', 'BsmtFinType2_NA', 'MasVnrType_Stone',\n",
    "       'Neighborhood_Gi_NWA_Cr_Co', 'Neighborhood_BrD_IDO', 'BedroomAbvGr',\n",
    "       'Fence_NA']\n",
    "\n",
    "#List used for smaller 30 variable correlation heatmap.\n",
    "\n",
    "predictors_heat = ['LogSalePrice', 'OverallQual', 'BsmtSF_Qual', 'GrLivArea',\n",
    "                   'GarageCars', 'GarageArea_Cars', 'GarageArea_Qual', 'GarageArea',\n",
    "                   'ExterQual', 'BsmtQual', 'TotalBsmtSF', 'KitchenQual', '1stFlrSF',\n",
    "                   'AgeHouse', 'FullBath', 'FireplaceQu', 'Foundation_PConc', 'Fireplaces',\n",
    "                   'TotRmsAbvGrd', 'Neighborhood_St_No_NHt', 'HeatingQC',\n",
    "                   'GarageType_Attchd', 'GarageFinish_Unf', 'BsmtFinType1_GLQ',\n",
    "                   'GarageType_Detchd', 'BsmtFinSF1', 'AgeGarage',\n",
    "                   'Neighborhood_Old_Ed_SW_Brk', 'MSSubClass_60', 'MasVnrArea',\n",
    "                   'CentralAir_Y']\n",
    "\n",
    "\n",
    "#Predictors used for OLS model.\n",
    "#Started with 30 and removed GarageArea_Qual, Fireplaces, TotRmsAbvGrd, GarageType_Detchd, 1stFlrSF.\n",
    "\n",
    "predictors1 = ['OverallQual', 'BsmtSF_Qual', 'GrLivArea', 'GarageCars', 'GarageArea_Cars', \n",
    "                'GarageArea', 'ExterQual', 'BsmtQual', 'TotalBsmtSF', 'KitchenQual',\n",
    "                'AgeHouse', 'FullBath', 'FireplaceQu', 'Foundation_PConc','Neighborhood_St_No_NHt', \n",
    "                'HeatingQC', 'GarageType_Attchd', 'GarageFinish_Unf', 'BsmtFinType1_GLQ',\n",
    "                'BsmtFinSF1', 'AgeGarage', 'Neighborhood_Old_Ed_SW_Brk', 'MSSubClass_60', \n",
    "                'MasVnrArea', 'CentralAir_Y']\n",
    "\n",
    "#Predictors used for Fwd + Ridge, Lasso, Enet, and Fwd + PCR models.\n",
    "#Started with 70 and removed GarageArea_Qual, Fireplaces, TotRmsAbvGrd, GarageType_Detchd, 1stFlrSF, CentralAir_N, PavedDrive_N, \n",
    "#GarageCond, LotShape_IR1, Foundation_CBlock, 2ndFlrSF, GarageType_NA, GarageFinish_NA, BsmtCond, MSZoning_RL, BsmtFullBath\n",
    "#MasVnrType_BrkFace, HouseStyle_2Story, Electrical_FuseA\n",
    "\n",
    "predictors2 = ['OverallQual', 'BsmtSF_Qual', 'GrLivArea',\n",
    "       'GarageCars', 'GarageArea_Cars', 'GarageArea',\n",
    "       'ExterQual', 'BsmtQual', 'TotalBsmtSF', 'KitchenQual',\n",
    "       'AgeHouse', 'FullBath', 'FireplaceQu', 'Foundation_PConc',\n",
    "       'Neighborhood_St_No_NHt', 'HeatingQC',\n",
    "       'GarageType_Attchd', 'GarageFinish_Unf', 'BsmtFinType1_GLQ',\n",
    "       'BsmtFinSF1', 'AgeGarage',\n",
    "       'Neighborhood_Old_Ed_SW_Brk', 'MSSubClass_60', 'MasVnrArea',\n",
    "       'CentralAir_Y', 'PavedDrive_Y', 'Exterior1st_VinylSd',\n",
    "       'Exterior2nd_VinylSd', 'GarageQual', 'BsmtExposure',\n",
    "       'MSZoning_RM', 'WoodDeckSF', 'GarageFinish_Fin', 'LotShape_Reg',\n",
    "       'MasVnrType_None', 'HalfBath', 'MSSubClass_30',\n",
    "       'OpenPorchSF', 'Electrical_SBrkr',\n",
    "       'GarageFinish_RFn', 'LotArea',\n",
    "       'Foundation_BrkTil', 'Neighborhood_Gr_CC_So_Ti',\n",
    "       'Neighborhood_Sa_NA_Bl_NP',\n",
    "       'BsmtFinType1_NA', 'BsmtFinType2_NA', 'MasVnrType_Stone',\n",
    "       'Neighborhood_Gi_NWA_Cr_Co', 'Neighborhood_BrD_IDO', 'BedroomAbvGr',\n",
    "       'Fence_NA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Display correlations of top 70.\n",
    "\n",
    "pd.set_option('display.max_columns',71)\n",
    "data_num[predictors_heat_large].corr().round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Display large heat map and save figure to have a large visual idea of variable relationships.\n",
    "\n",
    "data_num[predictors_heat_large].corr().round(4)\n",
    "fig, ax = plt.subplots(figsize = (14,14))\n",
    "cmap = sns.diverging_palette(220,10,as_cmap=True)\n",
    "sns.heatmap(data_num[predictors_heat_large].corr(), ax=ax, cmap=cmap)\n",
    "ax.set(title='Correlation heatmap for top 70 variables correlated with LogSalePrice')\n",
    "#fig.savefig('Correlation heatmap after feature engineering (top 70).png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Display small heatmap and save figure.\n",
    "\n",
    "data_num[predictors_heat].corr().round(4)\n",
    "fig, ax = plt.subplots(figsize = (14,14))\n",
    "cmap = sns.diverging_palette(220,10,as_cmap=True)\n",
    "sns.heatmap(data_num[predictors_heat].corr(), ax=ax, cmap=cmap)\n",
    "ax.set(title='Correlation heatmap for top 30 variables correlated with LogSalePrice')\n",
    "#fig.savefig('Correlation heatmap after feature engineering (top 30).png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OLS (Submission 20, MAE = 14621.89)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create copy of the data to standardize.\n",
    "\n",
    "data_s = data_num.copy()\n",
    "data_pred = data_num[predictors2] #This is so we can call the columns by dtype in the next cell to divide by 2 SD\n",
    "data_s.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardize data by subtracting predictors by respective mean and dividing by one standard deviation for dummy variables and\n",
    "#2 standard deviations for numerical variables. This is so they are on roughly the same scale for using the regularization\n",
    "#methods. Suggested by Marcel as something to try (not necessarily required) and also cited in various literature.\n",
    "\n",
    "pred_float = data_pred.select_dtypes(['float64']).columns\n",
    "pred_int = data_pred.select_dtypes(['int64']).columns\n",
    "pred_dum = data_pred.select_dtypes(['uint8']).columns\n",
    "\n",
    "mu_float = np.mean(data_s[pred_float])\n",
    "sigma_float = np.std(data_s[pred_float])\n",
    "\n",
    "mu_int = np.mean(data_s[pred_int])\n",
    "sigma_int = np.std(data_s[pred_int])\n",
    "\n",
    "mu_dum = np.mean(data_s[pred_dum])\n",
    "sigma_dum = np.std(data_s[pred_dum])\n",
    "\n",
    "data_s[pred_float] = (data_s[pred_float]-mu_float)/(2*sigma_float)\n",
    "data_s[pred_int] = (data_s[pred_int]-mu_int)/(2*sigma_int)\n",
    "data_s[pred_dum] = (data_s[pred_dum])/(sigma_dum)\n",
    "\n",
    "data_s.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit OLS model on 25 predictors and calculate cross validation score on LogSalePrice.\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def ols_reg_10_folds(predictors, response):\n",
    "    ols = LinearRegression()\n",
    "    scores = cross_val_score(ols, data_s[predictors], data_s[response], cv=10, scoring = 'neg_mean_absolute_error')\n",
    "    cv_mae = np.mean(-1*scores)\n",
    "    return cv_mae\n",
    "\n",
    "ols = LinearRegression()\n",
    "ols.fit(data_s[predictors1],data_s['LogSalePrice'])\n",
    "\n",
    "ols_reg_10_folds(predictors1,'LogSalePrice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display OLS coefficients.\n",
    "\n",
    "pd.set_option('display.max_columns',30)\n",
    "pd.DataFrame(ols.coef_.round(5), index = predictors1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Residual plots of OLS.\n",
    "\n",
    "ols.fit(data_s[predictors1], data_s['LogSalePrice'])\n",
    "y_fit = ols.predict(data_s[predictors1])\n",
    "y_actual = data_s['LogSalePrice']\n",
    "residuals = y_fit-y_actual\n",
    "abs_residuals = abs(residuals)\n",
    "\n",
    "fig, ax= plt.subplots(1,2, figsize=(13,5))\n",
    "sns.regplot(y_fit, residuals, fit_reg=False, ax=ax[0], scatter_kws={'alpha':0.5})\n",
    "ax[0].set_xlabel('Fitted values')\n",
    "ax[0].set_ylabel('Residuals')\n",
    "ax[0].set(title='Residuals vs Fitted Values')\n",
    "sns.regplot(y_fit, abs_residuals, fit_reg=False, ax=ax[1], scatter_kws={'alpha':0.5, 'color': sns.color_palette()[0]})\n",
    "ax[1].set_xlabel('Fitted values')\n",
    "ax[1].set_ylabel('Absolute residuals')\n",
    "ax[1].set(title='Absolure residuals vs Fitted Values')\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "fig.savefig('residuals_OLS.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Heatmap to check for perfect multicollinearity. ALready done in previous steps when creating heatmaps, but checking again. \n",
    "\n",
    "data_s[predictors1].corr().round(4)\n",
    "fig, ax = plt.subplots(figsize = (10,10))\n",
    "cmap = sns.diverging_palette(220,10,as_cmap=True)\n",
    "sns.heatmap(data_s[predictors1].corr(), ax=ax, cmap=cmap,center=0)\n",
    "ax.set(title='Correlation heatmap for predictors used in OLS')\n",
    "#fig.savefig('correlation_OLS.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso, Ridge, and Elastic Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LASSO (Submission 21, MAE = 13277.61)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Linear Regression fit to compare to Lasso, Ridge, and ENet coefficents.\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "ols2 = LinearRegression()\n",
    "ols2.fit(data_s[predictors2],data_s['LogSalePrice'])\n",
    "\n",
    "#Lasso CV to select shrinkage ad fit Lasso on 51 variables.\n",
    "\n",
    "from sklearn.linear_model import LassoCV\n",
    "lasso = LassoCV(cv=5)\n",
    "lasso.fit(data_s[predictors2], np.ravel(data_s['LogSalePrice']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ratio of Lasso coefficients to OLS coefficients\n",
    "\n",
    "round(np.linalg.norm(lasso.coef_, ord=1)/np.linalg.norm(np.ravel(ols2.coef_), ord=1),10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display Lasso coefficients.\n",
    "\n",
    "pd.set_option('display.max_columns',51)\n",
    "pd.DataFrame(lasso.coef_.round(5), index = predictors2).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate Lasso MAE CV Score on LogSalePrice\n",
    "\n",
    "scores_lasso = cross_val_score(lasso, data_s[predictors2], np.ravel(data_s['LogSalePrice']), \n",
    "                               cv=10, scoring = 'neg_mean_absolute_error')\n",
    "cv_mae_lasso = np.mean(-1*scores_lasso)\n",
    "cv_mae_lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Residual plots of Lasso\n",
    "\n",
    "lasso.fit(data_s[predictors2], data_s['LogSalePrice'])\n",
    "y_fit = lasso.predict(data_s[predictors2])\n",
    "y_actual = data_s['LogSalePrice']\n",
    "residuals = y_fit - y_actual\n",
    "abs_residuals = abs(residuals)\n",
    "\n",
    "fig, ax= plt.subplots(1,2, figsize=(13,5))\n",
    "sns.regplot(y_fit, residuals, fit_reg=False, ax=ax[0], scatter_kws={'alpha':0.5})\n",
    "ax[0].set_xlabel('Fitted values')\n",
    "ax[0].set_ylabel('Residuals')\n",
    "ax[0].set(title='Residuals vs Fitted Values')\n",
    "sns.regplot(y_fit, abs_residuals, fit_reg=False, ax=ax[1], scatter_kws={'alpha':0.5, 'color': sns.color_palette()[0]})\n",
    "ax[1].set_xlabel('Fitted values')\n",
    "ax[1].set_ylabel('Absolute residuals')\n",
    "ax[1].set(title='Absolute residuals vs Fitted Values')\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "fig.savefig('residuals_lasso.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fwd + Ridge (Submission 18, MAE = 13225.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define function and class for forward selection algorithm taken from Marcel's QBUS2820 file and edited for MAE.\n",
    "\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "def forwardselection(X, y):\n",
    "    \"\"\"Forward variable selection based on the Scikit learn API\n",
    "    \n",
    "    \n",
    "    Output:\n",
    "    ----------------------------------------------------------------------------------\n",
    "    Scikit learn OLS regression object for the best model\n",
    "    \"\"\"\n",
    "\n",
    "    # Functions\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "\n",
    "    # Initialisation\n",
    "    base = []\n",
    "    p = X.shape[1]\n",
    "    candidates = list(np.arange(p))\n",
    "\n",
    "    # Forward recursion\n",
    "    i=1\n",
    "    bestcvscore=-np.inf    \n",
    "    while i<=p:\n",
    "        bestscore = 0\n",
    "        for variable in candidates:\n",
    "            ols = LinearRegression()\n",
    "            ols.fit(X.iloc[:, base + [variable]], y)\n",
    "            score = ols.score(X.iloc[:, base + [variable]], y)\n",
    "            if score > bestscore:\n",
    "                bestscore = score \n",
    "                best = ols\n",
    "                newvariable=variable\n",
    "        base.append(newvariable)\n",
    "        candidates.remove(newvariable)\n",
    "        \n",
    "        cvscore = cross_val_score(best, X.iloc[:, base], y, scoring='neg_mean_absolute_error').mean() \n",
    "        \n",
    "        if cvscore > bestcvscore:\n",
    "            bestcvscore=cvscore\n",
    "            bestcv = best\n",
    "            subset = base[:]\n",
    "        i+=1\n",
    "    \n",
    "    #Finalise\n",
    "    return bestcv, subset\n",
    "\n",
    "class forward:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.ols, self.subset = forwardselection(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.ols.predict(X.iloc[:, self.subset])\n",
    "\n",
    "    def cv_score(self, X, y, cv=10):\n",
    "        from sklearn.model_selection import cross_val_score\n",
    "        scores = cross_val_score(self.ols, X.iloc[:, self.subset], np.ravel(y), cv=cv, scoring='neg_mean_absolute_error')\n",
    "        return -1*np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Fit forward selection on 51 predicotrs and print index of chosen predictors.\n",
    "\n",
    "fwd = forward()\n",
    "fwd.fit(data_s[predictors2], data_s['LogSalePrice'])\n",
    "forwardselection(data_s[predictors2],data_s['LogSalePrice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Copy and paste index from above output and run through loop to extract predictor names.\n",
    "#Name chosen list of predictors to be predictors_fw\n",
    "\n",
    "fwd_predictors_index = [0,2,1,19,10,3,30,24,40,15,12,29,25,9,11,42,47,14,36,20,5]\n",
    " \n",
    "predictors_fw = []\n",
    "for i in fwd_predictors_index:\n",
    "    predictors_fw.append(predictors2[i])\n",
    "print(predictors_fw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ridge CV to select shrinkage.\n",
    "\n",
    "from sklearn.linear_model import RidgeCV\n",
    "alphas = np.exp(np.linspace(-10,20,500)) \n",
    "ridge = RidgeCV(alphas=alphas, cv=5)\n",
    "ridge.fit(data_s[predictors_fw], np.ravel(data_s['LogSalePrice']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ratio of Ridge to OLS coefficients of forward selected predictors.\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "ols3 = LinearRegression()\n",
    "ols3.fit(data_s[predictors_fw],data_s['LogSalePrice'])\n",
    "print(round(np.linalg.norm(ridge.coef_)/np.linalg.norm(np.ravel(ols3.coef_)), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit Ridge on forward selected predictors.\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "ridge_fw = Ridge(alpha=ridge.alpha_)\n",
    "ridge_fw.fit(data_s[predictors_fw], np.ravel(data_s['LogSalePrice']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display ridge coefficients\n",
    "\n",
    "pd.set_option('display.max_columns',50)\n",
    "pd.DataFrame(ridge_fw.coef_.round(5), index = predictors_fw).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate Ridge MAE CV on LogSalePrice\n",
    "\n",
    "scores_ridge = cross_val_score(ridge_fw, data_s[predictors_fw], np.ravel(data_s['LogSalePrice']), \n",
    "                               cv=10, scoring = 'neg_mean_absolute_error')\n",
    "cv_mae_ridge = np.mean(-1*scores_ridge)\n",
    "cv_mae_ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Residual plot of Ridge with forward selection\n",
    "\n",
    "ridge_fw.fit(data_s[predictors2], data_s['LogSalePrice'])\n",
    "y_fit = ridge_fw.predict(data_s[predictors2])\n",
    "y_actual = data_s['LogSalePrice']\n",
    "residuals = y_fit-y_actual\n",
    "abs_residuals = abs(residuals)\n",
    "\n",
    "fig, ax= plt.subplots(1,2, figsize=(13,5))\n",
    "sns.regplot(y_fit, residuals, fit_reg=False, ax=ax[0], scatter_kws={'alpha':0.5})\n",
    "ax[0].set_xlabel('Fitted values')\n",
    "ax[0].set_ylabel('Residuals')\n",
    "ax[0].set(title='Residuals vs Fitted Values')\n",
    "sns.regplot(y_fit, abs_residuals, fit_reg=False, ax=ax[1], scatter_kws={'alpha':0.5, 'color': sns.color_palette()[0]})\n",
    "ax[1].set_xlabel('Fitted values')\n",
    "ax[1].set_ylabel('Absolute residuals')\n",
    "ax[1].set(title='Absolute residuals vs Fitted Values')\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "#fig.savefig('residuals_ridge_with_fwd.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Correlation heatmap on forward selected predictors to see relationships and check for perfect multicollinearity.\n",
    "\n",
    "data_num[predictors_fw].corr().round(4)\n",
    "fig, ax = plt.subplots(figsize = (14,14))\n",
    "cmap = sns.diverging_palette(220,10,as_cmap=True)\n",
    "sns.heatmap(data_num[predictors_fw].corr(), ax=ax, cmap=cmap)\n",
    "ax.set(title='Correlation heatmap for variables used in ridge regression (selected by forward selection)')\n",
    "#fig.savefig('Correlation heatmap ridge.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ElasticNet (Submission 19, MAE = 13280.37)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select ENet shrinkage\n",
    "\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "enet = ElasticNetCV(l1_ratio=[0.01,0.05,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.95,0.99], cv=5)\n",
    "enet.fit(data_s[predictors2],np.ravel(data_s['LogSalePrice']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit ENet model on 51 predictors\n",
    "\n",
    "from sklearn.linear_model import ElasticNet\n",
    "enet = ElasticNet(alpha=enet.alpha_, l1_ratio=enet.l1_ratio_)\n",
    "enet.fit(data_s[predictors2],np.ravel(data_s['LogSalePrice']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ratio of ENet coefficients to OLS coefficients.\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "ols4 = LinearRegression()\n",
    "ols4.fit(data_s[predictors2],data_s['LogSalePrice'])\n",
    "print(round(np.linalg.norm(enet.coef_)/np.linalg.norm(np.ravel(ols4.coef_)), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display ENet coefficients.\n",
    "\n",
    "pd.set_option('display.max_columns',51)\n",
    "pd.DataFrame(enet.coef_.round(5), index = predictors2).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#List of ENet predictors.\n",
    "\n",
    "enet_pred = ['OverallQual', 'BsmtSF_Qual', 'GrLivArea', 'GarageCars', 'GarageArea', \n",
    "           'BsmtQual', 'TotalBsmtSF', 'KitchenQual', 'AgeHouse', 'FireplaceQu', \n",
    "          'Neighborhood_St_No_NHt','HeatingQC','GarageType_Attchd', 'BsmtFinSF1', \n",
    "          'Neighborhood_Old_Ed_SW_Brk', 'CentralAir_Y', 'PavedDrive_Y', 'Exterior2nd_VinylSd',\n",
    "          'GarageQual', 'BsmtExposure', 'MSZoning_RM', 'GarageFinish_Fin', 'LotShape_Reg',\n",
    "          'MSSubClass_30','Electrical_SBrkr','LotArea', 'Neighborhood_Gr_CC_So_Ti', 'Neighborhood_Sa_NA_Bl_NP',\n",
    "          'Neighborhood_Gi_NWA_Cr_Co', 'Neighborhood_BrD_IDO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To calculate ENet MAE CV on LogSalePrice\n",
    "\n",
    "scores_enet = cross_val_score(enet, data_s[predictors2], np.ravel(data_s['LogSalePrice']), \n",
    "                               cv=10, scoring = 'neg_mean_absolute_error')\n",
    "cv_mae_enet = np.mean(-1*scores_enet)\n",
    "cv_mae_enet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Residual plots of Elastic net\n",
    "\n",
    "enet.fit(data_s[predictors2], data_s['LogSalePrice'])\n",
    "y_fit = enet.predict(data_s[predictors2])\n",
    "y_actual = data_s['LogSalePrice']\n",
    "residuals = y_fit-y_actual\n",
    "abs_residuals = abs(residuals)\n",
    "\n",
    "fig, ax= plt.subplots(1,2, figsize=(13,5))\n",
    "sns.regplot(y_fit, residuals, fit_reg=False, ax=ax[0], scatter_kws={'alpha':0.5})\n",
    "ax[0].set_xlabel('Fitted values')\n",
    "ax[0].set_ylabel('Residuals')\n",
    "ax[0].set(title='Residuals vs Fitted Values')\n",
    "sns.regplot(y_fit, abs_residuals, fit_reg=False, ax=ax[1], scatter_kws={'alpha':0.5, 'color': sns.color_palette()[0]})\n",
    "ax[1].set_xlabel('Fitted values')\n",
    "ax[1].set_ylabel('Absolute residuals')\n",
    "ax[1].set(title='Absolute residuals vs Fitted Values')\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "#fig.savefig('residuals_enet.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Heatmap of ENet predictors.\n",
    "\n",
    "data_num[enet_pred].corr().round(4)\n",
    "fig, ax = plt.subplots(figsize = (14,14))\n",
    "cmap = sns.diverging_palette(220,10,as_cmap=True)\n",
    "sns.heatmap(data_num[enet_pred].corr(), ax=ax, cmap=cmap)\n",
    "ax.set(title='Correlation heatmap for variables used in elastic net')\n",
    "#fig.savefig('Correlation heatmap enet.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCR with Forward Selection (Submission 22, MAE = 20918.68)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#PCR algorithms taken from Marcel's QBUS2820 file and edited for MAE.\n",
    "\n",
    "class PCR:\n",
    "    def __init__(self, M=1):\n",
    "        self.M=M\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        from sklearn.decomposition import PCA\n",
    "        from sklearn.linear_model import LinearRegression\n",
    "        \n",
    "        self.pca=PCA(n_components=self.M)\n",
    "        Z= self.pca.fit_transform(X)\n",
    "        self.pcr = LinearRegression().fit(Z, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.pcr.predict(self.pca.transform(X))\n",
    "\n",
    "    def cv_score(self, X, y, cv=10):\n",
    "        from sklearn.model_selection import cross_val_score\n",
    "        Z=self.pca.transform(X)\n",
    "        scores = cross_val_score(self.pcr, Z, np.ravel(y), cv=cv, scoring='neg_mean_absolute_error').mean() \n",
    "        return -1*np.mean(scores)\n",
    "\n",
    "\n",
    "def pcrCV(X, y):\n",
    "    # Approximate cross-validation\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    \n",
    "    p=X.shape[1]\n",
    "    bestscore= -np.inf\n",
    "    cv_scores = []\n",
    "    for m in range(1,p+1):\n",
    "        model = PCR(M=m)\n",
    "        model.fit(X, y)\n",
    "        Z=model.pca.transform(X)\n",
    "        score = cross_val_score(model.pcr, Z, y, cv=10, scoring='neg_mean_absolute_error').mean() \n",
    "        cv_scores.append(score)\n",
    "        if score > bestscore:\n",
    "            bestscore=score\n",
    "            best=model\n",
    "\n",
    "    best.cv_scores = pd.Series(cv_scores, index = np.arange(1,p+1))\n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Fit PCR model.\n",
    "pcr = pcrCV(data_s[predictors_fw],data_s['LogSalePrice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To calculate PCR MAE CV on LogSalePrice.\n",
    "\n",
    "cv_score_pcr = pcr.cv_score(data_s[predictors_fw], np.ravel(data_s['LogSalePrice']), cv=10)\n",
    "cv_score_pcr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Residual plot of PCR\n",
    "\n",
    "pcr.fit(data_s[predictors2], data_s['LogSalePrice'])\n",
    "y_fit = pcr.predict(data_s[predictors2])\n",
    "y_actual = data_s['LogSalePrice']\n",
    "residuals = y_fit-y_actual\n",
    "abs_residuals = abs(residuals)\n",
    "\n",
    "fig, ax= plt.subplots(1,2, figsize=(13,5))\n",
    "sns.regplot(y_fit, residuals, fit_reg=False, ax=ax[0], scatter_kws={'alpha':0.5})\n",
    "ax[0].set_xlabel('Fitted values')\n",
    "ax[0].set_ylabel('Residuals')\n",
    "ax[0].set(title='Residuals vs Fitted Values')\n",
    "sns.regplot(y_fit, abs_residuals, fit_reg=False, ax=ax[1], scatter_kws={'alpha':0.5, 'color': sns.color_palette()[0]})\n",
    "ax[1].set_xlabel('Fitted values')\n",
    "ax[1].set_ylabel('Absolute residuals')\n",
    "ax[1].set(title='Absolute residuals vs Fitted Values')\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "#fig.savefig('residuals_pcr.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN (Submission 23, MAE = 52483.60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define KNN algorithm and combine with forward selection.\n",
    "\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def knn_test(X, y):\n",
    "    \n",
    "    neighbours=np.arange(1, 40)\n",
    "    best_score = -np.inf\n",
    "    \n",
    "    for k in neighbours: \n",
    "        knn = KNeighborsRegressor(n_neighbors = k, metric='mahalanobis', metric_params={'V': X.cov()}) \n",
    "        scores = cross_val_score(knn, X, y, cv=10, scoring = 'neg_mean_absolute_error')\n",
    "        cv_score = np.mean(scores)\n",
    "        if cv_score >= best_score:\n",
    "            best_score = cv_score\n",
    "            best_knn = knn\n",
    "    \n",
    "    knn = best_knn\n",
    "    knn.fit(X, y)\n",
    "    #predictions = knn.predict(test[predictors])\n",
    "    #test_rmse = np.sqrt(mean_squared_error(test[response], predictions))\n",
    "    #cv_rmse= np.sqrt(-best_score)\n",
    "    cv_mae = -best_score\n",
    "    print('Chosen K: {}'.format(knn.n_neighbors))\n",
    "    #return test_rmse, cv_rmse \n",
    "    return cv_mae, knn\n",
    "\n",
    "def select_knn(X, y):\n",
    "    \"\"\"Forward variable selection based on the Scikit learn API\n",
    "    \n",
    "    \n",
    "    Output:\n",
    "    ----------------------------------------------------------------------------------\n",
    "    Scikit learn knn regression object for the best model\n",
    "    \"\"\"\n",
    "\n",
    "    # Functions\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "\n",
    "    # Initialisation\n",
    "    base = []\n",
    "    p = X.shape[1]\n",
    "    candidates = list(np.arange(p))\n",
    "\n",
    "    # Forward recursion\n",
    "    i=1\n",
    "    bestcvscore=-np.inf    \n",
    "    while i<=p:\n",
    "        bestscore = 0\n",
    "        for variable in candidates:\n",
    "            score,knn = knn_test(X.iloc[:, base + [variable]], y)\n",
    "            #knn.fit(X.iloc[:, base + [variable]], y)\n",
    "            #score = knn.score(X.iloc[:, base + [variable]], y)\n",
    "            if score > bestscore:\n",
    "                bestscore = score \n",
    "                best = knn\n",
    "                newvariable=variable\n",
    "        base.append(newvariable)\n",
    "        candidates.remove(newvariable)\n",
    "        \n",
    "        cvscore = cross_val_score(best, X.iloc[:, base], y, scoring='neg_mean_absolute_error').mean() \n",
    "        \n",
    "        if cvscore > bestcvscore:\n",
    "            bestcvscore=cvscore\n",
    "            bestcv = best\n",
    "            subset = base[:]\n",
    "        i+=1\n",
    "    bestcv_mae = -bestcvscore\n",
    "    #Finalise\n",
    "    return bestcv, bestcv_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Show correlations to have some initial KNN predictors.\n",
    "\n",
    "pd.set_option('display.max_rows',300)\n",
    "abs_correl = abs(data_num.corr().round(3)['LogSalePrice'])\n",
    "abs_correl_sort = abs_correl.sort_values(ascending=False)\n",
    "abs_correl_sort.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "abs_correl_sort.head(20).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create list of KNN predictors.\n",
    "#Use the top correlated prodictors\n",
    "#Keep some intersction terms and processsed terms rather than the original terms, because they contains more information.\n",
    "\n",
    "predictors_knn = ['OverallQual', 'BsmtSF_Qual','GrLivArea', 'GarageArea_Cars', 'ExterQual', 'AgeHouse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Correlation heatmap.\n",
    "\n",
    "data_num[predictors_knn].corr().round(4)\n",
    "fig, ax = plt.subplots(figsize = (10,10))\n",
    "cmap = sns.diverging_palette(220,10,as_cmap=True)\n",
    "sns.heatmap(data_num[predictors_knn].corr(), ax=ax, cmap=cmap)\n",
    "ax.set(title='Correlation heatmap for variables used in KNN')\n",
    "#fig.savefig('correlation_knn.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create copy to standardize\n",
    "data_k = data_num.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Standardize data.\n",
    "\n",
    "sigma=data_k[predictors_knn].std()\n",
    "data_k[predictors_knn]=data_k[predictors_knn]/(2*sigma) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Run KNN forward selection algorithm and fit model.\n",
    "\n",
    "knn,bestcv_mae = select_knn(data_k[predictors_knn],data_k['LogSalePrice'])\n",
    "print(knn)\n",
    "print(bestcv_mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import validation set\n",
    "\n",
    "data_v = pd.read_csv('test.csv')\n",
    "data_v.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Do all the same data manipulation/processing changes as with the train data!!\n",
    "\n",
    "#Convert to string type\n",
    "\n",
    "data_v['MSSubClass'] = data_v['MSSubClass'].astype(str)\n",
    "data_v['MoSold'] = data_v['MoSold'].astype(str)\n",
    "\n",
    "#Fill object type blanks with NA one by one for record purposes\n",
    "\n",
    "data_v['LotFrontage'] = data_v['LotFrontage'].fillna(0)\n",
    "data_v['Alley'] = data_v['Alley'].fillna('NA')\n",
    "data_v['BsmtQual'] = data_v['BsmtQual'].fillna('NA')\n",
    "data_v['BsmtCond'] = data_v['BsmtCond'].fillna('NA')\n",
    "data_v['BsmtExposure'] = data_v['BsmtExposure'].fillna('NA')\n",
    "data_v['BsmtFinType1'] = data_v['BsmtFinType1'].fillna('NA')\n",
    "data_v['BsmtFinType2'] = data_v['BsmtFinType2'].fillna('NA')\n",
    "data_v['FireplaceQu'] = data_v['FireplaceQu'].fillna('NA')\n",
    "data_v['GarageType'] = data_v['GarageType'].fillna('NA')\n",
    "data_v['GarageFinish'] = data_v['GarageFinish'].fillna('NA')\n",
    "data_v['GarageQual'] = data_v['GarageQual'].fillna('NA')\n",
    "data_v['GarageCond'] = data_v['GarageCond'].fillna('NA')\n",
    "data_v['PoolQC'] = data_v['PoolQC'].fillna('NA')\n",
    "data_v['Fence'] = data_v['Fence'].fillna('NA')\n",
    "data_v['MiscFeature'] = data_v['MiscFeature'].fillna('NA')\n",
    "data_v['MasVnrArea'] = data_v['MasVnrArea'].fillna(0)\n",
    "data_v['MasVnrType'] = data_v['MasVnrType'].fillna('None')\n",
    "data_v['BsmtFullBath'] = data_v['BsmtFullBath'].fillna(0)\n",
    "\n",
    "#Create age house and age garage to use in analysis\n",
    "\n",
    "data_v['AgeHouse'] = (data_v['YrSold'] - data_v['YearRemod/Add']).astype(float)\n",
    "data_v['AgeGarage'] = (data_v['YrSold'] - data_v['GarageYrBlt']).astype(float)\n",
    "\n",
    "#Delete year built, remodeled, and garage year built and fill blank AgeGarage with 0\n",
    "\n",
    "del data_v['YearBuilt']\n",
    "del data_v['YearRemod/Add']\n",
    "del data_v['GarageYrBlt']\n",
    "data_v['AgeGarage'] = data_v['AgeGarage'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Combine Neighborhood variables\n",
    "\n",
    "neighbor_combined = {'MeadowV':'MeadowV',\n",
    "                     'BrDale': 'BrD_IDO',\n",
    "                     'IDOTRR': 'BrD_IDO',\n",
    "                     'OldTown':'Old_Ed_SW_Brk',\n",
    "                     'Edwards':'Old_Ed_SW_Brk',\n",
    "                     'SWISU':'Old_Ed_SW_Brk',\n",
    "                     'BrkSide':'Old_Ed_SW_Brk',\n",
    "                     'Sawyer':'Sa_NA_Bl_NP',\n",
    "                     'NAmes':'Sa_NA_Bl_NP',\n",
    "                     'Blueste':'Sa_NA_Bl_NP',\n",
    "                     'NPkVill':'Sa_NA_Bl_NP',\n",
    "                     'Mitchel':'Mi_SaW,Bng',\n",
    "                     'SawyerW':'Mi_SaW,Bng',\n",
    "                     'Blmngtn':'Mi_SaW,Bng',\n",
    "                     'Gilbert':'Gi_NWA_Cr_Co',\n",
    "                     'NWAmes':'Gi_NWA_Cr_Co',\n",
    "                     'Crawfor':'Gi_NWA_Cr_Co',\n",
    "                     'CollgCr':'Gi_NWA_Cr_Co',\n",
    "                     'Greens':'Gr_CC_So_Ti',\n",
    "                     'ClearCr':'Gr_CC_So_Ti',\n",
    "                     'Somerst':'Gr_CC_So_Ti',\n",
    "                     'Timber':'Gr_CC_So_Ti',\n",
    "                     'Veenker':'Veenker',\n",
    "                     'StoneBr':'St_No_NHt',\n",
    "                     'NoRidge':'St_No_NHt',\n",
    "                     'NridgHt':'St_No_NHt'}\n",
    "data_v['Neighborhood'] = data_v['Neighborhood'].map(neighbor_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Convert quality ordinals to numerical\n",
    "\n",
    "exterqual_vals = {'Fa':1,'TA':2,'Gd':3,'Ex':4}\n",
    "data_v['ExterQual'] = data_v['ExterQual'].map(exterqual_vals).astype(int)\n",
    "\n",
    "bsmt_vals = {'NA':0,'Po':1,'Fa':2,'TA':3,'Gd':4,'Ex':5}\n",
    "data_v['BsmtQual'] = data_v['BsmtQual'].map(bsmt_vals).astype(int)\n",
    "\n",
    "bsmt_exp = {'NA':0,'No':1,'Mn':2,'Av':3,'Gd':4}\n",
    "data_v['BsmtExposure'] = data_v['BsmtExposure'].map(bsmt_exp).astype(int)\n",
    "\n",
    "kitchen_vals = {'Po':1,'Fa':2,'TA':3,'Gd':4,'Ex':5}\n",
    "data_v['KitchenQual'] = data_v['KitchenQual'].map(kitchen_vals).astype(int)\n",
    "\n",
    "fireplace_qual = {'NA':0,'Po':1,'Fa':2,'TA':3,'Gd':4,'Ex':5}\n",
    "data_v['FireplaceQu'] = data_v['FireplaceQu'].map(fireplace_qual).astype(int)\n",
    "\n",
    "garage_vals= {'NA':0,'Po':1,'Fa':2,'TA':3,'Gd':4,'Ex':5}\n",
    "data_v['GarageQual'] = data_v['GarageQual'].map(garage_vals).astype(int)\n",
    "\n",
    "heating_vals = {'Fa':1,'TA':2,'Gd':3,'Ex':4}\n",
    "data_v['HeatingQC'] = data_v['HeatingQC'].map(kitchen_vals).astype(int)\n",
    "\n",
    "garage_cond = {'NA':0,'Po':1,'Fa':2,'TA':3,'Gd':4,'Ex':5}\n",
    "data_v['GarageCond'] = data_v['GarageCond'].map(garage_cond).astype(int)\n",
    "\n",
    "bsmt_cond = {'NA':0,'Po':1,'Fa':2,'TA':3,'Gd':4,'Ex':5}\n",
    "data_v['BsmtCond'] = data_v['BsmtCond'].map(bsmt_cond).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create different lists by data type.\n",
    "\n",
    "columns_float_v = data_v.select_dtypes(['float64']).columns\n",
    "columns_int_v = data_v.select_dtypes(['int64']).columns\n",
    "columns_cat_v = data_v.select_dtypes(['object']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create dummy variables as before.\n",
    "\n",
    "columns_cat_v = list(columns_cat_v)\n",
    "for column in columns_cat_v:\n",
    "    data_v = pd.get_dummies(data_v, columns = [column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create interactions as before.\n",
    "\n",
    "data_v['BsmtSF_Qual'] = data_v['TotalBsmtSF']*data_v['BsmtQual']\n",
    "data_v['GarageArea_Qual'] = data_v['GarageArea']*data_v['GarageQual']\n",
    "data_v['GrLiv_Rooms'] = data_v['GrLivArea']*data_v['TotRmsAbvGrd']\n",
    "data_v['GarageArea_Cars'] = data_v['GarageArea']*data_v['GarageCars']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Standardize data for KNN.\n",
    "\n",
    "data_knn = data_v.copy()\n",
    "sigma=data_num[predictors_knn].std()\n",
    "data_knn[predictors_knn]=data_knn[predictors_knn]/(2*sigma) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardize data for all other methods.\n",
    "\n",
    "pred_float_v = data_v.select_dtypes(['float64']).columns\n",
    "pred_int_v = data_v.select_dtypes(['int64']).columns\n",
    "pred_dum_v = data_v.select_dtypes(['uint8']).columns\n",
    "\n",
    "mu_float = np.mean(data_num[pred_float])\n",
    "sigma_float = np.std(data_num[pred_float])\n",
    "\n",
    "mu_int = np.mean(data_num[pred_int])\n",
    "sigma_int = np.std(data_num[pred_int])\n",
    "\n",
    "mu_dum = np.mean(data_num[pred_dum])\n",
    "sigma_dum = np.std(data_num[pred_dum])\n",
    "\n",
    "data_v[pred_float] = (data_v[pred_float]-mu_float)/(2*sigma_float)\n",
    "data_v[pred_int] = (data_v[pred_int]-mu_int)/(2*sigma_int)\n",
    "data_v[pred_dum] = (data_v[pred_dum])/(sigma_dum)\n",
    "\n",
    "data_v.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predictions based on OLS model\n",
    "\n",
    "y_predict_ols = pd.DataFrame(np.exp(ols.predict(data_v[predictors1])))\n",
    "pd.set_option('display.max_rows', 1608)\n",
    "y_predict_ols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predictions based on Lasso model\n",
    "\n",
    "y_predict_lasso = pd.DataFrame(np.exp(lasso.predict(data_v[predictors2])))\n",
    "pd.set_option('display.max_rows', 1608)\n",
    "y_predict_lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predictions based on Forward + Ridge model\n",
    "\n",
    "y_predict_ridge = pd.DataFrame(np.exp(ridge_fw.predict(data_v[predictors2])))\n",
    "pd.set_option('display.max_rows', 1608)\n",
    "y_predict_ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predictions based on ENet model\n",
    "\n",
    "y_predict_enet = pd.DataFrame(np.exp(enet.predict(data_v[predictors2])))\n",
    "pd.set_option('display.max_rows', 1615)\n",
    "y_predict_enet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Predictions based on Forward + PCR model\n",
    "\n",
    "y_predict_pcr = pd.DataFrame(np.exp(pcr.predict(data_v[predictors2])))\n",
    "pd.set_option('display.max_rows', 1608)\n",
    "y_predict_pcr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Predictions based on KNN model\n",
    "\n",
    "y_predict_knn = pd.DataFrame(np.exp(knn.predict(data_knn[predictors_knn])))\n",
    "pd.set_option('display.max_rows', 1608)\n",
    "y_predict_knn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
