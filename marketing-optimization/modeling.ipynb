{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost-Benefit Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.805583693652594"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Define profits\n",
    "profit = .13*(np.mean(data['AVRG'])) #13% because profit margin of clothing stores\n",
    "profit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Assume cost is 1 (price of postage)\n",
    "TN = 0\n",
    "TP = -13.8\n",
    "FP = 1\n",
    "FN = 14.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03378378378378378"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Build cost-benefit matrix and calculate decision threshold tau\n",
    "benefit_cost=np.matrix([[TN, FP],[FN, TP]])\n",
    "benefit_cost\n",
    "tau = (FP - TN)/(FP + FN -TP - TN)\n",
    "tau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4348\n"
     ]
    }
   ],
   "source": [
    "#If we send mail to all the customers.\n",
    "y_pred_all=np.ones((len(test), 1))\n",
    "y_pred_no=np.zeros((len(test), 1))\n",
    "print(len(y_pred_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TN(0)</th>\n",
       "      <th>TP(-13.8)</th>\n",
       "      <th>FN(14.8)</th>\n",
       "      <th>FP(1)</th>\n",
       "      <th>Error rate</th>\n",
       "      <th>Total cost per customer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Send to all customers</th>\n",
       "      <td>0.0</td>\n",
       "      <td>731.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3617.0</td>\n",
       "      <td>0.832</td>\n",
       "      <td>-1.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Do not send to any customer</th>\n",
       "      <td>3617.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>731.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.168</td>\n",
       "      <td>2.49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              TN(0)  TP(-13.8)  FN(14.8)   FP(1)  Error rate  \\\n",
       "Send to all customers           0.0      731.0       0.0  3617.0       0.832   \n",
       "Do not send to any customer  3617.0        0.0     731.0     0.0       0.168   \n",
       "\n",
       "                             Total cost per customer  \n",
       "Send to all customers                          -1.49  \n",
       "Do not send to any customer                     2.49  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Build benchmark model table\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score, precision_score\n",
    "columns=['TN(0)', 'TP(-13.8)', 'FN(14.8)', 'FP(1)', 'Error rate', 'Total cost per customer']\n",
    "rows=['Send to all customers', 'Do not send to any customer']\n",
    "results=pd.DataFrame(0.0, columns=columns, index=rows) \n",
    "\n",
    "Confusion_all=confusion_matrix(test[response], y_pred_all)\n",
    "error_rate_all =  1 - accuracy_score(test[response], y_pred_all)\n",
    "formula1=Confusion_all[0,0]*benefit_cost[0,0]+Confusion_all[0,1]*benefit_cost[0,1]+Confusion_all[1,0]*benefit_cost[1,0]+Confusion_all[1,1]*benefit_cost[1,1]\n",
    "results.iloc[0,0]=  Confusion_all[0,0]\n",
    "results.iloc[0,1]=  Confusion_all[1,1]\n",
    "results.iloc[0,2]=  Confusion_all[1,0]\n",
    "results.iloc[0,3]=  Confusion_all[0,1]\n",
    "results.iloc[0,4]=  error_rate_all\n",
    "results.iloc[0,5]=  (formula1/len(test[response])).round(2)\n",
    "\n",
    "Confusion_no=confusion_matrix(test[response], y_pred_no)\n",
    "error_rate_no =  1 - accuracy_score(test[response], y_pred_no)\n",
    "formula2=Confusion_no[0,0]*benefit_cost[0,0]+Confusion_no[0,1]*benefit_cost[0,1]+Confusion_no[1,0]*benefit_cost[1,0]+Confusion_no[1,1]*benefit_cost[1,1]\n",
    "results.iloc[1,0]=  Confusion_no[0,0]\n",
    "results.iloc[1,1]=  Confusion_no[1,1]\n",
    "results.iloc[1,2]=  Confusion_no[1,0]\n",
    "results.iloc[1,3]=  Confusion_no[0,1]\n",
    "results.iloc[1,4]=  error_rate_no\n",
    "results.iloc[1,5]=  (formula2/len(test[response])).round(2)\n",
    "\n",
    "\n",
    "results.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegressionCV(Cs=10, class_weight=None, cv=None, dual=False,\n",
       "           fit_intercept=True, intercept_scaling=1.0, max_iter=100,\n",
       "           multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "           refit=True, scoring='neg_log_loss', solver='lbfgs', tol=0.0001,\n",
       "           verbose=0)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "# Logistic regression\n",
    "logit = LogisticRegression()\n",
    "logit.fit(train[predictors], train[response])\n",
    "\n",
    "# L-1 Regularised logistic regression\n",
    "logit1_l1 = LogisticRegressionCV(penalty='l1', solver='liblinear', scoring = 'neg_log_loss')\n",
    "logit1_l1.fit(train[predictors], train[response])\n",
    "\n",
    "# L-2 Regularised logistic regression\n",
    "logit1_l2 = LogisticRegressionCV(penalty='l2', scoring = 'neg_log_loss')\n",
    "logit1_l2.fit(train[predictors], train[response])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.392172\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.434724\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.426184\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.435654\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.434203\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.422526\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.427621\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.398614\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.400207\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.388114\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.404730\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.393551\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.346818\n",
      "         Iterations 7\n"
     ]
    }
   ],
   "source": [
    "Pred1=['MON','TOMONSPEND','OMONSPEND','STMONSPEND','PREVPD']\n",
    "for i in Pred1:\n",
    "    glm = sm.Logit(train[response], sm.add_constant(train[i])).fit()\n",
    "    #print(glm.summary())\n",
    "    \n",
    "Pred2=['PROMOS','MAILED','RESPONDED','RESPONSERATE']\n",
    "for i in Pred2:\n",
    "    glm = sm.Logit(train[response], sm.add_constant(train[i])).fit()\n",
    "    #print(glm.summary())\n",
    "\n",
    "Pred3=['CLASSES','HI','FREDAYS','LTFREDAY']\n",
    "for i in Pred3:\n",
    "    glm = sm.Logit(train[response], sm.add_constant(train[i])).fit()\n",
    "    #print(glm.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Remove binary variables for discriminant analysis\n",
    "gda_preds = predictors.copy()\n",
    "gda_preds.remove('CC_CARD')\n",
    "gda_preds.remove('WEB')\n",
    "gda_preds.remove('VALPHON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
       "               store_covariance=False, store_covariances=None, tol=0.0001)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit LDA and QDA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "lda.fit(train[gda_preds], train[response])\n",
    "\n",
    "qda = QuadraticDiscriminantAnalysis()\n",
    "qda.fit(train[gda_preds], train[response])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Cross validation for regularized QDA\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def qda_cv(X_train, y_train):\n",
    "    \n",
    "    alphas  = np.linspace(0, 1, 21)\n",
    "    best_score = -np.inf\n",
    "    \n",
    "    for alpha in alphas:\n",
    "        qda = QuadraticDiscriminantAnalysis(reg_param=alpha)\n",
    "        score = np.mean(cross_val_score(qda, X_train, y_train, cv=10, scoring = 'accuracy'))\n",
    "        if score >= best_score:\n",
    "            best = qda\n",
    "            best_score = score\n",
    "    \n",
    "    return qda.fit(X_train, y_train)\n",
    "        \n",
    "qda_reg = qda_cv(train[gda_preds], train[response]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "13044/13044 [==============================] - 0s - loss: 0.6334 - acc: 0.6594     \n",
      "Epoch 2/100\n",
      "13044/13044 [==============================] - 0s - loss: 0.4554 - acc: 0.7973     \n",
      "Epoch 3/100\n",
      "13044/13044 [==============================] - 0s - loss: 0.3973 - acc: 0.8316     \n",
      "Epoch 4/100\n",
      "13044/13044 [==============================] - 0s - loss: 0.3745 - acc: 0.8454     \n",
      "Epoch 5/100\n",
      "13044/13044 [==============================] - 0s - loss: 0.3637 - acc: 0.8497     \n",
      "Epoch 6/100\n",
      "13044/13044 [==============================] - 0s - loss: 0.3567 - acc: 0.8511     \n",
      "Epoch 7/100\n",
      "13044/13044 [==============================] - 0s - loss: 0.3515 - acc: 0.8522     \n",
      "Epoch 8/100\n",
      "13044/13044 [==============================] - 0s - loss: 0.3474 - acc: 0.8539     \n",
      "Epoch 9/100\n",
      "13044/13044 [==============================] - 0s - loss: 0.3435 - acc: 0.8543     \n",
      "Epoch 10/100\n",
      "13044/13044 [==============================] - 0s - loss: 0.3409 - acc: 0.8557     \n",
      "Epoch 11/100\n",
      "13044/13044 [==============================] - 0s - loss: 0.3378 - acc: 0.8561     \n",
      "Epoch 12/100\n",
      "13044/13044 [==============================] - 0s - loss: 0.3355 - acc: 0.8560     \n",
      "Epoch 13/100\n",
      "13044/13044 [==============================] - 0s - loss: 0.3335 - acc: 0.8568     \n",
      "Epoch 14/100\n",
      "13044/13044 [==============================] - 0s - loss: 0.3316 - acc: 0.8573     \n",
      "Epoch 15/100\n",
      "13044/13044 [==============================] - 0s - loss: 0.3299 - acc: 0.8586     \n",
      "Epoch 16/100\n",
      "13044/13044 [==============================] - 0s - loss: 0.3288 - acc: 0.8576     \n",
      "Epoch 17/100\n",
      "13044/13044 [==============================] - 0s - loss: 0.3274 - acc: 0.8592     \n",
      "Epoch 18/100\n",
      "13044/13044 [==============================] - 0s - loss: 0.3265 - acc: 0.8587     \n",
      "Epoch 19/100\n",
      "13044/13044 [==============================] - 0s - loss: 0.3255 - acc: 0.8586     \n",
      "Epoch 20/100\n",
      "13044/13044 [==============================] - 0s - loss: 0.3247 - acc: 0.8576     \n",
      "Epoch 21/100\n",
      "13044/13044 [==============================] - 0s - loss: 0.3241 - acc: 0.8599     \n",
      "Epoch 22/100\n",
      "13044/13044 [==============================] - 0s - loss: 0.3234 - acc: 0.8589     \n",
      "Epoch 23/100\n",
      "13044/13044 [==============================] - 0s - loss: 0.3227 - acc: 0.8587     \n",
      "Epoch 24/100\n",
      "13044/13044 [==============================] - 0s - loss: 0.3224 - acc: 0.8589     \n",
      "Epoch 25/100\n",
      "13044/13044 [==============================] - 0s - loss: 0.3216 - acc: 0.8587     \n",
      "Epoch 26/100\n",
      "13044/13044 [==============================] - 0s - loss: 0.3210 - acc: 0.8595     \n",
      "Epoch 27/100\n",
      "13044/13044 [==============================] - 0s - loss: 0.3208 - acc: 0.8591     \n",
      "Epoch 28/100\n",
      "13044/13044 [==============================] - 0s - loss: 0.3204 - acc: 0.8596     \n",
      "Epoch 29/100\n",
      "13044/13044 [==============================] - 0s - loss: 0.3200 - acc: 0.8600     \n",
      "Epoch 30/100\n",
      "13044/13044 [==============================] - 0s - loss: 0.3196 - acc: 0.8599     \n",
      "Epoch 31/100\n",
      "13044/13044 [==============================] - 0s - loss: 0.3194 - acc: 0.8599     \n",
      "Epoch 32/100\n",
      "13044/13044 [==============================] - 0s - loss: 0.3185 - acc: 0.8599     \n",
      "Epoch 33/100\n",
      "13044/13044 [==============================] - 0s - loss: 0.3188 - acc: 0.8589     \n",
      "Epoch 34/100\n",
      "13044/13044 [==============================] - 0s - loss: 0.3185 - acc: 0.8585     \n",
      "Epoch 35/100\n",
      "13044/13044 [==============================] - 0s - loss: 0.3183 - acc: 0.8589     \n",
      "Epoch 36/100\n",
      "13044/13044 [==============================] - 0s - loss: 0.3180 - acc: 0.8604     \n",
      "Epoch 37/100\n",
      "13044/13044 [==============================] - 0s - loss: 0.3178 - acc: 0.8596     \n",
      "Epoch 38/100\n",
      "13044/13044 [==============================] - 0s - loss: 0.3174 - acc: 0.8596     \n",
      "Epoch 39/100\n",
      "13044/13044 [==============================] - 0s - loss: 0.3172 - acc: 0.8595     \n",
      "Epoch 40/100\n",
      "13044/13044 [==============================] - 0s - loss: 0.3171 - acc: 0.8592     \n",
      "Epoch 41/100\n",
      "13044/13044 [==============================] - 0s - loss: 0.3169 - acc: 0.8598     \n",
      "Epoch 42/100\n",
      "13044/13044 [==============================] - 0s - loss: 0.3165 - acc: 0.8600     \n",
      "Epoch 43/100\n",
      "13044/13044 [==============================] - 0s - loss: 0.3164 - acc: 0.8604     \n",
      "Epoch 44/100\n",
      "13044/13044 [==============================] - 0s - loss: 0.3164 - acc: 0.8592     \n",
      "Epoch 45/100\n",
      "13044/13044 [==============================] - 0s - loss: 0.3159 - acc: 0.8592     \n",
      "Epoch 46/100\n",
      "13044/13044 [==============================] - 0s - loss: 0.3159 - acc: 0.8598     \n",
      "Epoch 47/100\n",
      "13044/13044 [==============================] - 0s - loss: 0.3156 - acc: 0.8597     \n",
      "Epoch 48/100\n",
      "13044/13044 [==============================] - 0s - loss: 0.3156 - acc: 0.8592     \n",
      "Epoch 49/100\n",
      "13044/13044 [==============================] - 0s - loss: 0.3154 - acc: 0.8598     \n",
      "Epoch 50/100\n",
      "13044/13044 [==============================] - 0s - loss: 0.3153 - acc: 0.8601     \n",
      "Epoch 51/100\n",
      "13044/13044 [==============================] - 0s - loss: 0.3151 - acc: 0.8608     \n",
      "Epoch 52/100\n",
      "13044/13044 [==============================] - 0s - loss: 0.3151 - acc: 0.8599     \n",
      "Epoch 53/100\n",
      "13044/13044 [==============================] - 0s - loss: 0.3148 - acc: 0.8611     \n",
      "Epoch 54/100\n",
      "13044/13044 [==============================] - 0s - loss: 0.3145 - acc: 0.8604     \n",
      "Epoch 55/100\n",
      "13044/13044 [==============================] - 0s - loss: 0.3141 - acc: 0.8599     \n",
      "Epoch 56/100\n",
      "13044/13044 [==============================] - 0s - loss: 0.3142 - acc: 0.8604     \n",
      "Epoch 57/100\n",
      "13044/13044 [==============================] - 0s - loss: 0.3142 - acc: 0.8606     \n",
      "Epoch 58/100\n",
      "13044/13044 [==============================] - 0s - loss: 0.3141 - acc: 0.8602     \n",
      "Epoch 59/100\n",
      "13044/13044 [==============================] - 0s - loss: 0.3140 - acc: 0.8610     \n",
      "Epoch 60/100\n",
      "13044/13044 [==============================] - 0s - loss: 0.3138 - acc: 0.8602     \n",
      "Epoch 61/100\n",
      "13044/13044 [==============================] - 0s - loss: 0.3137 - acc: 0.8614     \n",
      "Epoch 62/100\n",
      "13044/13044 [==============================] - 0s - loss: 0.3139 - acc: 0.8607     \n",
      "Epoch 63/100\n",
      "13044/13044 [==============================] - 0s - loss: 0.3136 - acc: 0.8609     \n",
      "Epoch 64/100\n",
      "13044/13044 [==============================] - 0s - loss: 0.3134 - acc: 0.8614     \n",
      "Epoch 65/100\n",
      "13044/13044 [==============================] - 0s - loss: 0.3132 - acc: 0.8619     \n",
      "Epoch 66/100\n",
      "13044/13044 [==============================] - 0s - loss: 0.3134 - acc: 0.8615     \n",
      "Epoch 67/100\n",
      "13044/13044 [==============================] - 0s - loss: 0.3133 - acc: 0.8615     \n",
      "Epoch 68/100\n",
      "13044/13044 [==============================] - 0s - loss: 0.3132 - acc: 0.8619     \n",
      "Epoch 69/100\n",
      "13044/13044 [==============================] - 0s - loss: 0.3130 - acc: 0.8609     \n",
      "Epoch 70/100\n",
      "13044/13044 [==============================] - 0s - loss: 0.3130 - acc: 0.8610     \n",
      "Epoch 71/100\n",
      "13044/13044 [==============================] - 0s - loss: 0.3127 - acc: 0.8607     \n",
      "Epoch 72/100\n",
      "13044/13044 [==============================] - 0s - loss: 0.3125 - acc: 0.8615     \n",
      "Epoch 73/100\n",
      "13044/13044 [==============================] - 0s - loss: 0.3127 - acc: 0.8619     \n",
      "Epoch 74/100\n",
      "13044/13044 [==============================] - 0s - loss: 0.3125 - acc: 0.8611     \n",
      "Epoch 75/100\n",
      "13044/13044 [==============================] - 0s - loss: 0.3123 - acc: 0.8622     \n",
      "Epoch 76/100\n",
      "13044/13044 [==============================] - 0s - loss: 0.3122 - acc: 0.8620     \n",
      "Epoch 77/100\n",
      "13044/13044 [==============================] - 0s - loss: 0.3121 - acc: 0.8615     \n",
      "Epoch 78/100\n",
      "13044/13044 [==============================] - 0s - loss: 0.3122 - acc: 0.8602     \n",
      "Epoch 79/100\n",
      "13044/13044 [==============================] - 0s - loss: 0.3116 - acc: 0.8623     \n",
      "Epoch 80/100\n",
      "13044/13044 [==============================] - 0s - loss: 0.3121 - acc: 0.8619     \n",
      "Epoch 81/100\n",
      "13044/13044 [==============================] - 0s - loss: 0.3119 - acc: 0.8608     \n",
      "Epoch 82/100\n",
      "13044/13044 [==============================] - 0s - loss: 0.3116 - acc: 0.8614     \n",
      "Epoch 83/100\n",
      "13044/13044 [==============================] - 0s - loss: 0.3115 - acc: 0.8612     \n",
      "Epoch 84/100\n",
      "13044/13044 [==============================] - 0s - loss: 0.3118 - acc: 0.8616     \n",
      "Epoch 85/100\n",
      "13044/13044 [==============================] - 0s - loss: 0.3116 - acc: 0.8618     \n",
      "Epoch 86/100\n",
      "13044/13044 [==============================] - 0s - loss: 0.3115 - acc: 0.8621     \n",
      "Epoch 87/100\n",
      "13044/13044 [==============================] - 0s - loss: 0.3112 - acc: 0.8621     \n",
      "Epoch 88/100\n",
      "13044/13044 [==============================] - 0s - loss: 0.3113 - acc: 0.8622     \n",
      "Epoch 89/100\n",
      "13044/13044 [==============================] - 0s - loss: 0.3112 - acc: 0.8612     \n",
      "Epoch 90/100\n",
      "13044/13044 [==============================] - 0s - loss: 0.3112 - acc: 0.8609     \n",
      "Epoch 91/100\n",
      "13044/13044 [==============================] - 0s - loss: 0.3109 - acc: 0.8619     \n",
      "Epoch 92/100\n",
      "13044/13044 [==============================] - 0s - loss: 0.3111 - acc: 0.8615     \n",
      "Epoch 93/100\n",
      "13044/13044 [==============================] - 0s - loss: 0.3109 - acc: 0.8621     \n",
      "Epoch 94/100\n",
      "13044/13044 [==============================] - 0s - loss: 0.3107 - acc: 0.8628     \n",
      "Epoch 95/100\n",
      "13044/13044 [==============================] - 0s - loss: 0.3107 - acc: 0.8625     \n",
      "Epoch 96/100\n",
      "13044/13044 [==============================] - 0s - loss: 0.3107 - acc: 0.8625     \n",
      "Epoch 97/100\n",
      "13044/13044 [==============================] - 0s - loss: 0.3105 - acc: 0.8625     \n",
      "Epoch 98/100\n",
      "13044/13044 [==============================] - 0s - loss: 0.3102 - acc: 0.8622     \n",
      "Epoch 99/100\n",
      "13044/13044 [==============================] - 0s - loss: 0.3104 - acc: 0.8619     \n",
      "Epoch 100/100\n",
      "13044/13044 [==============================] - 0s - loss: 0.3104 - acc: 0.8619     \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 25)                650       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 26        \n",
      "=================================================================\n",
      "Total params: 676\n",
      "Trainable params: 676\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "CPU times: user 14.6 s, sys: 4.52 s, total: 19.1 s\n",
      "Wall time: 30.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Build a basic neural network with one hidden layer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "\n",
    "np.random.seed(0)\n",
    "nn = Sequential()\n",
    "nn.add(Dense(25, input_dim = len(predictors), activation = 'relu'))\n",
    "nn.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "nn.compile(loss = 'binary_crossentropy', optimizer = 'rmsprop', metrics = ['accuracy'])\n",
    "nn.fit(np.array(train[predictors]), np.array(train[response]), epochs = 100, batch_size =  500)\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.85 s, sys: 177 ms, total: 7.02 s\n",
      "Wall time: 3min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Cross validation for a random forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "model = RandomForestClassifier(criterion = 'entropy', n_estimators = 120, random_state = 0)\n",
    "tuning_params = {'min_samples_leaf':[1,5,10],\n",
    "                 'max_features':np.arange(1,len(predictors)+1),}\n",
    "\n",
    "rf = RandomizedSearchCV(model, tuning_params, cv = 5, return_train_score = False, n_jobs = 4, scoring = 'neg_log_loss')\n",
    "rf.fit(train[predictors], train[response])\n",
    "rf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_features': 9, 'min_samples_leaf': 10}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.08526612,  0.05974159,  0.01576427,  0.04658457,  0.02851964,\n",
       "        0.00942867,  0.31849963,  0.01234955,  0.03711391,  0.03611594,\n",
       "        0.00431177,  0.0704613 ,  0.04273769,  0.02391378,  0.01595033,\n",
       "        0.01159466,  0.02542825,  0.0582555 ,  0.01137625,  0.00128074,\n",
       "        0.00566047,  0.00163928,  0.02943836,  0.02054666,  0.02802107])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Feature importance for random forest\n",
    "rf = RandomForestClassifier(criterion = 'entropy', n_estimators = 120, random_state = 0, min_samples_leaf = 10, max_features = 9)\n",
    "rf.fit(train[predictors],train[response])\n",
    "rf.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Fit naive bayes model\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "def nb_cv(X_train, y_train):\n",
    "    \n",
    "    alphas  = np.linspace(0, 1, 21)\n",
    "    best_score = -np.inf\n",
    "    \n",
    "    for alpha in alphas:\n",
    "        nbc = BernoulliNB(alpha=alpha)\n",
    "        score = np.mean(cross_val_score(nbc, X_train, y_train, cv=10, scoring = 'neg_log_loss'))\n",
    "        if score >= best_score:\n",
    "            best = nbc\n",
    "            best_score = score\n",
    "    \n",
    "    return nbc.fit(X_train, y_train)\n",
    "\n",
    "nbc = nb_cv(train[predictors],train[response])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight='balanced', coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit support vector machines model\n",
    "from sklearn.svm import SVC\n",
    "sv = SVC(class_weight = 'balanced', probability = True)\n",
    "sv.fit(train[predictors],train[response])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Fit on Validation Set for Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Error rate</th>\n",
       "      <th>SE</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>FNR</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Cost</th>\n",
       "      <th>Lower Bound 95% CI</th>\n",
       "      <th>Upper Bound 95% CI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Support Vector Machines</th>\n",
       "      <td>0.543</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.351</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.847</td>\n",
       "      <td>0.232</td>\n",
       "      <td>-1.68</td>\n",
       "      <td>-1.692</td>\n",
       "      <td>-1.668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.515</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.983</td>\n",
       "      <td>0.386</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.855</td>\n",
       "      <td>0.242</td>\n",
       "      <td>-1.70</td>\n",
       "      <td>-1.712</td>\n",
       "      <td>-1.688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naive Bayes</th>\n",
       "      <td>0.298</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.758</td>\n",
       "      <td>0.691</td>\n",
       "      <td>0.242</td>\n",
       "      <td>0.797</td>\n",
       "      <td>0.328</td>\n",
       "      <td>-0.88</td>\n",
       "      <td>-0.891</td>\n",
       "      <td>-0.869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic</th>\n",
       "      <td>0.530</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.989</td>\n",
       "      <td>0.367</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.237</td>\n",
       "      <td>-1.71</td>\n",
       "      <td>-1.722</td>\n",
       "      <td>-1.698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L1 regularised</th>\n",
       "      <td>0.532</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.989</td>\n",
       "      <td>0.364</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.237</td>\n",
       "      <td>-1.71</td>\n",
       "      <td>-1.722</td>\n",
       "      <td>-1.698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L2 regularised</th>\n",
       "      <td>0.530</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.989</td>\n",
       "      <td>0.366</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.237</td>\n",
       "      <td>-1.71</td>\n",
       "      <td>-1.722</td>\n",
       "      <td>-1.698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LDA</th>\n",
       "      <td>0.519</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.380</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.241</td>\n",
       "      <td>-1.71</td>\n",
       "      <td>-1.722</td>\n",
       "      <td>-1.698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QDA</th>\n",
       "      <td>0.239</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.665</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.335</td>\n",
       "      <td>0.819</td>\n",
       "      <td>0.376</td>\n",
       "      <td>-0.52</td>\n",
       "      <td>-0.531</td>\n",
       "      <td>-0.509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Regularised QDA</th>\n",
       "      <td>0.267</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.694</td>\n",
       "      <td>0.741</td>\n",
       "      <td>0.306</td>\n",
       "      <td>0.801</td>\n",
       "      <td>0.348</td>\n",
       "      <td>-0.62</td>\n",
       "      <td>-0.631</td>\n",
       "      <td>-0.609</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Error rate     SE  Sensitivity  Specificity    FNR  \\\n",
       "Support Vector Machines       0.543  0.008        0.986        0.351  0.014   \n",
       "Random Forest                 0.515  0.008        0.983        0.386  0.017   \n",
       "Naive Bayes                   0.298  0.007        0.758        0.691  0.242   \n",
       "Logistic                      0.530  0.008        0.989        0.367  0.011   \n",
       "L1 regularised                0.532  0.008        0.989        0.364  0.011   \n",
       "L2 regularised                0.530  0.008        0.989        0.366  0.011   \n",
       "LDA                           0.519  0.008        0.986        0.380  0.014   \n",
       "QDA                           0.239  0.006        0.665        0.780  0.335   \n",
       "Regularised QDA               0.267  0.007        0.694        0.741  0.306   \n",
       "\n",
       "                           AUC  Precision  Cost  Lower Bound 95% CI  \\\n",
       "Support Vector Machines  0.847      0.232 -1.68              -1.692   \n",
       "Random Forest            0.855      0.242 -1.70              -1.712   \n",
       "Naive Bayes              0.797      0.328 -0.88              -0.891   \n",
       "Logistic                 0.857      0.237 -1.71              -1.722   \n",
       "L1 regularised           0.857      0.237 -1.71              -1.722   \n",
       "L2 regularised           0.857      0.237 -1.71              -1.722   \n",
       "LDA                      0.857      0.241 -1.71              -1.722   \n",
       "QDA                      0.819      0.376 -0.52              -0.531   \n",
       "Regularised QDA          0.801      0.348 -0.62              -0.631   \n",
       "\n",
       "                         Upper Bound 95% CI  \n",
       "Support Vector Machines              -1.668  \n",
       "Random Forest                        -1.688  \n",
       "Naive Bayes                          -0.869  \n",
       "Logistic                             -1.698  \n",
       "L1 regularised                       -1.698  \n",
       "L2 regularised                       -1.698  \n",
       "LDA                                  -1.698  \n",
       "QDA                                  -0.509  \n",
       "Regularised QDA                      -0.609  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit all models on validation set for selection except neural networks\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score, precision_score\n",
    "\n",
    "columns=['Error rate', 'SE', 'Sensitivity', 'Specificity', 'FNR','AUC', 'Precision','Cost','Lower Bound 95% CI','Upper Bound 95% CI']\n",
    "rows=['Support Vector Machines','Random Forest','Naive Bayes','Logistic', 'L1 regularised', 'L2 regularised', 'LDA', 'QDA', 'Regularised QDA']\n",
    "results=pd.DataFrame(0.0, columns=columns, index=rows) \n",
    "\n",
    "methods=[sv, rf, nbc, logit, logit1_l1, logit1_l2, lda, qda, qda_reg]\n",
    "\n",
    "for i, method in enumerate(methods):\n",
    "    \n",
    "    if i >= 6: \n",
    "        y_prob = method.predict_proba(validate[gda_preds])\n",
    "        y_pred = np.array(((pd.DataFrame(y_prob)).iloc[:,1] > tau).astype(int))\n",
    "    else:\n",
    "        y_prob = (method.predict_proba(validate[predictors]))\n",
    "        y_pred = np.array(((pd.DataFrame(y_prob)).iloc[:,1] > tau).astype(int))\n",
    "    \n",
    "    Confusion  = confusion_matrix(validate[response], y_pred) \n",
    "    tn, fp, fn, tp = Confusion.ravel()\n",
    "    error_rate =  1 - accuracy_score(validate[response], y_pred)\n",
    "    formula2=((tn*benefit_cost[0,0]+fp*benefit_cost[0,1]+fn*benefit_cost[1,0]+tp*benefit_cost[1,1])/len(validate[response])).round(2)\n",
    "    se = np.sqrt(error_rate*(1- error_rate)/len(validate[response]))\n",
    "    \n",
    "    results.iloc[i,0] = error_rate\n",
    "    results.iloc[i,1] = se\n",
    "    results.iloc[i,2] = Confusion[1,1]/float(np.sum(Confusion[1,:]))\n",
    "    results.iloc[i,3] = Confusion[0,0]/float(np.sum(Confusion[0,:]))\n",
    "    results.iloc[i,4] = fn/float(tp+fn)\n",
    "    results.iloc[i,5] = roc_auc_score(validate[response], y_prob[:,1])\n",
    "    results.iloc[i,6] = precision_score(validate[response], y_pred)\n",
    "    results.iloc[i,7] = formula2\n",
    "    results.iloc[i,8] = formula2 - se*stats.t.ppf(0.95, df = len(validate[response])-1)\n",
    "    results.iloc[i,9] = formula2 + se*stats.t.ppf(0.95, df = len(validate[response])-1)\n",
    "\n",
    "results.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Fit Neural Network on Validation Set for Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3136/4348 [====================>.........] - ETA: 0s"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Error rate</th>\n",
       "      <th>SE</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>FNR</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Cost</th>\n",
       "      <th>Lower Bount 95% CI</th>\n",
       "      <th>Upper Bound 95% CI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Neural Networks</th>\n",
       "      <td>0.466</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.976</td>\n",
       "      <td>0.446</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.26</td>\n",
       "      <td>-1.72</td>\n",
       "      <td>-1.732</td>\n",
       "      <td>-1.708</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Error rate     SE  Sensitivity  Specificity    FNR    AUC  \\\n",
       "Neural Networks       0.466  0.008        0.976        0.446  0.024  0.857   \n",
       "\n",
       "                 Precision  Cost  Lower Bount 95% CI  Upper Bound 95% CI  \n",
       "Neural Networks       0.26 -1.72              -1.732              -1.708  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit all models for selection neural network model on validation set\n",
    "columns = ['Error rate', 'SE', 'Sensitivity', 'Specificity', 'FNR','AUC', 'Precision','Cost','Lower Bount 95% CI', 'Upper Bound 95% CI']\n",
    "rows = ['Neural Networks']\n",
    "results = pd.DataFrame(0.0, columns=columns, index=rows)\n",
    "\n",
    "y_prob_nn = (nn.predict_proba(np.array(validate[predictors])))\n",
    "y_pred_nn = np.array(((pd.DataFrame(y_prob_nn)) > tau).astype(int))\n",
    "\n",
    "Confusion  = confusion_matrix(validate[response], y_pred_nn) \n",
    "tn, fp, fn, tp = Confusion.ravel()\n",
    "error_rate =  1 - accuracy_score(validate[response], y_pred_nn)\n",
    "formula2=((tn*benefit_cost[0,0]+fp*benefit_cost[0,1]+fn*benefit_cost[1,0]+tp*benefit_cost[1,1])/len(validate[response])).round(2)\n",
    "se = np.sqrt(error_rate*(1- error_rate)/len(validate[response]))\n",
    "\n",
    "results.iloc[0,0]=  error_rate\n",
    "results.iloc[0,1]=  se\n",
    "results.iloc[0,2]=  Confusion[1,1]/float(np.sum(Confusion[1,:]))\n",
    "results.iloc[0,3]=  Confusion[0,0]/float(np.sum(Confusion[0,:]))\n",
    "results.iloc[0,4]=  fn/float(tp+fn)\n",
    "results.iloc[0,5]=  roc_auc_score(validate[response], y_prob_nn)\n",
    "results.iloc[0,6]=  precision_score(validate[response], y_pred_nn)\n",
    "results.iloc[0,7]=  formula2\n",
    "results.iloc[0,8] = formula2 - se*stats.t.ppf(0.95, df = len(validate[response])-1)\n",
    "results.iloc[0,9] = formula2 + se*stats.t.ppf(0.95, df = len(validate[response])-1)\n",
    "\n",
    "results.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 SVC(C=1.0, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "Normalized confusion matrix\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVcAAAEmCAYAAADWT9N8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEZEYKLiKiMTg/wG/EA7DY+x8FQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11f846a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
      "            max_depth=None, max_features=9, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=10, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=120, n_jobs=1,\n",
      "            oob_score=False, random_state=0, verbose=0, warm_start=False)\n",
      "Normalized confusion matrix\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVcAAAEmCAYAAADWT9N8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nriIiMfh/A8ku5+ggEFUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x110eb3a20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)\n",
      "Normalized confusion matrix\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVcAAAEmCAYAAADWT9N8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1112cc208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "Normalized confusion matrix\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVcAAAEmCAYAAADWT9N8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11747f320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 LogisticRegressionCV(Cs=10, class_weight=None, cv=None, dual=False,\n",
      "           fit_intercept=True, intercept_scaling=1.0, max_iter=100,\n",
      "           multi_class='ovr', n_jobs=1, penalty='l1', random_state=None,\n",
      "           refit=True, scoring='neg_log_loss', solver='liblinear',\n",
      "           tol=0.0001, verbose=0)\n",
      "Normalized confusion matrix\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVcAAAEmCAYAAADWT9N8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x112bf4588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 LogisticRegressionCV(Cs=10, class_weight=None, cv=None, dual=False,\n",
      "           fit_intercept=True, intercept_scaling=1.0, max_iter=100,\n",
      "           multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
      "           refit=True, scoring='neg_log_loss', solver='lbfgs', tol=0.0001,\n",
      "           verbose=0)\n",
      "Normalized confusion matrix\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVcAAAEmCAYAAADWT9N8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x111d4d6d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage=None,\n",
      "              solver='svd', store_covariance=False, tol=0.0001)\n",
      "Normalized confusion matrix\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVcAAAEmCAYAAADWT9N8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3XecVNX5x/HPnVk6LCigCGpE1Ecj1qABxIgaI5YkYGKM\nLWKJvUX9qYkmlsQSW4JRY49Gk2gsxKjYUWPvHX0UxS4idWkL7O78/jh312HdndmFvVN2v29e82Lu\nPXfunMuwz5557ilRJpNBRETaVqrYFRARaY8UXEVEEqDgKiKSAAVXEZEEKLiKiCRAwVVEJAEVxa6A\nlA4zSwPHAfsQ/m90Bu4GfufuS1binHcCGwGXuvtlrXz9MOBUd//pirx/WzOz3sBEd9+hmfJXgdHu\nPrewNZNSo+Aq2f4KrALs6O7zzKwH8A/gWmD/FTznIGBnoIe717b2xe7+IlASgTW2CrB1c4XuvnkB\n6yIlLNIgAgEws8HAm8Aa7l6VtX8AMNLd74xbbZcDmwMZ4D7gN+5eY2bVwPnATsBAYAJwHfAcYMAb\nwE+AqUB/d58Znz8D9Aeqgb8B6wN1wEvAYcD3gMvcfWhr39/d/9zEdVYDfwJ2ByqB/wP2BDYBPgd+\n6O4Lzeyg+P07A6sC57v7X83s0bhObwDfARYBdwGbAfsCL8TXcxQwBhgVb78M7Ovuj7bmc5HypZyr\n1NsSeCs7sAK4+3R3vzPevBSYRQhEwwgB5aS4rAsw0923IbQ0zweWAbsCi919c3d/P8f7jwN6xS2/\nreJ96zY6plXvb2Zdm3ifLsAX7r4JcAWhVX488G2gN/BjM+sJ/BLY1d23APYCLohff2DW9dQSp07c\n3eJWdr0/AEsJwftmwi8IBdYORMFV6tWR///DLoQgkYlzsFfG++rdFf/9MiGI9WjF+z8JbGxmjwGn\nAn9296kJvf8d8d/vA2+4+2fuXgdMA1Z19wWElu1uZvZ74DSgZ466P9F4Rxx49wNOIbSyz8vxemmH\nFFyl3vPARmbWK3unmQ0ys3vNrBvf/P+SAjplbS8GcPf6XFPUzHtF8bk71+9w92nAeoQgVAk8bGaN\nc61t9f7ZN+eWNS40szWBV4FvEYL+6c2cp96CZvavHddpPaBPnnNIO6PgKgC4+2eEm1fXm1klQPz3\nFcAsd18MPAAcZWaRmXUBDgUeauVbfUX4Sg+wR/1OMzuCkHN90N1Pid9raKPXtsX7t8SwuJ5/cPcH\nCK3Y+p4PNUDazJoL3MTH9iGkAw4A/kXIP0sHouAq2Y4EpgBPx12Knou3D4nLjwVWI9zMeQNw4JxW\nvsexwOVm9jKwBfBFvP/vQBqYYmYvElqvE5p47cq+f0s8CHwKuJm9QmiBfkVogX5BSDu8bWZ9c5zj\nGuBed38IOBMYYmZHJlBXKVHqLSAikgC1XEVEEqDgKiKSAAVXEZEEaPhrDvEd6a0INzFaPXRTpINK\nA2sAL6zonBRNMbNVCTc686ly99lt9b4rSsE1t61oooO4iLTItoR+wivNzFatpWJWmpqWHD7HzNYr\ndoBVcM3tC4B9fnsJlav2L3ZdpJGJL08vdhWkCbULZjNz4nnwdTe7tlCZpoYvuwyjJmpqVHNQkalm\n9SUvrkJo4Sq4lrBagMpV+9On/4Bi10UaqahsUStGiqfNU2k1qe7Upro1f0Bd6dxGUnAVkfKRSkEq\nneuAglUlHwVXESkfURQeucpLhIKriJSPKBUeucpLhIKriJSRPC3XZidCKzwFVxEpH/lyrhm1XEVE\nWk9pARGRBOiGlohIAtRyFRFJgHKuIiJJyNNy1SACEZEVkIrCI1d5iVBwFZHyoZyriEgC8uVcUwqu\nIiKtp65YIiIJUFpARCQJmltARKTtKecqIpIApQVERBKgG1oiIglQy1VEJAHKuYqIJEFzC4iItD3l\nXEVEEqCcq4hI24tSKaIcedVcZYWm4CoiZSNkBZr/6l9CWQEFVxEpIxG5R7gquIqItF4URXlarqUT\nXRVcRaRsROQJriXUdFVwFZGykUqlyOS4aZXSDS0RkRWgnKuISALy5FxLqbuAgquIlA3d0BIRSUAq\nFeWcnCW1Ektrm1kKuALYDFgCHOLuU7PK9wVOBGqB6939rznrusI1EREphijHY+WMBbq6+wjgVODi\nRuUXAd8HtgFONLNVcp1MwVVEykZ9WiDXYyWMAu4HcPdngWGNyl8HegNdCaE8k+tkSguISNloRc51\nmpk1Lj7L3c/McfpKYF7Wdq2ZVbh7Tbz9JvASsBC4093n5qqrgquIlI0oFRHlyKtmlQ129w9befoq\noFfWdqo+sJrZpsBuwGBgAXCzme3p7rc1dzKlBUSkbCScFngK2BXAzIYDb2SVzQMWA4vdvRaYAeTM\nuarlKiLlI9l+rhOBnczsaUJO9UAz2wfo6e5Xm9lVwJNmthR4H7gh18kUXEWkbER5ViJYmZaru9cB\nhzfa/U5W+ZXAlS09n4KriJSNKIogV85VgwhERFovisjTci1cXfJRcC1jdXV13PzH0/nkvSlUdO7C\n+NP+yOprrdNQ/uLkSUy68a9EUcTwMWPZ6ecH8eQ9t/HUPbcDsGzpEj5+dwp/vu8FZn7xKX8//zRS\n6TQD1h7M+NMuKKkZhspRBBy3/boM6deDZbV1XPTI+3w+r7qh3FbryRHbrkMUwexFyzj3gXepy8DJ\n3x/C6r260jkdcfMLn/L0tDkM6dedY7Zbl7pMhmW1dZz/4FTmLF5WvIsrkiTTAm1NPz1l7JXHH2DZ\n0iWcdv1/+OlRp3DrhD80lNXV1nL75X/kpMv/wWnXTWTy7Tcxf+5sRu2+J6dceSunXHkr39pwKPuc\neCbde/Xmrmsm8KODj+U319xBzdKlvP7U5CJeWfswasiqdE6nOOa2N7jm6Y84Ytt1lis/ccchXPDw\nVI67/U1e+GgOA3p1YSfrT9XiGo6/401Ouettjhm9LgBHbzeYvzz+ASfc+RZPvD+bnw8bVIQrKr6E\newu0KbVcy9h7r77A0BHbATBkky358O3XG8pS6TTn3PoI6YoKqmbPJFNXS0VFp4byaVNe5/MP3mP/\nk0NA/pZtzMKquWQyGaoXLSRdof8aK2vowEpe+GgOAG9PX4Ct1qOhbK0+XamqXsZPt1iDwX278+y0\nOXwyt5qvFi7l8Xg0exRBbV0YBPT7+95l9qLQUk2nIpbW1BX2YkpElMqTc12JuQXaWtm1XM1snJkN\nNLMBZnZFsetTTIsXLqBbz6/7PKdSaWprahq20xUVvPTofZyx7xhsy+F06da9oezeGy7jR4cc17C9\n2lrr8M+Lz+S0n+3IvNkz2XDL4YW5iHase+c0C5fWNmzXZr6OC5XdOrHxGr34z2vTOWniFLZcqzdb\nrFlJ9bI6Fi+ro1unFGfsalz/zMcADYF14wG9GLvpAG5/9fOCX08pKKeWa9kFV+A4oNLdp7v7kcWu\nTDF169GT6oULG7YzmbpvtDi/s/0uXHzv89QsW8ZTk+4AYNH8eUz/6AM2Gjay4bh/XXIWp151O+fe\nNpmRu+7BLVkpBlkxi5bW0q1zumE7FUHcEKWquobP5lbz8ZzF1NZleOGjuWywWk8A+vfszCV7DOWh\nd75i8rszG14/ev2+HL/Duvzmv28zb3ENHVO+wFo6wTWx735mNp4w2qE7MAT4I2Fc7qWEf4FZwEGE\nIWeXEyZJmE4YXvZDoCdwCZAG+gFHEEZEbA783cz2A/4OHApMcPft4/e9B/gtYZzwOYTpwd4HDnP3\ndnUHYL3NhvHaE4+w9U678/4bLzNoyNdjqRcvmM+EEw/mxL/cRKfOXejSrTupKPwu9VeeZ6Ottlnu\nXD0q+9CtZ/jh7tNvdaa+9mLhLqSdevPzKkYMXpXH35vFRgN68sHMRQ1lX8yrplunNAN7d+XzedVs\nMrCSSVNmsEq3Tlww9ttc+tg0Xvn062Hu37d+7D50ACfc8Rbzl3TUwJr/hlYpdRdIOrHW2913NrP1\ngbuBucBB7j7FzA4GTgaeB/q6+9Zm1h94L37txsCJ7v5GPEriQHf/pZm9SujouxTA3V83s65m9q14\nXz/gVcCBUe4+w8x+D4wHrmmuomZ2JnBGW/8DJGnL0WOY8tyTnHPwOMhkOOh3F/Hs/f+hevEiRo/b\nh+FjxnL+YT8jXVHBWuttyIhdxgEw/aP36T9o7eXONf60P3LlaUeTSldQ0akT439zfjEuqV158v3Z\nfGftPvxlz6FAxAUPT2WHDfrRrVOae9/6kosemcrpO68PUcRbX1Tx3IdzOOp769CrSwX7b70m+2+9\nJgC/+e/bHL3dYGbMX8pZu4VfoK99VsWNz31SxKsrjnw515xlBRZlMjlnzVphcct1I3c/xcy6EkY6\nrAK8Eh/SiRBI3wGq3f3P8eueBX4OrAkcSxjP2wuocvfxZvYYIbhWA7e4+3AzOwRYgzDB7TzCMLb3\nCS1lgG7AQ+5+eiuvYR1g2uF/uok+/Qe0+t9AknXTM58WuwrShJqqmXx50//Bik2e0qT6n8WaHX4L\n3fs2f+CiWVRM/n2bvveKSjrn2jhyO/ALdx9NaLXeQ5jGawRAPPnsBvGxlwJnuPsBhAkU6n8l1fHN\net8C7A6MA/4JzAQ+BX4cv9c5gPoWiZS5+qxArkepKHR/myMI+dIKQuA9mNB63SWeLGE6sAhYBtwM\n3GZmcwiBsl98jqf5OtcKgLsvMLPXgAp3nw9gZscB98ZLN1QBvyjA9YlIgpRzBdz9hqzn1cA68ebo\n7OPMbEPgCXc/ysz6Am8BM939EsINrcbnPR2o/3o/PGv/oY2OexB4cGWvQ0RKRyrP3AKlFFxLoSvW\nJ8Deca71fuAUd19S5DqJSCnKlxIondha/BFa7r4Q+HGx6yEipS+VZyWCTCqiVMauFT24ioi0VN6b\nVmq5ioi0XktarrXNlhaWgquIlI288weU0A0tBVcRKSO5g2umhPICCq4iUjbKqJurgquIlI98aYFS\nmnJQwVVEykYqFW5qNX9A4eqSj4KriJQNpQVERBKgtICISALUchURSUAURTlzrpkSiq4KriJSNpQW\nEBFJgNICIiIJUMtVRCQBqVSenGsJLVCo4CoiZUMtVxGRhJRQ/MxJwVVEyoZariIiCcg3t0BKcwuI\niLSeumKJiCQgFUVhee0c5SvKzFLAFcBmwBLgEHefmlW+FXAJYaWu6cB+7l7dbF1WuCYiIgWWa1nt\nvIsX5jcW6OruI4BTgYvrC8wsAq4BDnT3UcD9wLdynazZlquZ/S7XC9397FZUWkRkpaWiiHSOnGvd\nykXX+qCJuz9rZsOyyjYAZgG/MrOhwL3u7jnrmqMsyvMQESmo+t4CuR6xaWaWafQ4M8/pK4F5Wdu1\nZlbfAO0HjAQuA74P7GhmO+Q6WbMtV3c/q/65mfUAhgBvAt3cfWGeSoqItLlW3NAa7O4ftvL0VUCv\nrO2Uu9fEz2cBU939bQAzux8YBkxu7mR5c65xdH4NuAtYHfjQzH7QykqLiKy0qAV/VsJTwK4AZjYc\neCOr7AOgp5mtF29vC7yV62QtuaF1HiEXMdfdvwC2Ay5sZaVFRFZaKhVyrs09cq6vld9EoNrMngb+\nRMiv7mNmh7r7UuBg4J9m9gLwibvfm+tkLemKlXL36WYGgLtPqX8uIlJISfZzdfc64PBGu9/JKp8M\nbN3S87UkuH5qZrsDGTPrAxwFfNzSNxARaStJ9nNtay1JCxwG7AusRcg7bA4cmmSlRESaknA/1zaV\nt+Xq7jOAvc2sEljm7ouTr5aIyDel8qyhVUot17zB1cw2AW4E1o633wEOcPf3E66biMhyoih3AC2h\n2NqitMCVwGnu3s/d+xGGhF2fbLVERL4p38imEoqtLQqu3dz9vvoNd59IGMkgIlJQrRihVXS55hZY\nO376mpmdClwH1BBubj1RgLqJiCwnFYVHrvJSkSvn+jiQIbS0RxN6DdTLAMcmVy0RkW/Kt0DhSg4i\naFO55hYYXMiKiIjk066WebEwHOtIoCehFZsmTIrwvYTrJiKynIjcX/1LJ7S27IbWrcBcYAvgVWA1\nwuxYIiIFVU43tFoSXFPufgZhEtmXCbN1fzfRWomINCEdRXkfpaIlwXWRmXUB3gW+4+5LgK7JVktE\n5Jva1fBX4GbgbkIXrGfMbAzwWaK1EhFpQjnd0MrbcnX3y4CfuPtXhC5ZVxNSAyIihZWv1Vo6sbXl\nCxQ2msN1E0ALFIpIQdVPip2rvFTkSguUTi2L7EcbD2TQoDWLXQ1p5MhDLyh2FaQJ6brFDEro3BG5\nv/qXUtBq0QKFIiKlIEXuXGZL7tAXSktuaImIlIRyuqGl4CoiZSOdgooczdN0CTVdWxRczawHMISw\n1Gx3d1+YaK1ERJpQTi3XvHHezHYEXgPuAgYAH5rZD5KumIhIY/VTDuZ6lIqWNKLPBUYBc939C2A7\n4MJEayUi0oRyGqHV0rkFptdvuPuUBOsjItKsdBRRkeNRSnMLtCTn+qmZ7Q5kzKwPcBTwcbLVEhH5\nptDPNXd5qWhJy/UwwrwCawEfAJsDhyZZKRGRpqSiKO+jVORtubr7DGDvAtRFRCSnfHnVEoqtLVqJ\nYBphzazluPu6idRIRKQZ6VRERTuYW6De6KznnYBxQJdEaiMikkO7arm6+0eNdl1oZi8Cf0imSiIi\nTWsvS2sDYGbZCxFGwMZAt8RqJCLSjCj+k6u8VLQkLZA9O1YGmAkckEx1RESal47yzC1QOrG1RcH1\n3+7+18RrIiKSR7uaW4AwaEBEpOjKaW6BlrRcPzGzycBzwOL6ne6uZV5EpKDaVW8B4Nms5yVUdRHp\naKKInKOwVia4mlkKuALYDFgCHOLuU5s47mpgtrufmut8uRYoPMDdb9RyLyJSKtKp3BNir+Rk2WOB\nru4+wsyGAxcDP84+wMwOIyzQ+ni+k+WqynErU0sRkbaWIsr7WAmjgPsB3P1ZYFh2oZmNBL4LXNWS\nk2mZFxEpG63IuU4zs8bFZ7n7mTlOXwnMy9quNbMKd68xszWAMwgjVH/WkrrmCq4bm9kHTeyPgIzm\nFhCRQovI3SMgq2iwu3/YytNXAb2ytlPuXhM/3xPoB0wirMjS3czecfcbmjtZruA6Fdi1lZUTEUlM\nOhXlnJxlJSdueQr4IfDvOOf6Rn2Bu18KXApgZuOBDXMFVsgdXJc2Ma+AiEjR5JuzdSXnc50I7GRm\nTxMawQea2T5AT3e/urUnyxVcn1rBCoqIJCLJfq7uXgcc3mj3O00cd0NLztdscHX3o1tVMxGRhEXk\n7uJUSh3x1VtARMpGwmmBNqXgKiJlQ8FVRCQBEbm/+pdOaFVwFZEy0t4mbhERKQkpItK50gIl1HZV\ncBWRslFOk2UruIpI2VDOVUQkASHnmsx8rm1NwVVEykYqypNzLaHoquAqImVDaQERkQSoK5aISALy\nrTagrlgiIitAw19FRBKgtICISAKiPGmBSGkBEZHWU8tVRCQBKfLkXNVyFRFpvVSUe/XXlVufsG3l\nWjFBSlxdXR3HHHk4240awQ92HM37U6cuV37vPXezzfCt2G7UCK6/9prlyp5/7jl+sOPohu1XXn6Z\nUSO2ZsfR2/Kr446hrq6uEJfQrkVRxKWn/ZzHbjyRB645jnXX6rdc+d67bcXzt/6ah687ngPGjgCg\noiLFDeeO59EbTuDh645ng3VWX+41F5y4B4f8dFTBrqHURC34UyoUXMvYf+/6D9XV1Tz+5DP8/pzz\nOfXkExvKli1bxskn/Yp77nuQhyY/znXXXs2XX34JwMUXXcCRhx1CdXV1w/FHH3EoF178Zx557Al6\n9+7Nrf/6Z8Gvp7350fab0rVzBaMPuJjfXnoX55+wR0NZ3z49OOPI3dn5lxPY6ZAJ/HyXYay9xqqM\nGbUxFekU24+/hHOvvp+zjv4hAP1W6cl/LjuC3bbbpFiXUxqir/OuTT1KKLYquJazp596kp12HgPA\nd4cP56WXXmwoe+fttxkyZD1WWWUVOnfuzMhtRvHkE/8DYN11h3DLbXcud67PPvuUESNHAjBi5DY8\n/dSTBbqK9mvkFkN46Om3AXj+jQ/5zrfXbigbPKgfr7/7GXOqFpHJZHjprY/57qaDee+jGVSkU0RR\nRGXPriyrqQWgR7cunHPlJP557wtFuZZSkY7nFsj1KBVlEVzNbICZXRE//56ZbRo/vzP3K9u3+VVV\n9O7du2E7nU5TU1MDQFVVFZVZZb169aJq3jwAxu3xEzp16rTcudYZvC5P/O9xACbdczcLFy5Muvrt\nXq8eXZm3YHHDdm1tHel0+JGb+vEMvr3uGqy2ai+6de3E6O8a3bt1ZuGiJaw9sC+vTfwtl/92b674\n12MAfPT5LF5486NiXEZJCY3TckgKlElwdffp7n5kvHkQMDDev0fzr2r/elVWMn/+/Ibturo6KirC\nPcrKykoWZJXNnz+f3n36NHuuq6/9Gxf+8Tx2+cGO9F9tNfr269fssdIy8xdW06t7l4btVCqitjbk\nsufOX8zJF9/Bvy46hBvPO5BX3/6EWXMXcMx+O/DwM2+z6diz+e5e53HN2fvTpbPuO9fLlRLI102r\n0Ar2qZnZeGAs0AvoB5wNVAF/AKqBWYTA2Qm4lRD4uwKHA3OBW4CjgDHAlmY2BXgeGAo8AXzb3TNm\ndhnwCDAVuJTwy24WcJC7zyvEtRbKiJHbMOmeu/npnj/juWefZejQr/NxG260EVOnvsfs2bPp2bMn\nTz3xP44/4aRmz3XfpHv529//Qd++ffnVccew85hdCnEJ7dozr37Art8byh0PvcLWm6zDm1M/byhL\np1NsvuFa7HjQn+jcqYJ7rzyaMy77L0PXH0RNnAqYPW8RnSrSpFNl0QYqCM2K1bwewE5Af0JgrANG\nuftnZnYccDrwKCEY/gL4dvyauQDu/pKZ3Q/c4u4fmxnuPtPMXge2NbPngO2B44EnCQF1ipkdDJwM\nnNZcxczsTOCMJC46KT8eO47JDz/E6G1HkslkuPrav3HLv/7JwgULOPiXh/LHCy/hh7vuTKaujl+M\nP4hBgwY1e6711l+fXX+wI926d2e70dszZpddC3gl7dNdk19jh+Eb8ugNJxBFEYeecTN7jRlGj+5d\nuP7OpwB45l+nsGRpDRNueoRZcxfyl5snc9WZ+/HwdcfTuVMFZ/zlbhZVLy3ylZSOKM/cAqW0zEuU\nyWQK8kZxy3VNd/9DvP0WUOHuFm9vAZwL7AYcC+wKLCO0bL8gBNThZnZD/Px+M5vu7gPM7PvA3sAD\nwBbu/mszmwe8Er99J+A9dx/fyjqvA0yb9OAjDBq05opfvCRila2OLnYVpAnpusUMqn4SYLC7f9gW\n56z/WbzobxPpv/rAZo/76svPOenAcW363iuq0N83vgNgZqsD3YHOZrZGXLYd8C4wGvjC3X9ACKzn\nNjpHHd+s9yPAFoS0wrXxPgd+4e6jCa3We9ryQkSk8Mqpn2uh0wIDzOwRoDdwBFAD3GlmdcAcYDyQ\nAW4xsyPi+p3d6BzPAeeb2bT6HXGu9Xbg++7+frz7CODvZlYRn/Pg5C5LRApBcws073F3P7XRvoeb\nOG6nJvYNB3D3q4Cr4n0D6gvd/VyyWrnu/hKhFSwi7YRuaImIJCAiyr36awmF14IFV3e/oVDvJSLt\nk9ICIiIJUFpARCQJZRRdFVxFpGyU0yACBVcRKRtJNlzNLAVcAWwGLAEOcfepWeV7E0Z/1gBvAEe6\ne7MTH2vQsoiUj6gFjxU3Fujq7iOAU4GL6wvMrBthUNP27r4Noa/+7rlOpuAqImUj4RFao4D7Adz9\nWWBYVtkSYKS7L4q3KwgTTjVLaQERKRutWENrmpk1Lj7L3c/McfpKIHvmvFozq3D3mvjr/5cAZnYM\n0BN4KFddFVxFpHy0POm6IhO3VBGmRK2Xcvea+o04J3sBsAHwE3fPOeuV0gIiUjYSTgs8RZiNDzMb\nTrhple0qwhzTY7PSA81Sy1VEykbCI7QmAjuZ2dOENvCBZrYPIQXwImHypyeAyXHKYYK7T2zuZAqu\nIlJWkurKGudVD2+0+52s5636pq/gKiJlI99X/w45cYuIyMrSxC0iIgkoo6kFFFxFpHyElmuuuQUK\nWJk8FFxFpGwoLSAikgClBUREklBG0VXBVUTKhuZzFRFJQBk1XBVcRaSMlFF0VXAVkbKhEVoiIglQ\nVywRkQSkyDNZdsFqkp+Cq4iUkfJJuiq4ikjZUFpARCQB5dNuVXAVkTKiQQQiIkkoo6argquIlI0y\niq0KriJSPnRDS0QkAVEU5Zksu3Siq4KriJQNpQVERBKgtICISAI0cYuISBLytFxLKLYquIpI+YjI\nkxYoWE3yU3AVkbKhtICISAJ0Q0tEJAEKriIiCQj9XHOlBUqHgquIlA21XEVEEqARWiIiScgzt0Ap\nNV0VXHNLA3w5fXqx6yFNSNctLnYVpAnpuuqGp2197hlfTs8ZP2d8WTo/qwquua0BcOAv9i12PaQJ\ng4pdAclnDeD9NjpXFTDnwF/su0oLjp0TH19UCq65vQBsC3wB1Ba5Lm1lGjC42JWQJrWXzyZNCKwv\ntNUJ3X22ma0HVLbg8Cp3n91W772iokwmU+w6SAGZWcbdSycxJQ302bQvqWJXQESkPVJwFRFJgIKr\niEgCFFw7nrOKXQFplj6bdkQ3tEREEqCWq4hIAhRcRUQSoOAqIpIABVcRkQQouIqIJEDBVUQkAQqu\nIiIJUHCVZpmZJhEpEdmfhT6X8qDgKg3MbLnJjd09E+/XD3MRmVm6/rOIdYn363MpYRqhJQCYWcrd\n68wsBZwLODDb3e8qctU6NDOL3D0Tfy43AB8CPYDL3f2DYtZNclPLVQCIA2sETAJmESb6P9jMdi5u\nzTq2rBbrHcDzwCPAcOAnZtazaBWTvBRcO7i4RVRvMPCKu18IjASeBLoXpWIdXKMca0/gDeDfwHHA\nNcCnwGrFqZ20hNICUv+DvBfwEvA4MAM4EpgLXAns7e6fFa+GHZeZHQU8C/yOsOTQ/sBrwN3Awe7+\nchGrJzmo5dpBNbp5NRD4NdAbOBxYB/gWcCNwngJrUQ0Ffgr8BHgPGAHcDvxGgbW0Kbh2QGa2obvX\nmllkZmtax/2RAAAIO0lEQVTHwfNkYIy7/xcYBywAjnP3+4pa2Q7EzPaJ/47MbO949/FAZ6APsANw\nPbCfPpfSp9VfOxgzGwqMBt4BxgATzOz/gFWAgWbWx90fLWIVO7L6lU1XB04ws80JS0R3Aka4+92A\negiUCeVcOxAzW83dZ8TPLyTcsPqEEGTXAfYGJgC/c/e6YtWzozGzDYAZ7j7XzM4HBrn7/mY2HNgF\nOBD4GNgdmNeoz6uUKAXXDsLMVgXGA28CEaGv5InASe7+jJlVAr8C/uvurxStoh2QmY0FtgDqgMsJ\nOdV33f3QuHxbQvD14tVSWkvBtQMxs/0I3Xjud/dxZrYHIaBe7O7/qR9IUNxadhxmdgShh8YnhP7F\nPYEt3H2BmT0MVLn7HsWso6w43dBq5xr1CngcOBvoYWaj3f1O4M/Ab8ysf1Eq2LHdAbwIbAfsA0wE\nTjGzLsCPgdXNbFMNcy1Parm2Y/GY9Np4oMAfCEMn/w1sTeh6dQ8wH5jo7l8VraIdTP3nEj9fE7gL\nuIrQE2ACoQVbA/zK3auKVlFZKQqu7VwcWP9OuOs8E1gbOBbYjJCDvc3d7y9aBTuYRr/wxgJPE/oX\n/4XQcr2S0BVulrs/XryayspScG2HsnOncd9JI7RcJxCGTKaB/wOm1fd31R3owokD678Judb/EuYM\nGEBovT4QDz+WMqd+ru1Mo8C6CmFM+mLCaKvLCF2uDgD6uvtUWG5yEElQ1i+xXwPLgNOBm4DPgOnA\n0Xzd11XKnIJrO5L1lTMi/NCuAexLmOVqOOEH+ijgRHd/rng17VjqP5esX2LPEn7JXQb8DcgAm7r7\nO0WqoiRAaYF2Jg6stxD6s44E5hCGtl5MGEZ5g+ZoLZxG8+SeR5gfoCdwKaGXQHdCiuZcd3+weDWV\ntqauWO1EVnednwGd3P337r4LYcDABOAYYE93v0tdewona57c/xBWEFhC+BZxOuHn7+eEyXEUWNsZ\nBdcyV9+PNesr52tAlZltHW//mfDDfJO71zQ6VhLSqH/xMOAzdz8e+AdwNdDZ3R8hTBv4QDHqKMlS\nWqCMNfrKeQHwOqE3QIqwksBs4HuEVus5hGnq3i5WfTuKRp/LD4Htge8Cu7n7bDP7EWFqx72AhRoV\n1z7phlYZa/SV8xlC/m5b4GHC6J9tgT8B3QjBdmaRqtphxD0C6j+XOwkTj69BCK73mNnlhDkdTnH3\n+UWsqiRMaYEy1Ogr57rAK4SW648JgfVjd/8f8E/CZMsTgIM0Cit5WSmX3wJz4slXfkQYINCbMDnL\nr9z9oSJVUQpEaYEy0+gr537AesAownDJi4AvCDMr7UnogtUH6KLVBArHzHoDpwKbElIxr5nZOGCg\nu19e3NpJoSi4lpGsZZYj4FZCv9VKYDfC5NfHErr7nOHukzTLVfHEAzgOJHyzmELob3yWegV0HEoL\nlJGsr5y/Br5y930JN0X+TbiRNZ/wlXNSfe6vSFXt8Nx9DmFOhxmE7lbXu/uD6gbXcajlWmbir5yn\nAJsDp7v7y/G++4ED3P3dolZQlhNPUn4gYcKc69z99SJXSQpEwbUMxV85DyHcILnb3Z/LnsZOSouZ\nrUYY3HGbu39Z7PpIYSi4likz6wccBvQFzgQWKA1QuvTLr+NRcC1j8eoBPd19WrHrIiLLU3AVEUmA\neguIiCRAwVVEJAEKriIiCVBwFRFJgGbFkhYzs3WAdwnDOTOElQ0+Bw50909X8JzjgdHuPt7MJgGH\nuPvnzRx7FvCwuz/RivNn3D1qtO9MAHc/M8frPozr9WEL3yfvOaVjUXCV1vrc3Tev3zCz8wjLQo9b\n2RO7+655DtkOeHRl30ekEBRcZWX9jzClXn1r7znC0NxtgTHA8YT000vAUe5ebWb7E5Y5qQI+AhZk\nvX40YSXUywmzfS0Dfk9YImUYcG08w9Ri4K+EQRSLgGPc/ZW4dX0zYZ2qZ/NV3syOBvYHehCmA9wr\na0LxM81sM6AaOMzdXzez1QlLYK8VH/9rd3+4Vf9i0iEo5yorzMw6ESaOeSpr933ubkB/4JfAyLil\nOwM4ycwGEuae/R4wAujVxKmPIQTHjYDvA78jLLr4IiFt8AZhqfCT3X1L4NC4HMKKqjfE7/lU4xM3\nqn8lMJbw9X8oYdLxI7MOec/dtyAE9xvjfRMIk7B8h/BL5Soza+oapINTy1Vaa6CZvRo/7wI8T5i7\ntF79kt3bA+sDz5oZhPzsy4QVaZ+uH2NvZjcDOzZ6j+2Aq+PhvNOBjeNjif/uCWwF/K1+H9DTzPoS\nWr57x/v+AVzX3IW4e5WZ7QP83Mw2ILS0X8065Nr4uElmdrOZ9SEE+w3N7Oz4mE7AkObeQzouBVdp\nreVyrk1YHP+dBv7t7sdCQ0CsIATS7G9MNU2cY1n2hpmtB3yctSsNVDfK/a5JWDMsk3X+DOGre5PM\nbC3gMUJr9z5CIN8iR92Wxu+9g7vPjs8xEPiS0AIWaaC0gCTlMWCcma0Wz2H6V0L+9UlguJkNildT\n2KuJ1/4P+JmZRfGMUo8TWsk1QIW7zwPeM7P9AMxsp/g1EJa52S9+vkf8uuZsBUx19z8RWty7EIJn\nvX3j848D3nH3RcBk4tSBmX2bsChk95b9k0hHouAqiXD314CzCMHoLcL/tfPjdMAxhCD4POGmVmNX\nAAsJy4Q/TLhZNZ8wZ+2VZjaSEPgOMbPXCasv7BVPJn408JN4/66ECcSb8yCQMrMphJtfHwKDs8o3\niFMgJwAHxPuOIfxyeJ2wGsT+WmhQmqKJW0REEqCWq4hIAhRcRUQSoOAqIpIABVcRkQQouIqIJEDB\nVUQkAQquIiIJ+H8RAu9CpX392QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1206c6b70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariance=False, store_covariances=None, tol=0.0001)\n",
      "Normalized confusion matrix\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVcAAAEmCAYAAADWT9N8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11f83f2e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 QuadraticDiscriminantAnalysis(priors=None, reg_param=1.0,\n",
      "               store_covariance=False, store_covariances=None, tol=0.0001)\n",
      "Normalized confusion matrix\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVcAAAEmCAYAAADWT9N8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nyVVEJAZKriIiMVByFRGJgZKriEgM/j+kPCoTbm6H5AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1209c97f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Error rate</th>\n",
       "      <th>SE</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>FNR</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Cost</th>\n",
       "      <th>Lower Bound 95% CI</th>\n",
       "      <th>Upper Bound 95% CI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Support Vector Machines</th>\n",
       "      <td>0.548</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.345</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.835</td>\n",
       "      <td>0.233</td>\n",
       "      <td>-1.69</td>\n",
       "      <td>-1.702</td>\n",
       "      <td>-1.678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.519</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.977</td>\n",
       "      <td>0.380</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.840</td>\n",
       "      <td>0.242</td>\n",
       "      <td>-1.69</td>\n",
       "      <td>-1.702</td>\n",
       "      <td>-1.678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naive Bayes</th>\n",
       "      <td>0.288</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.784</td>\n",
       "      <td>0.698</td>\n",
       "      <td>0.216</td>\n",
       "      <td>0.796</td>\n",
       "      <td>0.344</td>\n",
       "      <td>-1.03</td>\n",
       "      <td>-1.041</td>\n",
       "      <td>-1.019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic</th>\n",
       "      <td>0.530</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.366</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.844</td>\n",
       "      <td>0.239</td>\n",
       "      <td>-1.71</td>\n",
       "      <td>-1.722</td>\n",
       "      <td>-1.698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L1 regularised</th>\n",
       "      <td>0.532</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.364</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.844</td>\n",
       "      <td>0.238</td>\n",
       "      <td>-1.71</td>\n",
       "      <td>-1.722</td>\n",
       "      <td>-1.698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L2 regularised</th>\n",
       "      <td>0.530</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.366</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.844</td>\n",
       "      <td>0.239</td>\n",
       "      <td>-1.71</td>\n",
       "      <td>-1.722</td>\n",
       "      <td>-1.698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LDA</th>\n",
       "      <td>0.520</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.981</td>\n",
       "      <td>0.378</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.839</td>\n",
       "      <td>0.242</td>\n",
       "      <td>-1.71</td>\n",
       "      <td>-1.722</td>\n",
       "      <td>-1.698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QDA</th>\n",
       "      <td>0.246</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.659</td>\n",
       "      <td>0.773</td>\n",
       "      <td>0.341</td>\n",
       "      <td>0.807</td>\n",
       "      <td>0.370</td>\n",
       "      <td>-0.49</td>\n",
       "      <td>-0.501</td>\n",
       "      <td>-0.479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Regularised QDA</th>\n",
       "      <td>0.256</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.726</td>\n",
       "      <td>0.747</td>\n",
       "      <td>0.274</td>\n",
       "      <td>0.798</td>\n",
       "      <td>0.367</td>\n",
       "      <td>-0.79</td>\n",
       "      <td>-0.801</td>\n",
       "      <td>-0.779</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Error rate     SE  Sensitivity  Specificity    FNR  \\\n",
       "Support Vector Machines       0.548  0.008        0.982        0.345  0.018   \n",
       "Random Forest                 0.519  0.008        0.977        0.380  0.023   \n",
       "Naive Bayes                   0.288  0.007        0.784        0.698  0.216   \n",
       "Logistic                      0.530  0.008        0.984        0.366  0.016   \n",
       "L1 regularised                0.532  0.008        0.984        0.364  0.016   \n",
       "L2 regularised                0.530  0.008        0.984        0.366  0.016   \n",
       "LDA                           0.520  0.008        0.981        0.378  0.019   \n",
       "QDA                           0.246  0.007        0.659        0.773  0.341   \n",
       "Regularised QDA               0.256  0.007        0.726        0.747  0.274   \n",
       "\n",
       "                           AUC  Precision  Cost  Lower Bound 95% CI  \\\n",
       "Support Vector Machines  0.835      0.233 -1.69              -1.702   \n",
       "Random Forest            0.840      0.242 -1.69              -1.702   \n",
       "Naive Bayes              0.796      0.344 -1.03              -1.041   \n",
       "Logistic                 0.844      0.239 -1.71              -1.722   \n",
       "L1 regularised           0.844      0.238 -1.71              -1.722   \n",
       "L2 regularised           0.844      0.239 -1.71              -1.722   \n",
       "LDA                      0.839      0.242 -1.71              -1.722   \n",
       "QDA                      0.807      0.370 -0.49              -0.501   \n",
       "Regularised QDA          0.798      0.367 -0.79              -0.801   \n",
       "\n",
       "                         Upper Bound 95% CI  \n",
       "Support Vector Machines              -1.678  \n",
       "Random Forest                        -1.678  \n",
       "Naive Bayes                          -1.019  \n",
       "Logistic                             -1.698  \n",
       "L1 regularised                       -1.698  \n",
       "L2 regularised                       -1.698  \n",
       "LDA                                  -1.698  \n",
       "QDA                                  -0.479  \n",
       "Regularised QDA                      -0.779  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluate all models except neural networks on test data\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score, precision_score\n",
    "from statlearning import plot_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix \n",
    "\n",
    "columns=['Error rate', 'SE', 'Sensitivity', 'Specificity', 'FNR','AUC', 'Precision','Cost', 'Lower Bound 95% CI', 'Upper Bound 95% CI']\n",
    "rows=['Support Vector Machines','Random Forest','Naive Bayes','Logistic', 'L1 regularised', 'L2 regularised', 'LDA', 'QDA', 'Regularised QDA']\n",
    "results=pd.DataFrame(0.0, columns=columns, index=rows) \n",
    "\n",
    "methods=[sv, rf, nbc, logit, logit1_l1, logit1_l2, lda, qda, qda_reg]\n",
    "\n",
    "for i, method in enumerate(methods):\n",
    "    \n",
    "    if i >= 6: \n",
    "        y_prob = method.predict_proba(test[gda_preds])\n",
    "        y_pred = np.array(((pd.DataFrame(y_prob)).iloc[:,1] > tau).astype(int))\n",
    "    else:\n",
    "        y_prob = (method.predict_proba(test[predictors]))\n",
    "        y_pred = np.array(((pd.DataFrame(y_prob)).iloc[:,1] > tau).astype(int))\n",
    "    \n",
    "    Confusion  = confusion_matrix(test[response], y_pred) \n",
    "    tn, fp, fn, tp = Confusion.ravel()\n",
    "    error_rate =  1 - accuracy_score(test[response], y_pred)\n",
    "    formula2=((tn*benefit_cost[0,0]+fp*benefit_cost[0,1]+fn*benefit_cost[1,0]+tp*benefit_cost[1,1])/len(test[response])).round(2)\n",
    "    se = np.sqrt(error_rate*(1- error_rate)/len(test[response]))\n",
    "    \n",
    "    results.iloc[i,0]=  error_rate\n",
    "    results.iloc[i,1]=  se\n",
    "    results.iloc[i,2]=  Confusion[1,1]/float(np.sum(Confusion[1,:]))\n",
    "    results.iloc[i,3]=  Confusion[0,0]/float(np.sum(Confusion[0,:]))\n",
    "    results.iloc[i,4]=  fn/float(tp+fn)\n",
    "    results.iloc[i,5]=  roc_auc_score(test[response], y_prob[:,1])\n",
    "    results.iloc[i,6]=  precision_score(test[response], y_pred)\n",
    "    results.iloc[i,7]=  formula2\n",
    "    results.iloc[i,8] = formula2 - se*stats.t.ppf(0.95, df = len(test[response])-1)\n",
    "    results.iloc[i,9] = formula2 + se*stats.t.ppf(0.95, df = len(test[response])-1)\n",
    "    \n",
    "    print(i,method)\n",
    "    plot_confusion_matrix(Confusion, classes=['negative','positive'], normalize=True)\n",
    "    plt.show()\n",
    "\n",
    "results.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Evaluation Neural Network on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3520/4348 [=======================>......] - ETA: 0sNormalized confusion matrix\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVcAAAEmCAYAAADWT9N8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRURioOQqIhKD/wdvcxDplMr91wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x114530fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Error rate</th>\n",
       "      <th>SE</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>FNR</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Cost</th>\n",
       "      <th>Lower Bound 95% CI</th>\n",
       "      <th>Upper Bound 95% CI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Neural Networks</th>\n",
       "      <td>0.474</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.977</td>\n",
       "      <td>0.435</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.259</td>\n",
       "      <td>-1.74</td>\n",
       "      <td>-1.752</td>\n",
       "      <td>-1.728</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Error rate     SE  Sensitivity  Specificity    FNR    AUC  \\\n",
       "Neural Networks       0.474  0.008        0.977        0.435  0.023  0.848   \n",
       "\n",
       "                 Precision  Cost  Lower Bound 95% CI  Upper Bound 95% CI  \n",
       "Neural Networks      0.259 -1.74              -1.752              -1.728  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluate all models on test data for \n",
    "columns = ['Error rate', 'SE', 'Sensitivity', 'Specificity', 'FNR','AUC', 'Precision','Cost', 'Lower Bound 95% CI', 'Upper Bound 95% CI']\n",
    "rows = ['Neural Networks']\n",
    "results = pd.DataFrame(0.0, columns=columns, index=rows)\n",
    "\n",
    "y_prob_nn = (nn.predict_proba(np.array(test[predictors])))\n",
    "y_pred_nn = np.array(((pd.DataFrame(y_prob_nn)) > tau).astype(int))\n",
    "\n",
    "Confusion  = confusion_matrix(test[response], y_pred_nn) \n",
    "tn, fp, fn, tp = Confusion.ravel()\n",
    "error_rate =  1 - accuracy_score(test[response], y_pred_nn)\n",
    "formula2=((tn*benefit_cost[0,0]+fp*benefit_cost[0,1]+fn*benefit_cost[1,0]+tp*benefit_cost[1,1])/len(test[response])).round(2)\n",
    "se = np.sqrt(error_rate*(1- error_rate)/len(test[response])) \n",
    "    \n",
    "results.iloc[0,0]=  error_rate\n",
    "results.iloc[0,1]=  se\n",
    "results.iloc[0,2]=  Confusion[1,1]/float(np.sum(Confusion[1,:]))\n",
    "results.iloc[0,3]=  Confusion[0,0]/float(np.sum(Confusion[0,:]))\n",
    "results.iloc[0,4]=  fn/float(tp+fn)\n",
    "results.iloc[0,5]=  roc_auc_score(test[response], y_prob_nn)\n",
    "results.iloc[0,6]=  precision_score(test[response], y_pred_nn)\n",
    "results.iloc[0,7]=  formula2\n",
    "results.iloc[0,8] = formula2 - se*stats.t.ppf(0.95, df = len(test[response])-1)\n",
    "results.iloc[0,9] = formula2 + se*stats.t.ppf(0.95, df = len(test[response])-1)\n",
    "\n",
    "plot_confusion_matrix(Confusion, classes=['negative','positive'], normalize=True)\n",
    "plt.show()\n",
    "\n",
    "results.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Balanced Data 50%-50% ratio (After Standardization and Original Results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#SMOTE function to oversample minority class to 50/50 ratio\n",
    "from imblearn.over_sampling import SMOTE\n",
    "os = SMOTE(random_state = 1, ratio = 'minority')\n",
    "train_res_preds, train_res_resp = os.fit_sample(train[predictors],train[response])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegressionCV(Cs=10, class_weight=None, cv=None, dual=False,\n",
       "           fit_intercept=True, intercept_scaling=1.0, max_iter=100,\n",
       "           multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "           refit=True, scoring=None, solver='lbfgs', tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic regression\n",
    "logit_res = LogisticRegression()\n",
    "logit_res.fit(train_res_preds, train_res_resp)\n",
    "\n",
    "# L-1 Regularised logistic regression\n",
    "logit1_l1_res = LogisticRegressionCV(penalty='l1', solver='liblinear')\n",
    "logit1_l1_res.fit(train_res_preds, train_res_resp)\n",
    "\n",
    "# L-2 Regularised logistic regression\n",
    "logit1_l2_res = LogisticRegressionCV(penalty='l2')\n",
    "logit1_l2_res.fit(train_res_preds, train_res_resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gda_preds_res = pd.DataFrame(train_res_preds)\n",
    "del gda_preds_res[13]\n",
    "del gda_preds_res[21]\n",
    "del gda_preds_res[24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
       "               store_covariance=False, store_covariances=None, tol=0.0001)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_res = LinearDiscriminantAnalysis()\n",
    "lda_res.fit(gda_preds_res, train_res_resp)\n",
    "\n",
    "qda_res = QuadraticDiscriminantAnalysis()\n",
    "qda_res.fit(gda_preds_res, train_res_resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "qda_reg_res = qda_cv(gda_preds_res, train_res_resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "21772/21772 [==============================] - 0s - loss: 0.5144 - acc: 0.7415     \n",
      "Epoch 2/100\n",
      "21772/21772 [==============================] - 0s - loss: 0.4553 - acc: 0.7801     \n",
      "Epoch 3/100\n",
      "21772/21772 [==============================] - 0s - loss: 0.4357 - acc: 0.7938     \n",
      "Epoch 4/100\n",
      "21772/21772 [==============================] - 0s - loss: 0.4222 - acc: 0.8014     \n",
      "Epoch 5/100\n",
      "21772/21772 [==============================] - 0s - loss: 0.4125 - acc: 0.8080     \n",
      "Epoch 6/100\n",
      "21772/21772 [==============================] - 0s - loss: 0.4036 - acc: 0.8124     \n",
      "Epoch 7/100\n",
      "21772/21772 [==============================] - 0s - loss: 0.3952 - acc: 0.8188     \n",
      "Epoch 8/100\n",
      "21772/21772 [==============================] - 0s - loss: 0.3895 - acc: 0.8212     \n",
      "Epoch 9/100\n",
      "21772/21772 [==============================] - 0s - loss: 0.3809 - acc: 0.8276     \n",
      "Epoch 10/100\n",
      "21772/21772 [==============================] - 0s - loss: 0.3740 - acc: 0.8306     \n",
      "Epoch 11/100\n",
      "21772/21772 [==============================] - 0s - loss: 0.3662 - acc: 0.8365     \n",
      "Epoch 12/100\n",
      "21772/21772 [==============================] - 0s - loss: 0.3580 - acc: 0.8429     \n",
      "Epoch 13/100\n",
      "21772/21772 [==============================] - 0s - loss: 0.3525 - acc: 0.8450     \n",
      "Epoch 14/100\n",
      "21772/21772 [==============================] - 0s - loss: 0.3455 - acc: 0.8492     \n",
      "Epoch 15/100\n",
      "21772/21772 [==============================] - 0s - loss: 0.3433 - acc: 0.8508     \n",
      "Epoch 16/100\n",
      "21772/21772 [==============================] - 0s - loss: 0.3379 - acc: 0.8556     \n",
      "Epoch 17/100\n",
      "21772/21772 [==============================] - 0s - loss: 0.3293 - acc: 0.8611     \n",
      "Epoch 18/100\n",
      "21772/21772 [==============================] - 0s - loss: 0.3252 - acc: 0.8619     \n",
      "Epoch 19/100\n",
      "21772/21772 [==============================] - 0s - loss: 0.3196 - acc: 0.8655     \n",
      "Epoch 20/100\n",
      "21772/21772 [==============================] - 0s - loss: 0.3152 - acc: 0.8673     \n",
      "Epoch 21/100\n",
      "21772/21772 [==============================] - 0s - loss: 0.3082 - acc: 0.8728     \n",
      "Epoch 22/100\n",
      "21772/21772 [==============================] - 0s - loss: 0.3075 - acc: 0.8685     \n",
      "Epoch 23/100\n",
      "21772/21772 [==============================] - 0s - loss: 0.2954 - acc: 0.8789     \n",
      "Epoch 24/100\n",
      "21772/21772 [==============================] - 0s - loss: 0.2974 - acc: 0.8764     \n",
      "Epoch 25/100\n",
      "21772/21772 [==============================] - 0s - loss: 0.2949 - acc: 0.8766     \n",
      "Epoch 26/100\n",
      "21772/21772 [==============================] - 0s - loss: 0.2854 - acc: 0.8809     \n",
      "Epoch 27/100\n",
      "21772/21772 [==============================] - 0s - loss: 0.2823 - acc: 0.8838     \n",
      "Epoch 28/100\n",
      "21772/21772 [==============================] - 0s - loss: 0.2776 - acc: 0.8861     \n",
      "Epoch 29/100\n",
      "21772/21772 [==============================] - 0s - loss: 0.2703 - acc: 0.8908     \n",
      "Epoch 30/100\n",
      "21772/21772 [==============================] - 0s - loss: 0.2707 - acc: 0.8890     \n",
      "Epoch 31/100\n",
      "21772/21772 [==============================] - 0s - loss: 0.2649 - acc: 0.8922     \n",
      "Epoch 32/100\n",
      "21772/21772 [==============================] - 0s - loss: 0.2611 - acc: 0.8950     \n",
      "Epoch 33/100\n",
      "21772/21772 [==============================] - 0s - loss: 0.2542 - acc: 0.8993     \n",
      "Epoch 34/100\n",
      "21772/21772 [==============================] - 0s - loss: 0.2574 - acc: 0.8967     \n",
      "Epoch 35/100\n",
      "21772/21772 [==============================] - 0s - loss: 0.2474 - acc: 0.9021     \n",
      "Epoch 36/100\n",
      "21772/21772 [==============================] - 0s - loss: 0.2476 - acc: 0.9004     \n",
      "Epoch 37/100\n",
      "21772/21772 [==============================] - 0s - loss: 0.2459 - acc: 0.9019     \n",
      "Epoch 38/100\n",
      "21772/21772 [==============================] - 0s - loss: 0.2372 - acc: 0.9062     \n",
      "Epoch 39/100\n",
      "21772/21772 [==============================] - 0s - loss: 0.2371 - acc: 0.9067     \n",
      "Epoch 40/100\n",
      "21772/21772 [==============================] - 0s - loss: 0.2274 - acc: 0.9115     \n",
      "Epoch 41/100\n",
      "21772/21772 [==============================] - 0s - loss: 0.2278 - acc: 0.9095     \n",
      "Epoch 42/100\n",
      "21772/21772 [==============================] - 0s - loss: 0.2295 - acc: 0.9107     \n",
      "Epoch 43/100\n",
      "21772/21772 [==============================] - 0s - loss: 0.2252 - acc: 0.9113     \n",
      "Epoch 44/100\n",
      "21772/21772 [==============================] - 0s - loss: 0.2207 - acc: 0.9149     \n",
      "Epoch 45/100\n",
      "21772/21772 [==============================] - 0s - loss: 0.2182 - acc: 0.9138     \n",
      "Epoch 46/100\n",
      "21772/21772 [==============================] - 0s - loss: 0.2133 - acc: 0.9181     \n",
      "Epoch 47/100\n",
      "21772/21772 [==============================] - 0s - loss: 0.2103 - acc: 0.9205     \n",
      "Epoch 48/100\n",
      "21772/21772 [==============================] - 0s - loss: 0.2091 - acc: 0.9195     \n",
      "Epoch 49/100\n",
      "21772/21772 [==============================] - 0s - loss: 0.2051 - acc: 0.9220     \n",
      "Epoch 50/100\n",
      "21772/21772 [==============================] - 0s - loss: 0.1985 - acc: 0.9253     \n",
      "Epoch 51/100\n",
      "21772/21772 [==============================] - 0s - loss: 0.2007 - acc: 0.9228     \n",
      "Epoch 52/100\n",
      "21772/21772 [==============================] - 0s - loss: 0.1945 - acc: 0.9264     \n",
      "Epoch 53/100\n",
      "21772/21772 [==============================] - 0s - loss: 0.2001 - acc: 0.9232     \n",
      "Epoch 54/100\n",
      "21772/21772 [==============================] - 0s - loss: 0.1903 - acc: 0.9293     \n",
      "Epoch 55/100\n",
      "21772/21772 [==============================] - 0s - loss: 0.1894 - acc: 0.9286     \n",
      "Epoch 56/100\n",
      "21772/21772 [==============================] - 0s - loss: 0.1852 - acc: 0.9296     \n",
      "Epoch 57/100\n",
      "21772/21772 [==============================] - 0s - loss: 0.1813 - acc: 0.9310     \n",
      "Epoch 58/100\n",
      "21772/21772 [==============================] - 0s - loss: 0.1851 - acc: 0.9305     \n",
      "Epoch 59/100\n",
      "21772/21772 [==============================] - 0s - loss: 0.1790 - acc: 0.9340     \n",
      "Epoch 60/100\n",
      "21772/21772 [==============================] - 0s - loss: 0.1740 - acc: 0.9352     \n",
      "Epoch 61/100\n",
      "21772/21772 [==============================] - 0s - loss: 0.1706 - acc: 0.9357     \n",
      "Epoch 62/100\n",
      "21772/21772 [==============================] - 0s - loss: 0.1758 - acc: 0.9335     \n",
      "Epoch 63/100\n",
      "21772/21772 [==============================] - 0s - loss: 0.1676 - acc: 0.9390     \n",
      "Epoch 64/100\n",
      "21772/21772 [==============================] - 0s - loss: 0.1675 - acc: 0.9375     \n",
      "Epoch 65/100\n",
      "21772/21772 [==============================] - 0s - loss: 0.1641 - acc: 0.9403     \n",
      "Epoch 66/100\n",
      "21772/21772 [==============================] - 0s - loss: 0.1644 - acc: 0.9378     \n",
      "Epoch 67/100\n",
      "21772/21772 [==============================] - 0s - loss: 0.1584 - acc: 0.9420     \n",
      "Epoch 68/100\n",
      "21772/21772 [==============================] - 0s - loss: 0.1582 - acc: 0.9423     \n",
      "Epoch 69/100\n",
      "21772/21772 [==============================] - 0s - loss: 0.1559 - acc: 0.9441     \n",
      "Epoch 70/100\n",
      "21772/21772 [==============================] - 0s - loss: 0.1519 - acc: 0.9454     \n",
      "Epoch 71/100\n",
      "21772/21772 [==============================] - 0s - loss: 0.1502 - acc: 0.9444     \n",
      "Epoch 72/100\n",
      "21772/21772 [==============================] - 0s - loss: 0.1542 - acc: 0.9424     \n",
      "Epoch 73/100\n",
      "21772/21772 [==============================] - 0s - loss: 0.1416 - acc: 0.9499     \n",
      "Epoch 74/100\n",
      "21772/21772 [==============================] - 0s - loss: 0.1500 - acc: 0.9452     \n",
      "Epoch 75/100\n",
      "21772/21772 [==============================] - 0s - loss: 0.1421 - acc: 0.9485     \n",
      "Epoch 76/100\n",
      "21772/21772 [==============================] - 0s - loss: 0.1383 - acc: 0.9502     \n",
      "Epoch 77/100\n",
      "21772/21772 [==============================] - 0s - loss: 0.1467 - acc: 0.9474     \n",
      "Epoch 78/100\n",
      "21772/21772 [==============================] - 0s - loss: 0.1339 - acc: 0.9514     \n",
      "Epoch 79/100\n",
      "21772/21772 [==============================] - 0s - loss: 0.1353 - acc: 0.9498     \n",
      "Epoch 80/100\n",
      "21772/21772 [==============================] - 0s - loss: 0.1344 - acc: 0.9533     \n",
      "Epoch 81/100\n",
      "21772/21772 [==============================] - 0s - loss: 0.1281 - acc: 0.9558     \n",
      "Epoch 82/100\n",
      "21772/21772 [==============================] - 0s - loss: 0.1359 - acc: 0.9500     \n",
      "Epoch 83/100\n",
      "21772/21772 [==============================] - 0s - loss: 0.1217 - acc: 0.9562     \n",
      "Epoch 84/100\n",
      "21772/21772 [==============================] - 0s - loss: 0.1265 - acc: 0.9549     \n",
      "Epoch 85/100\n",
      "21772/21772 [==============================] - 0s - loss: 0.1253 - acc: 0.9543     \n",
      "Epoch 86/100\n",
      "21772/21772 [==============================] - 0s - loss: 0.1277 - acc: 0.9545     \n",
      "Epoch 87/100\n",
      "21772/21772 [==============================] - 0s - loss: 0.1154 - acc: 0.9610     \n",
      "Epoch 88/100\n",
      "21772/21772 [==============================] - 0s - loss: 0.1247 - acc: 0.9550     \n",
      "Epoch 89/100\n",
      "21772/21772 [==============================] - 0s - loss: 0.1185 - acc: 0.9593     \n",
      "Epoch 90/100\n",
      "21772/21772 [==============================] - 0s - loss: 0.1165 - acc: 0.9587     \n",
      "Epoch 91/100\n",
      "21772/21772 [==============================] - 0s - loss: 0.1206 - acc: 0.9582     \n",
      "Epoch 92/100\n",
      "21772/21772 [==============================] - 0s - loss: 0.1105 - acc: 0.9607     \n",
      "Epoch 93/100\n",
      "21772/21772 [==============================] - 0s - loss: 0.1095 - acc: 0.9619     \n",
      "Epoch 94/100\n",
      "21772/21772 [==============================] - 0s - loss: 0.1084 - acc: 0.9613     \n",
      "Epoch 95/100\n",
      "21772/21772 [==============================] - 0s - loss: 0.1125 - acc: 0.9601     \n",
      "Epoch 96/100\n",
      "21772/21772 [==============================] - 0s - loss: 0.1038 - acc: 0.9652     \n",
      "Epoch 97/100\n",
      "21772/21772 [==============================] - 0s - loss: 0.1030 - acc: 0.9647     \n",
      "Epoch 98/100\n",
      "21772/21772 [==============================] - 0s - loss: 0.1074 - acc: 0.9616     \n",
      "Epoch 99/100\n",
      "21772/21772 [==============================] - 0s - loss: 0.1069 - acc: 0.9628     \n",
      "Epoch 100/100\n",
      "21772/21772 [==============================] - 0s - loss: 0.1059 - acc: 0.9644     \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 100)               2600      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 75)                7575      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 50)                3800      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 25)                1275      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 26        \n",
      "=================================================================\n",
      "Total params: 15,276\n",
      "Trainable params: 15,276\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "CPU times: user 51.1 s, sys: 10.1 s, total: 1min 1s\n",
      "Wall time: 29 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "np.random.seed(0)\n",
    "nn_res = Sequential()\n",
    "nn_res.add(Dense(100, input_dim = len(predictors), activation = 'relu'))\n",
    "nn_res.add(Dense(75, activation = 'relu'))\n",
    "nn_res.add(Dense(50, activation = 'relu'))\n",
    "nn_res.add(Dense(25, activation = 'relu'))\n",
    "nn_res.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "nn_res.compile(loss = 'binary_crossentropy', optimizer = 'rmsprop', metrics = ['accuracy'])\n",
    "nn_res.fit(np.array(train_res_preds), np.array(train_res_resp), epochs = 100, batch_size =  500)\n",
    "nn_res.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 41.1 s, sys: 453 ms, total: 41.5 s\n",
      "Wall time: 8min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "np.random.seed(0)\n",
    "\n",
    "model = RandomForestClassifier(criterion = 'entropy', n_estimators = 120, random_state = 0)\n",
    "tuning_params = {'min_samples_leaf':[1,5,10],\n",
    "                 'max_features':np.arange(1,len(predictors)+1),}\n",
    "\n",
    "rf_res = RandomizedSearchCV(model, tuning_params, cv = 5, return_train_score = False, n_jobs = 4, scoring = 'neg_log_loss')\n",
    "rf_res.fit(train_res_preds, train_res_resp)\n",
    "rf_res.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "nbc_res = BernoulliNB()\n",
    "nbc_res.fit(train_res_preds, train_res_resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight='balanced', coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "sv_res = SVC(class_weight = 'balanced', probability = True)\n",
    "sv_res.fit(train_res_preds, train_res_resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Fit on Validation Set for Selection 50/50 Balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Error rate</th>\n",
       "      <th>SE</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>FNR</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Cost</th>\n",
       "      <th>Lower Bound 95% CI</th>\n",
       "      <th>Upper Bound 95% CI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Support Vector Machines</th>\n",
       "      <td>0.585</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.989</td>\n",
       "      <td>0.301</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.835</td>\n",
       "      <td>0.220</td>\n",
       "      <td>-1.66</td>\n",
       "      <td>-1.672</td>\n",
       "      <td>-1.648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.528</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.370</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.849</td>\n",
       "      <td>0.237</td>\n",
       "      <td>-1.69</td>\n",
       "      <td>-1.702</td>\n",
       "      <td>-1.678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naive Bayes</th>\n",
       "      <td>0.321</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.798</td>\n",
       "      <td>0.656</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.798</td>\n",
       "      <td>0.316</td>\n",
       "      <td>-1.04</td>\n",
       "      <td>-1.052</td>\n",
       "      <td>-1.028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic</th>\n",
       "      <td>0.730</td>\n",
       "      <td>0.007</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.855</td>\n",
       "      <td>0.185</td>\n",
       "      <td>-1.56</td>\n",
       "      <td>-1.571</td>\n",
       "      <td>-1.549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L1 regularised</th>\n",
       "      <td>0.731</td>\n",
       "      <td>0.007</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.123</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.855</td>\n",
       "      <td>0.185</td>\n",
       "      <td>-1.56</td>\n",
       "      <td>-1.571</td>\n",
       "      <td>-1.549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L2 regularised</th>\n",
       "      <td>0.729</td>\n",
       "      <td>0.007</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.855</td>\n",
       "      <td>0.185</td>\n",
       "      <td>-1.56</td>\n",
       "      <td>-1.571</td>\n",
       "      <td>-1.549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LDA</th>\n",
       "      <td>0.729</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.185</td>\n",
       "      <td>-1.56</td>\n",
       "      <td>-1.571</td>\n",
       "      <td>-1.549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QDA</th>\n",
       "      <td>0.257</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.636</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.364</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.350</td>\n",
       "      <td>-0.37</td>\n",
       "      <td>-0.381</td>\n",
       "      <td>-0.359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Regularised QDA</th>\n",
       "      <td>0.293</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.733</td>\n",
       "      <td>0.701</td>\n",
       "      <td>0.267</td>\n",
       "      <td>0.803</td>\n",
       "      <td>0.328</td>\n",
       "      <td>-0.77</td>\n",
       "      <td>-0.781</td>\n",
       "      <td>-0.759</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Error rate     SE  Sensitivity  Specificity    FNR  \\\n",
       "Support Vector Machines       0.585  0.007        0.989        0.301  0.011   \n",
       "Random Forest                 0.528  0.008        0.985        0.370  0.015   \n",
       "Naive Bayes                   0.321  0.007        0.798        0.656  0.202   \n",
       "Logistic                      0.730  0.007        1.000        0.125  0.000   \n",
       "L1 regularised                0.731  0.007        1.000        0.123  0.000   \n",
       "L2 regularised                0.729  0.007        1.000        0.125  0.000   \n",
       "LDA                           0.729  0.007        0.999        0.126  0.001   \n",
       "QDA                           0.257  0.007        0.636        0.765  0.364   \n",
       "Regularised QDA               0.293  0.007        0.733        0.701  0.267   \n",
       "\n",
       "                           AUC  Precision  Cost  Lower Bound 95% CI  \\\n",
       "Support Vector Machines  0.835      0.220 -1.66              -1.672   \n",
       "Random Forest            0.849      0.237 -1.69              -1.702   \n",
       "Naive Bayes              0.798      0.316 -1.04              -1.052   \n",
       "Logistic                 0.855      0.185 -1.56              -1.571   \n",
       "L1 regularised           0.855      0.185 -1.56              -1.571   \n",
       "L2 regularised           0.855      0.185 -1.56              -1.571   \n",
       "LDA                      0.850      0.185 -1.56              -1.571   \n",
       "QDA                      0.775      0.350 -0.37              -0.381   \n",
       "Regularised QDA          0.803      0.328 -0.77              -0.781   \n",
       "\n",
       "                         Upper Bound 95% CI  \n",
       "Support Vector Machines              -1.648  \n",
       "Random Forest                        -1.678  \n",
       "Naive Bayes                          -1.028  \n",
       "Logistic                             -1.549  \n",
       "L1 regularised                       -1.549  \n",
       "L2 regularised                       -1.549  \n",
       "LDA                                  -1.549  \n",
       "QDA                                  -0.359  \n",
       "Regularised QDA                      -0.759  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score, precision_score\n",
    "\n",
    "columns=['Error rate', 'SE', 'Sensitivity', 'Specificity', 'FNR','AUC', 'Precision','Cost','Lower Bound 95% CI','Upper Bound 95% CI']\n",
    "rows=['Support Vector Machines','Random Forest','Naive Bayes','Logistic', 'L1 regularised', 'L2 regularised', 'LDA', 'QDA', 'Regularised QDA']\n",
    "results_res=pd.DataFrame(0.0, columns=columns, index=rows) \n",
    "\n",
    "methods=[sv_res, rf_res, nbc_res, logit_res, logit1_l1_res, logit1_l2_res, lda_res, qda_res, qda_reg_res]\n",
    "\n",
    "for i, method in enumerate(methods):\n",
    "    \n",
    "    if i >= 6: \n",
    "        y_prob = method.predict_proba(validate[gda_preds])\n",
    "        y_pred = np.array(((pd.DataFrame(y_prob)).iloc[:,1] > tau).astype(int))\n",
    "    else:\n",
    "        y_prob = (method.predict_proba(validate[predictors]))\n",
    "        y_pred = np.array(((pd.DataFrame(y_prob)).iloc[:,1] > tau).astype(int))\n",
    "    \n",
    "    Confusion_res  = confusion_matrix(validate[response], y_pred) \n",
    "    tn_res, fp_res, fn_res, tp_res = Confusion_res.ravel()\n",
    "    error_rate_res =  1 - accuracy_score(validate[response], y_pred)\n",
    "    formula2_res=((tn_res*benefit_cost[0,0]+fp_res*benefit_cost[0,1]+fn_res*benefit_cost[1,0]+tp_res*benefit_cost[1,1])/len(validate[response])).round(2)\n",
    "    se_res = np.sqrt(error_rate_res*(1- error_rate_res)/len(validate[response]))\n",
    "    \n",
    "    results_res.iloc[i,0]=  error_rate_res\n",
    "    results_res.iloc[i,1]=  se_res\n",
    "    results_res.iloc[i,2]=  Confusion_res[1,1]/float(np.sum(Confusion_res[1,:]))\n",
    "    results_res.iloc[i,3]=  Confusion_res[0,0]/float(np.sum(Confusion_res[0,:]))\n",
    "    results_res.iloc[i,4]=  fn_res/float(tp_res+fn_res)\n",
    "    results_res.iloc[i,5]=  roc_auc_score(validate[response], y_prob[:,1])\n",
    "    results_res.iloc[i,6]=  precision_score(validate[response], y_pred)\n",
    "    results_res.iloc[i,7]=  formula2_res\n",
    "    results_res.iloc[i,8] = formula2_res - se_res*stats.t.ppf(0.95, df = len(test[response])-1)\n",
    "    results_res.iloc[i,9] = formula2_res + se_res*stats.t.ppf(0.95, df = len(test[response])-1)\n",
    "\n",
    "results_res.round(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Evaluation Neural Network on Validation Data balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2464/4348 [================>.............] - ETA: 0s"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Error rate</th>\n",
       "      <th>SE</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>FNR</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Cost</th>\n",
       "      <th>Lower Bound 95% CI</th>\n",
       "      <th>Upper Bound 95% CI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Neural Networks</th>\n",
       "      <td>0.236</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.619</td>\n",
       "      <td>0.793</td>\n",
       "      <td>0.381</td>\n",
       "      <td>0.789</td>\n",
       "      <td>0.373</td>\n",
       "      <td>-0.31</td>\n",
       "      <td>-0.321</td>\n",
       "      <td>-0.299</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Error rate     SE  Sensitivity  Specificity    FNR    AUC  \\\n",
       "Neural Networks       0.236  0.006        0.619        0.793  0.381  0.789   \n",
       "\n",
       "                 Precision  Cost  Lower Bound 95% CI  Upper Bound 95% CI  \n",
       "Neural Networks      0.373 -0.31              -0.321              -0.299  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['Error rate', 'SE', 'Sensitivity', 'Specificity', 'FNR','AUC', 'Precision','Cost','Lower Bound 95% CI','Upper Bound 95% CI']\n",
    "rows = ['Neural Networks']\n",
    "results = pd.DataFrame(0.0, columns=columns, index=rows)\n",
    "\n",
    "y_prob_nn = (nn_res.predict_proba(np.array(validate[predictors])))\n",
    "y_pred_nn = np.array(((pd.DataFrame(y_prob_nn)) > tau).astype(int))\n",
    "\n",
    "Confusion  = confusion_matrix(validate[response], y_pred_nn) \n",
    "tn, fp, fn, tp = Confusion.ravel()\n",
    "error_rate =  1 - accuracy_score(validate[response], y_pred_nn)\n",
    "formula2=((tn*benefit_cost[0,0]+fp*benefit_cost[0,1]+fn*benefit_cost[1,0]+tp*benefit_cost[1,1])/len(validate[response])).round(2)\n",
    "se = np.sqrt(error_rate*(1- error_rate)/len(validate[response]))\n",
    "    \n",
    "results.iloc[0,0]=  error_rate\n",
    "results.iloc[0,1]=  se\n",
    "results.iloc[0,2]=  Confusion[1,1]/float(np.sum(Confusion[1,:]))\n",
    "results.iloc[0,3]=  Confusion[0,0]/float(np.sum(Confusion[0,:]))\n",
    "results.iloc[0,4]=  fn/float(tp+fn)\n",
    "results.iloc[0,5]=  roc_auc_score(validate[response], y_prob_nn)\n",
    "results.iloc[0,6]=  precision_score(validate[response], y_pred_nn)\n",
    "results.iloc[0,7]=  formula2\n",
    "results.iloc[0,8] = formula2 - se*stats.t.ppf(0.95, df = len(test[response])-1)\n",
    "results.iloc[0,9] = formula2 + se*stats.t.ppf(0.95, df = len(test[response])-1)\n",
    "\n",
    "results.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation on Test Data 50/50 Balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Error rate</th>\n",
       "      <th>SE</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>FNR</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Cost</th>\n",
       "      <th>Lower Bound 95% CI</th>\n",
       "      <th>Upper Bound 95% CI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Support Vector Machines</th>\n",
       "      <td>0.594</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.988</td>\n",
       "      <td>0.288</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.823</td>\n",
       "      <td>0.219</td>\n",
       "      <td>-1.67</td>\n",
       "      <td>-1.682</td>\n",
       "      <td>-1.658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.526</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.371</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.828</td>\n",
       "      <td>0.240</td>\n",
       "      <td>-1.72</td>\n",
       "      <td>-1.732</td>\n",
       "      <td>-1.708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naive Bayes</th>\n",
       "      <td>0.320</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.802</td>\n",
       "      <td>0.656</td>\n",
       "      <td>0.198</td>\n",
       "      <td>0.796</td>\n",
       "      <td>0.320</td>\n",
       "      <td>-1.08</td>\n",
       "      <td>-1.092</td>\n",
       "      <td>-1.068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic</th>\n",
       "      <td>0.724</td>\n",
       "      <td>0.007</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.841</td>\n",
       "      <td>0.188</td>\n",
       "      <td>-1.60</td>\n",
       "      <td>-1.611</td>\n",
       "      <td>-1.589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L1 regularised</th>\n",
       "      <td>0.726</td>\n",
       "      <td>0.007</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.841</td>\n",
       "      <td>0.188</td>\n",
       "      <td>-1.59</td>\n",
       "      <td>-1.601</td>\n",
       "      <td>-1.579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L2 regularised</th>\n",
       "      <td>0.724</td>\n",
       "      <td>0.007</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.841</td>\n",
       "      <td>0.189</td>\n",
       "      <td>-1.60</td>\n",
       "      <td>-1.611</td>\n",
       "      <td>-1.589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LDA</th>\n",
       "      <td>0.721</td>\n",
       "      <td>0.007</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.134</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.831</td>\n",
       "      <td>0.189</td>\n",
       "      <td>-1.60</td>\n",
       "      <td>-1.611</td>\n",
       "      <td>-1.589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QDA</th>\n",
       "      <td>0.256</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.620</td>\n",
       "      <td>0.769</td>\n",
       "      <td>0.380</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.352</td>\n",
       "      <td>-0.30</td>\n",
       "      <td>-0.311</td>\n",
       "      <td>-0.289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Regularised QDA</th>\n",
       "      <td>0.282</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.762</td>\n",
       "      <td>0.709</td>\n",
       "      <td>0.238</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.346</td>\n",
       "      <td>-0.93</td>\n",
       "      <td>-0.941</td>\n",
       "      <td>-0.919</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Error rate     SE  Sensitivity  Specificity    FNR  \\\n",
       "Support Vector Machines       0.594  0.007        0.988        0.288  0.012   \n",
       "Random Forest                 0.526  0.008        0.984        0.371  0.016   \n",
       "Naive Bayes                   0.320  0.007        0.802        0.656  0.198   \n",
       "Logistic                      0.724  0.007        1.000        0.130  0.000   \n",
       "L1 regularised                0.726  0.007        1.000        0.127  0.000   \n",
       "L2 regularised                0.724  0.007        1.000        0.130  0.000   \n",
       "LDA                           0.721  0.007        1.000        0.134  0.000   \n",
       "QDA                           0.256  0.007        0.620        0.769  0.380   \n",
       "Regularised QDA               0.282  0.007        0.762        0.709  0.238   \n",
       "\n",
       "                           AUC  Precision  Cost  Lower Bound 95% CI  \\\n",
       "Support Vector Machines  0.823      0.219 -1.67              -1.682   \n",
       "Random Forest            0.828      0.240 -1.72              -1.732   \n",
       "Naive Bayes              0.796      0.320 -1.08              -1.092   \n",
       "Logistic                 0.841      0.188 -1.60              -1.611   \n",
       "L1 regularised           0.841      0.188 -1.59              -1.601   \n",
       "L2 regularised           0.841      0.189 -1.60              -1.611   \n",
       "LDA                      0.831      0.189 -1.60              -1.611   \n",
       "QDA                      0.775      0.352 -0.30              -0.311   \n",
       "Regularised QDA          0.800      0.346 -0.93              -0.941   \n",
       "\n",
       "                         Upper Bound 95% CI  \n",
       "Support Vector Machines              -1.658  \n",
       "Random Forest                        -1.708  \n",
       "Naive Bayes                          -1.068  \n",
       "Logistic                             -1.589  \n",
       "L1 regularised                       -1.579  \n",
       "L2 regularised                       -1.589  \n",
       "LDA                                  -1.589  \n",
       "QDA                                  -0.289  \n",
       "Regularised QDA                      -0.919  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score, precision_score\n",
    "\n",
    "columns=['Error rate', 'SE', 'Sensitivity', 'Specificity', 'FNR','AUC', 'Precision','Cost','Lower Bound 95% CI','Upper Bound 95% CI']\n",
    "rows=['Support Vector Machines','Random Forest','Naive Bayes','Logistic', 'L1 regularised', 'L2 regularised', 'LDA', 'QDA', 'Regularised QDA']\n",
    "results=pd.DataFrame(0.0, columns=columns, index=rows) \n",
    "\n",
    "methods=[sv_res, rf_res, nbc_res, logit_res, logit1_l1_res, logit1_l2_res, lda_res, qda_res, qda_reg_res]\n",
    "\n",
    "for i, method in enumerate(methods):\n",
    "    \n",
    "    if i >= 6: \n",
    "        y_prob = method.predict_proba(test[gda_preds])\n",
    "        y_pred = np.array(((pd.DataFrame(y_prob)).iloc[:,1] > tau).astype(int))\n",
    "    else:\n",
    "        y_prob = method.predict_proba(test[predictors])\n",
    "        y_pred = np.array(((pd.DataFrame(y_prob)).iloc[:,1] > tau).astype(int))\n",
    "    \n",
    "    Confusion  = confusion_matrix(test[response], y_pred) \n",
    "    tn, fp, fn, tp = Confusion.ravel()\n",
    "    error_rate =  1 - accuracy_score(test[response], y_pred)\n",
    "    formula2=((tn*benefit_cost[0,0]+fp*benefit_cost[0,1]+fn*benefit_cost[1,0]+tp*benefit_cost[1,1])/len(test[response])).round(2)\n",
    "    se = np.sqrt(error_rate*(1- error_rate)/len(test[response]))\n",
    "    \n",
    "    results.iloc[i,0]=  error_rate\n",
    "    results.iloc[i,1]=  se\n",
    "    results.iloc[i,2]=  Confusion[1,1]/float(np.sum(Confusion[1,:]))\n",
    "    results.iloc[i,3]=  Confusion[0,0]/float(np.sum(Confusion[0,:]))\n",
    "    results.iloc[i,4]=  fn/float(tp+fn)\n",
    "    results.iloc[i,5]=  roc_auc_score(test[response], y_prob[:,1])\n",
    "    results.iloc[i,6]=  precision_score(test[response], y_pred)\n",
    "    results.iloc[i,7]=  formula2\n",
    "    results.iloc[i,8] = formula2 - se*stats.t.ppf(0.95, df = len(test[response])-1)\n",
    "    results.iloc[i,9] = formula2 + se*stats.t.ppf(0.95, df = len(test[response])-1)\n",
    "\n",
    "results.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Evaluation on Test Data Neural Networks balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2432/4348 [===============>..............] - ETA: 0s"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Error rate</th>\n",
       "      <th>SE</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>FNR</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Cost</th>\n",
       "      <th>Lower Bound 95% CI</th>\n",
       "      <th>Upper Bound 95% CI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Neural Networks</th>\n",
       "      <td>0.248</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.585</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.415</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.356</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>-0.161</td>\n",
       "      <td>-0.139</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Error rate     SE  Sensitivity  Specificity    FNR    AUC  \\\n",
       "Neural Networks       0.248  0.007        0.585        0.786  0.415  0.768   \n",
       "\n",
       "                 Precision  Cost  Lower Bound 95% CI  Upper Bound 95% CI  \n",
       "Neural Networks      0.356 -0.15              -0.161              -0.139  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['Error rate', 'SE', 'Sensitivity', 'Specificity', 'FNR','AUC', 'Precision','Cost','Lower Bound 95% CI','Upper Bound 95% CI']\n",
    "rows = ['Neural Networks']\n",
    "results = pd.DataFrame(0.0, columns=columns, index=rows)\n",
    "\n",
    "y_prob_nn_res = (nn_res.predict_proba(np.array(test[predictors])))\n",
    "y_pred_nn_res = np.array(((pd.DataFrame(y_prob_nn_res)) > tau).astype(int))\n",
    "\n",
    "Confusion  = confusion_matrix(test[response], y_pred_nn_res) \n",
    "tn, fp, fn, tp = Confusion.ravel()\n",
    "error_rate =  1 - accuracy_score(test[response], y_pred_nn_res)\n",
    "formula2=((tn*benefit_cost[0,0]+fp*benefit_cost[0,1]+fn*benefit_cost[1,0]+tp*benefit_cost[1,1])/len(test[response])).round(2)\n",
    "se = np.sqrt(error_rate*(1- error_rate)/len(test[response]))\n",
    "\n",
    "results.iloc[0,0]=  error_rate\n",
    "results.iloc[0,1]=  se\n",
    "results.iloc[0,2]=  Confusion[1,1]/float(np.sum(Confusion[1,:]))\n",
    "results.iloc[0,3]=  Confusion[0,0]/float(np.sum(Confusion[0,:]))\n",
    "results.iloc[0,4]=  fn/float(tp+fn)\n",
    "results.iloc[0,5]=  roc_auc_score(test[response], y_prob_nn_res)\n",
    "results.iloc[0,6]=  precision_score(test[response], y_pred_nn_res)\n",
    "results.iloc[0,7]=  formula2\n",
    "results.iloc[0,8] = formula2 - se*stats.t.ppf(0.95, df = len(test[response])-1)\n",
    "results.iloc[0,9] = formula2 + se*stats.t.ppf(0.95, df = len(test[response])-1)\n",
    "\n",
    "results.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Oversampling the data to a 50/50 ratio does not seem to help the model. Possibly because the loss matrix is defined in such a way that a false negative is very costly compared to a false positive. We try again below with a 70/30 ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Balanced Data 70%-30% ratio (After Standardization and Original Results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We oversample the data now so 70% respond and 30% do not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10886"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "len(train[train['RESP']==0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25400.66666666667"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Determine number to get 70/30 ratio\n",
    "(10886/.3)-10886"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    25400\n",
       "0    10886\n",
       "Name: RESP, dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separate majority and minority classes\n",
    "train_majority = train[train['RESP']==0]\n",
    "train_minority = train[train['RESP']==1]\n",
    " \n",
    "# Upsample minority class\n",
    "train_minority_upsampled = resample(train_minority, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=25400,    # oversample\n",
    "                                 random_state=123) # reproducible results\n",
    "\n",
    "    \n",
    "# Combine majority class with upsampled minority class\n",
    "train_resampled = pd.concat([train_majority, train_minority_upsampled])\n",
    " \n",
    "# Display new class counts\n",
    "train_resampled.RESP.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegressionCV(Cs=10, class_weight=None, cv=None, dual=False,\n",
       "           fit_intercept=True, intercept_scaling=1.0, max_iter=100,\n",
       "           multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "           refit=True, scoring='neg_log_loss', solver='lbfgs', tol=0.0001,\n",
       "           verbose=0)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic regression\n",
    "logit_res70 = LogisticRegression()\n",
    "logit_res70.fit(train_resampled[predictors], train_resampled[response])\n",
    "\n",
    "# L-1 Regularised logistic regression\n",
    "logit1_l1res70 = LogisticRegressionCV(penalty='l1', solver='liblinear', scoring = 'neg_log_loss')\n",
    "logit1_l1res70.fit(train_resampled[predictors], train_resampled[response])\n",
    "\n",
    "# L-2 Regularised logistic regression\n",
    "logit1_l2res70 = LogisticRegressionCV(penalty='l2', scoring = 'neg_log_loss')\n",
    "logit1_l2res70.fit(train_resampled[predictors], train_resampled[response])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
       "               store_covariance=False, store_covariances=None, tol=0.0001)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit LDA and QDA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "lda_res70 = LinearDiscriminantAnalysis()\n",
    "lda_res70.fit(train_resampled[gda_preds], train_resampled[response])\n",
    "\n",
    "qda_res70 = QuadraticDiscriminantAnalysis()\n",
    "qda_res70.fit(train_resampled[gda_preds], train_resampled[response])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "qda_reg_res70 = qda_cv(train_resampled[gda_preds], train_resampled[response]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "36286/36286 [==============================] - 0s - loss: 0.6116 - acc: 0.6738     \n",
      "Epoch 2/100\n",
      "36286/36286 [==============================] - 0s - loss: 0.4673 - acc: 0.7820     \n",
      "Epoch 3/100\n",
      "36286/36286 [==============================] - 0s - loss: 0.4451 - acc: 0.7957     \n",
      "Epoch 4/100\n",
      "36286/36286 [==============================] - 0s - loss: 0.4304 - acc: 0.8045     \n",
      "Epoch 5/100\n",
      "36286/36286 [==============================] - 0s - loss: 0.4203 - acc: 0.8133     \n",
      "Epoch 6/100\n",
      "36286/36286 [==============================] - 0s - loss: 0.4131 - acc: 0.8175     \n",
      "Epoch 7/100\n",
      "36286/36286 [==============================] - 0s - loss: 0.4087 - acc: 0.8216     \n",
      "Epoch 8/100\n",
      "36286/36286 [==============================] - 0s - loss: 0.4057 - acc: 0.8237     \n",
      "Epoch 9/100\n",
      "36286/36286 [==============================] - 0s - loss: 0.4035 - acc: 0.8249     \n",
      "Epoch 10/100\n",
      "36286/36286 [==============================] - 0s - loss: 0.4016 - acc: 0.8260     \n",
      "Epoch 11/100\n",
      "36286/36286 [==============================] - 0s - loss: 0.4002 - acc: 0.8273     \n",
      "Epoch 12/100\n",
      "36286/36286 [==============================] - 0s - loss: 0.3987 - acc: 0.8284     \n",
      "Epoch 13/100\n",
      "36286/36286 [==============================] - 0s - loss: 0.3974 - acc: 0.8287     \n",
      "Epoch 14/100\n",
      "36286/36286 [==============================] - 0s - loss: 0.3962 - acc: 0.8289     \n",
      "Epoch 15/100\n",
      "36286/36286 [==============================] - 0s - loss: 0.3954 - acc: 0.8301     \n",
      "Epoch 16/100\n",
      "36286/36286 [==============================] - 0s - loss: 0.3943 - acc: 0.8305     \n",
      "Epoch 17/100\n",
      "36286/36286 [==============================] - 0s - loss: 0.3932 - acc: 0.8309     \n",
      "Epoch 18/100\n",
      "36286/36286 [==============================] - 0s - loss: 0.3925 - acc: 0.8313     \n",
      "Epoch 19/100\n",
      "36286/36286 [==============================] - 0s - loss: 0.3917 - acc: 0.8325     \n",
      "Epoch 20/100\n",
      "36286/36286 [==============================] - 0s - loss: 0.3911 - acc: 0.8322     \n",
      "Epoch 21/100\n",
      "36286/36286 [==============================] - 0s - loss: 0.3905 - acc: 0.8331     \n",
      "Epoch 22/100\n",
      "36286/36286 [==============================] - 0s - loss: 0.3899 - acc: 0.8332     \n",
      "Epoch 23/100\n",
      "36286/36286 [==============================] - 0s - loss: 0.3892 - acc: 0.8336     \n",
      "Epoch 24/100\n",
      "36286/36286 [==============================] - 0s - loss: 0.3887 - acc: 0.8333     \n",
      "Epoch 25/100\n",
      "36286/36286 [==============================] - 0s - loss: 0.3880 - acc: 0.8335     \n",
      "Epoch 26/100\n",
      "36286/36286 [==============================] - 0s - loss: 0.3874 - acc: 0.8347     \n",
      "Epoch 27/100\n",
      "36286/36286 [==============================] - 0s - loss: 0.3871 - acc: 0.8350     \n",
      "Epoch 28/100\n",
      "36286/36286 [==============================] - 0s - loss: 0.3866 - acc: 0.8359     \n",
      "Epoch 29/100\n",
      "36286/36286 [==============================] - 0s - loss: 0.3863 - acc: 0.8355     \n",
      "Epoch 30/100\n",
      "36286/36286 [==============================] - 0s - loss: 0.3855 - acc: 0.8363     \n",
      "Epoch 31/100\n",
      "36286/36286 [==============================] - 0s - loss: 0.3853 - acc: 0.8358     \n",
      "Epoch 32/100\n",
      "36286/36286 [==============================] - 0s - loss: 0.3846 - acc: 0.8364     \n",
      "Epoch 33/100\n",
      "36286/36286 [==============================] - 0s - loss: 0.3844 - acc: 0.8365     \n",
      "Epoch 34/100\n",
      "36286/36286 [==============================] - 0s - loss: 0.3838 - acc: 0.8374     \n",
      "Epoch 35/100\n",
      "36286/36286 [==============================] - 0s - loss: 0.3834 - acc: 0.8371     \n",
      "Epoch 36/100\n",
      "36286/36286 [==============================] - 0s - loss: 0.3829 - acc: 0.8373     \n",
      "Epoch 37/100\n",
      "36286/36286 [==============================] - 0s - loss: 0.3827 - acc: 0.8378     \n",
      "Epoch 38/100\n",
      "36286/36286 [==============================] - 0s - loss: 0.3824 - acc: 0.8368     \n",
      "Epoch 39/100\n",
      "36286/36286 [==============================] - 0s - loss: 0.3817 - acc: 0.8373     \n",
      "Epoch 40/100\n",
      "36286/36286 [==============================] - 0s - loss: 0.3815 - acc: 0.8384     \n",
      "Epoch 41/100\n",
      "36286/36286 [==============================] - 0s - loss: 0.3811 - acc: 0.8376     \n",
      "Epoch 42/100\n",
      "36286/36286 [==============================] - 0s - loss: 0.3809 - acc: 0.8382     \n",
      "Epoch 43/100\n",
      "36286/36286 [==============================] - 0s - loss: 0.3804 - acc: 0.8387     \n",
      "Epoch 44/100\n",
      "36286/36286 [==============================] - 0s - loss: 0.3800 - acc: 0.8386     \n",
      "Epoch 45/100\n",
      "36286/36286 [==============================] - 0s - loss: 0.3796 - acc: 0.8378     \n",
      "Epoch 46/100\n",
      "36286/36286 [==============================] - 0s - loss: 0.3795 - acc: 0.8386     \n",
      "Epoch 47/100\n",
      "36286/36286 [==============================] - 0s - loss: 0.3789 - acc: 0.8393     \n",
      "Epoch 48/100\n",
      "36286/36286 [==============================] - 0s - loss: 0.3787 - acc: 0.8394     \n",
      "Epoch 49/100\n",
      "36286/36286 [==============================] - 0s - loss: 0.3783 - acc: 0.8397     \n",
      "Epoch 50/100\n",
      "36286/36286 [==============================] - 0s - loss: 0.3780 - acc: 0.8399     \n",
      "Epoch 51/100\n",
      "36286/36286 [==============================] - 0s - loss: 0.3777 - acc: 0.8397     \n",
      "Epoch 52/100\n",
      "36286/36286 [==============================] - 0s - loss: 0.3775 - acc: 0.8399     \n",
      "Epoch 53/100\n",
      "36286/36286 [==============================] - 0s - loss: 0.3772 - acc: 0.8405     \n",
      "Epoch 54/100\n",
      "36286/36286 [==============================] - 0s - loss: 0.3767 - acc: 0.8403     \n",
      "Epoch 55/100\n",
      "36286/36286 [==============================] - 0s - loss: 0.3765 - acc: 0.8408     \n",
      "Epoch 56/100\n",
      "36286/36286 [==============================] - 0s - loss: 0.3763 - acc: 0.8412     \n",
      "Epoch 57/100\n",
      "36286/36286 [==============================] - 0s - loss: 0.3762 - acc: 0.8415     \n",
      "Epoch 58/100\n",
      "36286/36286 [==============================] - 0s - loss: 0.3758 - acc: 0.8423     \n",
      "Epoch 59/100\n",
      "36286/36286 [==============================] - 0s - loss: 0.3756 - acc: 0.8418     \n",
      "Epoch 60/100\n",
      "36286/36286 [==============================] - 0s - loss: 0.3751 - acc: 0.8426     \n",
      "Epoch 61/100\n",
      "36286/36286 [==============================] - 0s - loss: 0.3749 - acc: 0.8425     \n",
      "Epoch 62/100\n",
      "36286/36286 [==============================] - 0s - loss: 0.3746 - acc: 0.8424     \n",
      "Epoch 63/100\n",
      "36286/36286 [==============================] - 0s - loss: 0.3745 - acc: 0.8432     \n",
      "Epoch 64/100\n",
      "36286/36286 [==============================] - 0s - loss: 0.3739 - acc: 0.8429     \n",
      "Epoch 65/100\n",
      "36286/36286 [==============================] - 0s - loss: 0.3739 - acc: 0.8434     \n",
      "Epoch 66/100\n",
      "36286/36286 [==============================] - 0s - loss: 0.3735 - acc: 0.8429     \n",
      "Epoch 67/100\n",
      "36286/36286 [==============================] - 0s - loss: 0.3733 - acc: 0.8433     \n",
      "Epoch 68/100\n",
      "36286/36286 [==============================] - 0s - loss: 0.3732 - acc: 0.8432     \n",
      "Epoch 69/100\n",
      "36286/36286 [==============================] - 0s - loss: 0.3728 - acc: 0.8438     \n",
      "Epoch 70/100\n",
      "36286/36286 [==============================] - 0s - loss: 0.3725 - acc: 0.8439     \n",
      "Epoch 71/100\n",
      "36286/36286 [==============================] - 0s - loss: 0.3722 - acc: 0.8443     \n",
      "Epoch 72/100\n",
      "36286/36286 [==============================] - 0s - loss: 0.3720 - acc: 0.8440     \n",
      "Epoch 73/100\n",
      "36286/36286 [==============================] - 0s - loss: 0.3718 - acc: 0.8448     \n",
      "Epoch 74/100\n",
      "36286/36286 [==============================] - 0s - loss: 0.3716 - acc: 0.8440     \n",
      "Epoch 75/100\n",
      "36286/36286 [==============================] - 0s - loss: 0.3714 - acc: 0.8443     \n",
      "Epoch 76/100\n",
      "36286/36286 [==============================] - 0s - loss: 0.3709 - acc: 0.8446     \n",
      "Epoch 77/100\n",
      "36286/36286 [==============================] - 0s - loss: 0.3710 - acc: 0.8448     \n",
      "Epoch 78/100\n",
      "36286/36286 [==============================] - 0s - loss: 0.3704 - acc: 0.8453     \n",
      "Epoch 79/100\n",
      "36286/36286 [==============================] - 0s - loss: 0.3704 - acc: 0.8448     \n",
      "Epoch 80/100\n",
      "36286/36286 [==============================] - 0s - loss: 0.3702 - acc: 0.8452     \n",
      "Epoch 81/100\n",
      "36286/36286 [==============================] - 0s - loss: 0.3701 - acc: 0.8456     \n",
      "Epoch 82/100\n",
      "36286/36286 [==============================] - 0s - loss: 0.3698 - acc: 0.8456     \n",
      "Epoch 83/100\n",
      "36286/36286 [==============================] - 0s - loss: 0.3696 - acc: 0.8454     \n",
      "Epoch 84/100\n",
      "36286/36286 [==============================] - 0s - loss: 0.3693 - acc: 0.8461     \n",
      "Epoch 85/100\n",
      "36286/36286 [==============================] - 0s - loss: 0.3690 - acc: 0.8461     \n",
      "Epoch 86/100\n",
      "36286/36286 [==============================] - 0s - loss: 0.3690 - acc: 0.8465     \n",
      "Epoch 87/100\n",
      "36286/36286 [==============================] - 0s - loss: 0.3686 - acc: 0.8470     \n",
      "Epoch 88/100\n",
      "36286/36286 [==============================] - 0s - loss: 0.3685 - acc: 0.8468     \n",
      "Epoch 89/100\n",
      "36286/36286 [==============================] - 0s - loss: 0.3682 - acc: 0.8468     \n",
      "Epoch 90/100\n",
      "36286/36286 [==============================] - 0s - loss: 0.3679 - acc: 0.8464     \n",
      "Epoch 91/100\n",
      "36286/36286 [==============================] - 0s - loss: 0.3676 - acc: 0.8470     \n",
      "Epoch 92/100\n",
      "36286/36286 [==============================] - 0s - loss: 0.3677 - acc: 0.8469     \n",
      "Epoch 93/100\n",
      "36286/36286 [==============================] - 0s - loss: 0.3671 - acc: 0.8470     \n",
      "Epoch 94/100\n",
      "36286/36286 [==============================] - 0s - loss: 0.3670 - acc: 0.8471     \n",
      "Epoch 95/100\n",
      "36286/36286 [==============================] - 0s - loss: 0.3667 - acc: 0.8470     \n",
      "Epoch 96/100\n",
      "36286/36286 [==============================] - 0s - loss: 0.3666 - acc: 0.8470     \n",
      "Epoch 97/100\n",
      "36286/36286 [==============================] - 0s - loss: 0.3663 - acc: 0.8466     \n",
      "Epoch 98/100\n",
      "36286/36286 [==============================] - 0s - loss: 0.3661 - acc: 0.8480     \n",
      "Epoch 99/100\n",
      "36286/36286 [==============================] - 0s - loss: 0.3658 - acc: 0.8471     \n",
      "Epoch 100/100\n",
      "36286/36286 [==============================] - 0s - loss: 0.3656 - acc: 0.8480     \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_8 (Dense)              (None, 25)                650       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 26        \n",
      "=================================================================\n",
      "Total params: 676\n",
      "Trainable params: 676\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "CPU times: user 31.8 s, sys: 10.4 s, total: 42.2 s\n",
      "Wall time: 27.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "np.random.seed(0)\n",
    "nn_res70 = Sequential()\n",
    "nn_res70.add(Dense(25, input_dim = len(predictors), activation = 'relu'))\n",
    "nn_res70.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "nn_res70.compile(loss = 'binary_crossentropy', optimizer = 'rmsprop', metrics = ['accuracy'])\n",
    "nn_res70.fit(np.array(train_resampled[predictors]), np.array(train_resampled[response]), epochs = 100, batch_size =  500)\n",
    "nn_res70.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 35.7 s, sys: 857 ms, total: 36.5 s\n",
      "Wall time: 8min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "model = RandomForestClassifier(criterion = 'entropy', n_estimators = 120, random_state = 0)\n",
    "tuning_params = {'min_samples_leaf':[1,5,10],\n",
    "                 'max_features':np.arange(1,len(predictors)+1),}\n",
    "\n",
    "rf_res70 = RandomizedSearchCV(model, tuning_params, cv = 5, return_train_score = False, n_jobs = 4, scoring = 'neg_log_loss')\n",
    "rf_res70.fit(train_resampled[predictors], train_resampled[response])\n",
    "rf_res70.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This cell can take a while to run\n",
    "nbc_res70 = nb_cv(train_resampled[predictors], train_resampled[response])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight='balanced', coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sv_res70 = SVC(class_weight = 'balanced', probability = True)\n",
    "sv_res70.fit(train_resampled[predictors], train_resampled[response])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Fit on Validation Set for Selection 70/30 Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Error rate</th>\n",
       "      <th>SE</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>FNR</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Cost</th>\n",
       "      <th>Lower Bound 95% CI</th>\n",
       "      <th>Upper Bound 95% CI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Support Vector Machines</th>\n",
       "      <td>0.785</td>\n",
       "      <td>0.006</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.175</td>\n",
       "      <td>-1.51</td>\n",
       "      <td>-1.520</td>\n",
       "      <td>-1.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.501</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.983</td>\n",
       "      <td>0.403</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.843</td>\n",
       "      <td>0.247</td>\n",
       "      <td>-1.71</td>\n",
       "      <td>-1.722</td>\n",
       "      <td>-1.698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naive Bayes</th>\n",
       "      <td>0.350</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.819</td>\n",
       "      <td>0.616</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.797</td>\n",
       "      <td>0.298</td>\n",
       "      <td>-1.11</td>\n",
       "      <td>-1.122</td>\n",
       "      <td>-1.098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic</th>\n",
       "      <td>0.796</td>\n",
       "      <td>0.006</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.173</td>\n",
       "      <td>-1.50</td>\n",
       "      <td>-1.510</td>\n",
       "      <td>-1.490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L1 regularised</th>\n",
       "      <td>0.796</td>\n",
       "      <td>0.006</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.173</td>\n",
       "      <td>-1.50</td>\n",
       "      <td>-1.510</td>\n",
       "      <td>-1.490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L2 regularised</th>\n",
       "      <td>0.796</td>\n",
       "      <td>0.006</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.173</td>\n",
       "      <td>-1.50</td>\n",
       "      <td>-1.510</td>\n",
       "      <td>-1.490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LDA</th>\n",
       "      <td>0.761</td>\n",
       "      <td>0.006</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.851</td>\n",
       "      <td>0.179</td>\n",
       "      <td>-1.53</td>\n",
       "      <td>-1.541</td>\n",
       "      <td>-1.519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QDA</th>\n",
       "      <td>0.323</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.647</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.318</td>\n",
       "      <td>-1.17</td>\n",
       "      <td>-1.182</td>\n",
       "      <td>-1.158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Regularised QDA</th>\n",
       "      <td>0.315</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.783</td>\n",
       "      <td>0.665</td>\n",
       "      <td>0.217</td>\n",
       "      <td>0.801</td>\n",
       "      <td>0.318</td>\n",
       "      <td>-0.98</td>\n",
       "      <td>-0.992</td>\n",
       "      <td>-0.968</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Error rate     SE  Sensitivity  Specificity    FNR  \\\n",
       "Support Vector Machines       0.785  0.006        1.000        0.059  0.000   \n",
       "Random Forest                 0.501  0.008        0.983        0.403  0.017   \n",
       "Naive Bayes                   0.350  0.007        0.819        0.616  0.181   \n",
       "Logistic                      0.796  0.006        1.000        0.046  0.000   \n",
       "L1 regularised                0.796  0.006        1.000        0.046  0.000   \n",
       "L2 regularised                0.796  0.006        1.000        0.046  0.000   \n",
       "LDA                           0.761  0.006        1.000        0.087  0.000   \n",
       "QDA                           0.323  0.007        0.825        0.647  0.175   \n",
       "Regularised QDA               0.315  0.007        0.783        0.665  0.217   \n",
       "\n",
       "                           AUC  Precision  Cost  Lower Bound 95% CI  \\\n",
       "Support Vector Machines  0.833      0.175 -1.51              -1.520   \n",
       "Random Forest            0.843      0.247 -1.71              -1.722   \n",
       "Naive Bayes              0.797      0.298 -1.11              -1.122   \n",
       "Logistic                 0.857      0.173 -1.50              -1.510   \n",
       "L1 regularised           0.857      0.173 -1.50              -1.510   \n",
       "L2 regularised           0.857      0.173 -1.50              -1.510   \n",
       "LDA                      0.851      0.179 -1.53              -1.541   \n",
       "QDA                      0.818      0.318 -1.17              -1.182   \n",
       "Regularised QDA          0.801      0.318 -0.98              -0.992   \n",
       "\n",
       "                         Upper Bound 95% CI  \n",
       "Support Vector Machines              -1.500  \n",
       "Random Forest                        -1.698  \n",
       "Naive Bayes                          -1.098  \n",
       "Logistic                             -1.490  \n",
       "L1 regularised                       -1.490  \n",
       "L2 regularised                       -1.490  \n",
       "LDA                                  -1.519  \n",
       "QDA                                  -1.158  \n",
       "Regularised QDA                      -0.968  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score, precision_score\n",
    "\n",
    "columns=['Error rate', 'SE', 'Sensitivity', 'Specificity', 'FNR','AUC', 'Precision','Cost','Lower Bound 95% CI','Upper Bound 95% CI']\n",
    "rows=['Support Vector Machines','Random Forest','Naive Bayes','Logistic', 'L1 regularised', 'L2 regularised', 'LDA', 'QDA', 'Regularised QDA']\n",
    "results_res=pd.DataFrame(0.0, columns=columns, index=rows) \n",
    "\n",
    "methods=[sv_res70, rf_res70, nbc_res70, logit_res70, logit1_l1res70, logit1_l2res70, lda_res70, qda_res70, qda_reg_res70]\n",
    "\n",
    "for i, method in enumerate(methods):\n",
    "    \n",
    "    if i >= 6: \n",
    "        y_prob = method.predict_proba(validate[gda_preds])\n",
    "        y_pred = np.array(((pd.DataFrame(y_prob)).iloc[:,1] > tau).astype(int))\n",
    "    else:\n",
    "        y_prob = (method.predict_proba(validate[predictors]))\n",
    "        y_pred = np.array(((pd.DataFrame(y_prob)).iloc[:,1] > tau).astype(int))\n",
    "    \n",
    "    Confusion_res  = confusion_matrix(validate[response], y_pred) \n",
    "    tn_res, fp_res, fn_res, tp_res = Confusion_res.ravel()\n",
    "    error_rate_res =  1 - accuracy_score(validate[response], y_pred)\n",
    "    formula2_res=((tn_res*benefit_cost[0,0]+fp_res*benefit_cost[0,1]+fn_res*benefit_cost[1,0]+tp_res*benefit_cost[1,1])/len(validate[response])).round(2)\n",
    "    se_res = np.sqrt(error_rate_res*(1- error_rate_res)/len(validate[response]))\n",
    "    \n",
    "    results_res.iloc[i,0]=  error_rate_res\n",
    "    results_res.iloc[i,1]=  se_res\n",
    "    results_res.iloc[i,2]=  Confusion_res[1,1]/float(np.sum(Confusion_res[1,:]))\n",
    "    results_res.iloc[i,3]=  Confusion_res[0,0]/float(np.sum(Confusion_res[0,:]))\n",
    "    results_res.iloc[i,4]=  fn_res/float(tp_res+fn_res)\n",
    "    results_res.iloc[i,5]=  roc_auc_score(validate[response], y_prob[:,1])\n",
    "    results_res.iloc[i,6]=  precision_score(validate[response], y_pred)\n",
    "    results_res.iloc[i,7]=  formula2_res\n",
    "    results_res.iloc[i,8] = formula2_res - se_res*stats.t.ppf(0.95, df = len(test[response])-1)\n",
    "    results_res.iloc[i,9] = formula2_res + se_res*stats.t.ppf(0.95, df = len(test[response])-1)\n",
    "\n",
    "results_res.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model fit on validation data for neural networks 70/30 ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3232/4348 [=====================>........] - ETA: 0s"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Error rate</th>\n",
       "      <th>SE</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>FNR</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Cost</th>\n",
       "      <th>Lower Bound 95% CI</th>\n",
       "      <th>Upper Bound 95% CI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Neural Networks</th>\n",
       "      <td>0.676</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.189</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.851</td>\n",
       "      <td>0.197</td>\n",
       "      <td>-1.61</td>\n",
       "      <td>-1.622</td>\n",
       "      <td>-1.598</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Error rate     SE  Sensitivity  Specificity    FNR    AUC  \\\n",
       "Neural Networks       0.676  0.007        0.999        0.189  0.001  0.851   \n",
       "\n",
       "                 Precision  Cost  Lower Bound 95% CI  Upper Bound 95% CI  \n",
       "Neural Networks      0.197 -1.61              -1.622              -1.598  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['Error rate', 'SE', 'Sensitivity', 'Specificity', 'FNR','AUC', 'Precision','Cost','Lower Bound 95% CI','Upper Bound 95% CI']\n",
    "rows = ['Neural Networks']\n",
    "results = pd.DataFrame(0.0, columns=columns, index=rows)\n",
    "\n",
    "y_prob_nn = (nn_res70.predict_proba(np.array(validate[predictors])))\n",
    "y_pred_nn = np.array(((pd.DataFrame(y_prob_nn)) > tau).astype(int))\n",
    "\n",
    "Confusion  = confusion_matrix(validate[response], y_pred_nn) \n",
    "tn, fp, fn, tp = Confusion.ravel()\n",
    "error_rate =  1 - accuracy_score(validate[response], y_pred_nn)\n",
    "formula2=((tn*benefit_cost[0,0]+fp*benefit_cost[0,1]+fn*benefit_cost[1,0]+tp*benefit_cost[1,1])/len(validate[response])).round(2)\n",
    "se = np.sqrt(error_rate*(1- error_rate)/len(validate[response]))\n",
    "    \n",
    "results.iloc[0,0]=  error_rate\n",
    "results.iloc[0,1]=  se\n",
    "results.iloc[0,2]=  Confusion[1,1]/float(np.sum(Confusion[1,:]))\n",
    "results.iloc[0,3]=  Confusion[0,0]/float(np.sum(Confusion[0,:]))\n",
    "results.iloc[0,4]=  fn/float(tp+fn)\n",
    "results.iloc[0,5]=  roc_auc_score(validate[response], y_prob_nn)\n",
    "results.iloc[0,6]=  precision_score(validate[response], y_pred_nn)\n",
    "results.iloc[0,7]=  formula2\n",
    "results.iloc[0,8] = formula2 - se*stats.t.ppf(0.95, df = len(test[response])-1)\n",
    "results.iloc[0,9] = formula2 + se*stats.t.ppf(0.95, df = len(test[response])-1)\n",
    "\n",
    "results.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation on test data 70/30 ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Error rate</th>\n",
       "      <th>SE</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>FNR</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Cost</th>\n",
       "      <th>Lower Bound 95% CI</th>\n",
       "      <th>Upper Bound 95% CI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Support Vector Machines</th>\n",
       "      <td>0.594</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.988</td>\n",
       "      <td>0.288</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.823</td>\n",
       "      <td>0.219</td>\n",
       "      <td>-1.67</td>\n",
       "      <td>-1.682</td>\n",
       "      <td>-1.658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.501</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.969</td>\n",
       "      <td>0.404</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.829</td>\n",
       "      <td>0.247</td>\n",
       "      <td>-1.67</td>\n",
       "      <td>-1.682</td>\n",
       "      <td>-1.658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naive Bayes</th>\n",
       "      <td>0.346</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.829</td>\n",
       "      <td>0.618</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.796</td>\n",
       "      <td>0.305</td>\n",
       "      <td>-1.18</td>\n",
       "      <td>-1.192</td>\n",
       "      <td>-1.168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic</th>\n",
       "      <td>0.791</td>\n",
       "      <td>0.006</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.843</td>\n",
       "      <td>0.175</td>\n",
       "      <td>-1.53</td>\n",
       "      <td>-1.540</td>\n",
       "      <td>-1.520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L1 regularised</th>\n",
       "      <td>0.792</td>\n",
       "      <td>0.006</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.843</td>\n",
       "      <td>0.175</td>\n",
       "      <td>-1.53</td>\n",
       "      <td>-1.540</td>\n",
       "      <td>-1.520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L2 regularised</th>\n",
       "      <td>0.792</td>\n",
       "      <td>0.006</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.843</td>\n",
       "      <td>0.175</td>\n",
       "      <td>-1.53</td>\n",
       "      <td>-1.540</td>\n",
       "      <td>-1.520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LDA</th>\n",
       "      <td>0.755</td>\n",
       "      <td>0.007</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.841</td>\n",
       "      <td>0.182</td>\n",
       "      <td>-1.57</td>\n",
       "      <td>-1.581</td>\n",
       "      <td>-1.559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QDA</th>\n",
       "      <td>0.326</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.806</td>\n",
       "      <td>0.647</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.807</td>\n",
       "      <td>0.316</td>\n",
       "      <td>-1.09</td>\n",
       "      <td>-1.102</td>\n",
       "      <td>-1.078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Regularised QDA</th>\n",
       "      <td>0.307</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.792</td>\n",
       "      <td>0.673</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.798</td>\n",
       "      <td>0.329</td>\n",
       "      <td>-1.05</td>\n",
       "      <td>-1.062</td>\n",
       "      <td>-1.038</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Error rate     SE  Sensitivity  Specificity    FNR  \\\n",
       "Support Vector Machines       0.594  0.007        0.988        0.288  0.012   \n",
       "Random Forest                 0.501  0.008        0.969        0.404  0.031   \n",
       "Naive Bayes                   0.346  0.007        0.829        0.618  0.171   \n",
       "Logistic                      0.791  0.006        1.000        0.049  0.000   \n",
       "L1 regularised                0.792  0.006        1.000        0.048  0.000   \n",
       "L2 regularised                0.792  0.006        1.000        0.048  0.000   \n",
       "LDA                           0.755  0.007        1.000        0.093  0.000   \n",
       "QDA                           0.326  0.007        0.806        0.647  0.194   \n",
       "Regularised QDA               0.307  0.007        0.792        0.673  0.208   \n",
       "\n",
       "                           AUC  Precision  Cost  Lower Bound 95% CI  \\\n",
       "Support Vector Machines  0.823      0.219 -1.67              -1.682   \n",
       "Random Forest            0.829      0.247 -1.67              -1.682   \n",
       "Naive Bayes              0.796      0.305 -1.18              -1.192   \n",
       "Logistic                 0.843      0.175 -1.53              -1.540   \n",
       "L1 regularised           0.843      0.175 -1.53              -1.540   \n",
       "L2 regularised           0.843      0.175 -1.53              -1.540   \n",
       "LDA                      0.841      0.182 -1.57              -1.581   \n",
       "QDA                      0.807      0.316 -1.09              -1.102   \n",
       "Regularised QDA          0.798      0.329 -1.05              -1.062   \n",
       "\n",
       "                         Upper Bound 95% CI  \n",
       "Support Vector Machines              -1.658  \n",
       "Random Forest                        -1.658  \n",
       "Naive Bayes                          -1.168  \n",
       "Logistic                             -1.520  \n",
       "L1 regularised                       -1.520  \n",
       "L2 regularised                       -1.520  \n",
       "LDA                                  -1.559  \n",
       "QDA                                  -1.078  \n",
       "Regularised QDA                      -1.038  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score, precision_score\n",
    "\n",
    "columns=['Error rate', 'SE', 'Sensitivity', 'Specificity', 'FNR','AUC', 'Precision','Cost','Lower Bound 95% CI','Upper Bound 95% CI']\n",
    "rows=['Support Vector Machines','Random Forest','Naive Bayes','Logistic', 'L1 regularised', 'L2 regularised', 'LDA', 'QDA', 'Regularised QDA']\n",
    "results=pd.DataFrame(0.0, columns=columns, index=rows) \n",
    "\n",
    "methods=[sv_res, rf_res70, nbc_res70, logit_res70, logit1_l1res70, logit1_l2res70, lda_res70, qda_res70, qda_reg_res70]\n",
    "\n",
    "for i, method in enumerate(methods):\n",
    "    \n",
    "    if i >= 6: \n",
    "        y_prob = method.predict_proba(test[gda_preds])\n",
    "        y_pred = np.array(((pd.DataFrame(y_prob)).iloc[:,1] > tau).astype(int))\n",
    "    else:\n",
    "        y_prob = method.predict_proba(test[predictors])\n",
    "        y_pred = np.array(((pd.DataFrame(y_prob)).iloc[:,1] > tau).astype(int))\n",
    "    \n",
    "    Confusion  = confusion_matrix(test[response], y_pred) \n",
    "    tn, fp, fn, tp = Confusion.ravel()\n",
    "    error_rate =  1 - accuracy_score(test[response], y_pred)\n",
    "    formula2=((tn*benefit_cost[0,0]+fp*benefit_cost[0,1]+fn*benefit_cost[1,0]+tp*benefit_cost[1,1])/len(test[response])).round(2)\n",
    "    se = np.sqrt(error_rate*(1- error_rate)/len(test[response]))\n",
    "    \n",
    "    results.iloc[i,0]=  error_rate\n",
    "    results.iloc[i,1]=  se\n",
    "    results.iloc[i,2]=  Confusion[1,1]/float(np.sum(Confusion[1,:]))\n",
    "    results.iloc[i,3]=  Confusion[0,0]/float(np.sum(Confusion[0,:]))\n",
    "    results.iloc[i,4]=  fn/float(tp+fn)\n",
    "    results.iloc[i,5]=  roc_auc_score(test[response], y_prob[:,1])\n",
    "    results.iloc[i,6]=  precision_score(test[response], y_pred)\n",
    "    results.iloc[i,7]=  formula2\n",
    "    results.iloc[i,8] = formula2 - se*stats.t.ppf(0.95, df = len(test[response])-1)\n",
    "    results.iloc[i,9] = formula2 + se*stats.t.ppf(0.95, df = len(test[response])-1)\n",
    "\n",
    "results.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model evaluation on test data for neural networks 70/30 ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2688/4348 [=================>............] - ETA: 0s"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Error rate</th>\n",
       "      <th>SE</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>FNR</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Cost</th>\n",
       "      <th>Lower Bound 95% CI</th>\n",
       "      <th>Upper Bound 95% CI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Neural Networks</th>\n",
       "      <td>0.669</td>\n",
       "      <td>0.007</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.839</td>\n",
       "      <td>0.201</td>\n",
       "      <td>-1.65</td>\n",
       "      <td>-1.662</td>\n",
       "      <td>-1.638</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Error rate     SE  Sensitivity  Specificity  FNR    AUC  \\\n",
       "Neural Networks       0.669  0.007          1.0        0.196  0.0  0.839   \n",
       "\n",
       "                 Precision  Cost  Lower Bound 95% CI  Upper Bound 95% CI  \n",
       "Neural Networks      0.201 -1.65              -1.662              -1.638  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['Error rate', 'SE', 'Sensitivity', 'Specificity', 'FNR','AUC', 'Precision','Cost','Lower Bound 95% CI','Upper Bound 95% CI']\n",
    "rows = ['Neural Networks']\n",
    "results = pd.DataFrame(0.0, columns=columns, index=rows)\n",
    "\n",
    "y_prob_nn_res = (nn_res70.predict_proba(np.array(test[predictors])))\n",
    "y_pred_nn_res = np.array(((pd.DataFrame(y_prob_nn_res)) > tau).astype(int))\n",
    "\n",
    "Confusion  = confusion_matrix(test[response], y_pred_nn_res) \n",
    "tn, fp, fn, tp = Confusion.ravel()\n",
    "error_rate =  1 - accuracy_score(test[response], y_pred_nn_res)\n",
    "formula2=((tn*benefit_cost[0,0]+fp*benefit_cost[0,1]+fn*benefit_cost[1,0]+tp*benefit_cost[1,1])/len(test[response])).round(2)\n",
    "se = np.sqrt(error_rate*(1- error_rate)/len(test[response]))\n",
    "\n",
    "results.iloc[0,0]=  error_rate\n",
    "results.iloc[0,1]=  se\n",
    "results.iloc[0,2]=  Confusion[1,1]/float(np.sum(Confusion[1,:]))\n",
    "results.iloc[0,3]=  Confusion[0,0]/float(np.sum(Confusion[0,:]))\n",
    "results.iloc[0,4]=  fn/float(tp+fn)\n",
    "results.iloc[0,5]=  roc_auc_score(test[response], y_prob_nn_res)\n",
    "results.iloc[0,6]=  precision_score(test[response], y_pred_nn_res)\n",
    "results.iloc[0,7]=  formula2\n",
    "results.iloc[0,8] = formula2 - se*stats.t.ppf(0.95, df = len(test[response])-1)\n",
    "results.iloc[0,9] = formula2 + se*stats.t.ppf(0.95, df = len(test[response])-1)\n",
    "\n",
    "results.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results from oversampling the data to a 70/30 ratio are worse than the 50/50 split. Neither ovesampling method produces better results than the data no resampled, so we choose to use the data without resampling"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
